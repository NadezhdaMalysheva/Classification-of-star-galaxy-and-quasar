{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Эксперименты с гиперпараметрами",
      "provenance": [],
      "collapsed_sections": [
        "m0kPZJ5yOVbo",
        "N-hlXdD5xbL8"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NadezhdaMalysheva/projects/blob/main/Experiments_with_hyperparameters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoXFJs19Ks2y",
        "outputId": "4c398145-0498-4bc6-b5b3-4e4e92fa33ac"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0kPZJ5yOVbo"
      },
      "source": [
        "# Подгружаем необходимые библиотеки "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtFLkOBsdnJR",
        "outputId": "451106b5-0cfb-4c01-a77a-83102d54d669"
      },
      "source": [
        "pip install pytorch-tabnet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-tabnet in /usr/local/lib/python3.7/dist-packages (3.1.1)\n",
            "Requirement already satisfied: torch<2.0,>=1.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.8.0+cu101)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.4.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.19.5)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.36 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (4.41.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0,>=1.2->pytorch-tabnet) (3.7.4.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCLtYHFqwmod"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2lA0dgTwmib",
        "outputId": "e456ceb1-4e40-4a78-aafb-ec85aca92607"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import plotly.offline as py\n",
        "color = sns.color_palette()\n",
        "import plotly.graph_objs as go\n",
        "py.init_notebook_mode(connected=True)\n",
        "import plotly.tools as tls\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVxxcXZGwmdb"
      },
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, roc_auc_score \n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "import joblib\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "\n",
        "from hyperopt import hp\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, f1_score, accuracy_score\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import KFold\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "import lightgbm as lgb\n",
        "from hyperopt import fmin, tpe, STATUS_OK, STATUS_FAIL, Trials\n",
        "\n",
        "from time import time\n",
        "import joblib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guuBGRaaiDoJ"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-hlXdD5xbL8"
      },
      "source": [
        "#Загружаем данные, параметры"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16jPxCCCBTwd"
      },
      "source": [
        "target = 'class'\n",
        "\n",
        "add_columns = ['subClass', 'objID', 'z', 'zErr', 'ra', 'dec']\n",
        "\n",
        "photo_columns = ['psfMag_u',\t'psfMag_g',\t'psfMag_r',\t'psfMag_i',\t'psfMag_z',\n",
        "                 'cModelMag_u',\t'cModelMag_g',\t'cModelMag_r',\t'cModelMag_i',\t'cModelMag_z']\n",
        "\n",
        "feature_columns = (\n",
        "    photo_columns + add_columns + [target])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIwVGqf2C1KA"
      },
      "source": [
        "df = joblib.load('/content/drive/MyDrive/Научная работа/Спецсем/TabNetModel/df_agg.pkl')#pd.read_csv('/content/drive/MyDrive/Научная работа/Спецсем/TabNetModel/df_agg.csv')\n",
        "agr_feature = [x for x in df.columns if x not in feature_columns]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yer4R5LMyP0m"
      },
      "source": [
        "def data_preparation(X, y, c=10000, test_size = 0.8):\n",
        "\n",
        "    X1_train, X1_test, y1_train, y1_test = train_test_split(X[y==1], y[y==1], test_size=test_size, random_state = 43)\n",
        "    X2_train, X2_test, y2_train, y2_test = train_test_split(X[y==2], y[y==2], test_size=test_size, random_state = 43)\n",
        "    X3_train, X3_test, y3_train, y3_test = train_test_split(X[y==3], y[y==3], test_size=test_size, random_state = 43)\n",
        "    \n",
        "    count = c\n",
        "    count1 = c\n",
        "\n",
        "    X_train, X_test = np.concatenate((X1_train[:count], X2_train[:count], X3_train[:count])), np.concatenate((X1_test[:count1], X2_test[:count1], X3_test[:count1]))\n",
        "    y_train, y_test = np.concatenate((y1_train[:count], y2_train[:count], y3_train[:count])), np.concatenate((y1_test[:count1], y2_test[:count1], y3_test[:count1]))\n",
        "    \n",
        "\n",
        "    return [X_train, X_test, y_train, y_test, X1_train, X1_test, y1_train, y1_test, X2_train, X2_test, y2_train, y2_test, X3_train, X3_test, y3_train, y3_test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NopTyppkzaA"
      },
      "source": [
        "def scor(y_test, y_pred):\n",
        "  return accuracy_score(y_test, y_pred)\n",
        "\n",
        "lgb_reg_params = {\n",
        "    'learning_rate':    hp.uniform('learning_rate', 0.001, 0.1),\n",
        "    'min_child_samples':hp.randint('min_child_samples', 50)+1,\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.1, 0.9),\n",
        "    'num_leaves' :      hp.randint('num_leaves', 100)+10,\n",
        "    'min_child_weight': hp.uniform('min_child_weight', 0.001, 0.99),\n",
        "    'n_estimators':     hp.randint('n_estimators', 1500)+100\n",
        "}\n",
        "lgb_fit_params = {\n",
        "    'early_stopping_rounds': 20,\n",
        "    'verbose': False\n",
        "}\n",
        "lgb_para = dict()\n",
        "lgb_para['reg_params'] = lgb_reg_params\n",
        "lgb_para['fit_params'] = lgb_fit_params\n",
        "lgb_para['score'] = lambda y, pred: -accuracy_score(y, pred)\n",
        "\n",
        "\n",
        "rf_reg_params = {\n",
        "    'min_samples_leaf': hp.randint('min_samples_leaf', 20)+1,\n",
        "    'min_samples_split':hp.uniform('min_samples_split', 0.001, 0.1),\n",
        "    #'max_features':     hp.choice('max_features', ['auto', 'sqrt', 'log2', None]),\n",
        "    #'learning_rate':    hp.uniform('learning_rate', 0.001, 0.1),\n",
        "    'n_estimators':     hp.randint('n_estimators', 800)+100\n",
        "}\n",
        "rf_fit_params = {\n",
        "}\n",
        "rf_para = dict()\n",
        "rf_para['reg_params'] = rf_reg_params\n",
        "rf_para['fit_params'] = rf_fit_params\n",
        "rf_para['score'] = lambda y, pred: -accuracy_score(y, pred)\n",
        "\n",
        "tabnet_reg_params = {\n",
        "    'n_d' :              64,\n",
        "    'n_a' :              64,\n",
        "    'n_steps' :          hp.randint('n_steps', 10-3)+3,\n",
        "    'gamma' :            hp.uniform('gamma', 1.0, 3.0),\n",
        "    'lambda_sparse' :    hp.uniform('lambda_sparse', 0.0, 0.01),\n",
        "    'momentum' :         0.3, \n",
        "    'clip_value' :       2.,\n",
        "    'optimizer_params' : dict(lr=2e-2),\n",
        "    'scheduler_params' : {\"step_size\":50, \"gamma\":0.9},\n",
        "    'scheduler_fn' :     torch.optim.lr_scheduler.StepLR,\n",
        "    'mask_type' :       'entmax'\n",
        "}\n",
        "\n",
        "tabnet_fit_params = {\n",
        "    'max_epochs' : 100, \n",
        "    'patience' : 15,\n",
        "    'batch_size' : 512,\n",
        "    'virtual_batch_size' : 128,\n",
        "    'num_workers' : 0,\n",
        "    'weights' : 1,\n",
        "    'drop_last' : False,\n",
        "    #'from_unsupervised' : unsupervised_model\n",
        "}\n",
        "tabnet_para = dict()\n",
        "tabnet_para['reg_params'] = tabnet_reg_params\n",
        "tabnet_para['fit_params'] = tabnet_fit_params\n",
        "tabnet_para['score'] = lambda y, pred: -accuracy_score(y, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Krr4en2uzv-"
      },
      "source": [
        "target = 'class'\n",
        "\n",
        "add_columns = ['subClass', 'objID', 'z', 'zErr', 'ra', 'dec']\n",
        "\n",
        "photo_columns = ['psfMag_u',\t'psfMag_g',\t'psfMag_r',\t'psfMag_i',\t'psfMag_z',\n",
        "                 'cModelMag_u',\t'cModelMag_g',\t'cModelMag_r',\t'cModelMag_i',\t'cModelMag_z']\n",
        "\n",
        "feature_columns = (\n",
        "    photo_columns + add_columns + [target])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeLm9XEC7z88"
      },
      "source": [
        "X, y  = joblib.load('/content/drive/MyDrive/Научная работа/Спецсем/TabNetModel/X_y.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Senx9ogAuulc"
      },
      "source": [
        "# Общая функция"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqcSoieSu6bG"
      },
      "source": [
        "with open('/content/drive/MyDrive/Научная работа/Data/hyperparametrs.txt', 'w') as f:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvnRCetO2baB"
      },
      "source": [
        "def bootstrap_accuracy(model, X_test, y_test):\n",
        "  from sklearn.utils import resample\n",
        "  from matplotlib import pyplot\n",
        "  values = np.concatenate((X_test, y_test.reshape((len(y_test), 1))), axis=1)\n",
        "  n_iterations = 100\n",
        "  n_size = int(len(y_test) * 0.50)\n",
        "  stats = list()\n",
        "  for i in range(n_iterations):\n",
        "    test = resample(values, n_samples=n_size)\n",
        "    predictions = model.predict(test[:,:-1])\n",
        "    score = accuracy_score(test[:,-1], predictions)\n",
        "    stats.append(score)\n",
        "  #pyplot.hist(stats, range=(0.872, 0.9))\n",
        "  #pyplot.show()\n",
        "  alpha = 0.97\n",
        "  p = ((1.0-alpha)/2.0) * 100\n",
        "  lower = max(0.0, np.percentile(stats, p))\n",
        "  p = (alpha+((1.0-alpha)/2.0)) * 100\n",
        "  upper = min(1.0, np.percentile(stats, p))\n",
        "  main = np.mean(stats)\n",
        "  #print('%.1f confidence interval %.1f%% and %.1f%%' % (alpha*100, lower*100, upper*100))\n",
        "  return main, np.max([main-lower, upper-main])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ysnlzZFAZ8T"
      },
      "source": [
        "def bootstrap(X_test, y_test, X_valid, y_valid):\n",
        "  from sklearn.utils import resample\n",
        "  from matplotlib import pyplot\n",
        "  values = np.concatenate((X_test, y_test.reshape((len(y_test), 1))), axis=1)\n",
        "  n_iterations = 100\n",
        "  n_size = int(len(y_test) * 0.50)\n",
        "  stats = list()\n",
        "  for i in range(n_iterations):\n",
        "    train_ind = np.random.randint(0, len(values), n_size)\n",
        "    test_ind = np.setdiff1d(range(len(values)), train_ind)\n",
        "    train = values[train_ind]\n",
        "    test = values[test_ind]\n",
        "    # fit model\n",
        "    model = lgb.LGBMClassifier()\n",
        "    model.fit(train[:,:-1], train[:,-1], eval_set=[(train[:,:-1], train[:,-1]), (X_valid, y_valid)], **lgb_fit_params)\n",
        "    # evaluate model\n",
        "    predictions = model.predict(test[:,:-1])\n",
        "    test = resample(values, n_samples=n_size)\n",
        "    predictions = model.predict(test[:,:-1])\n",
        "    score = accuracy_score(test[:,-1], predictions)\n",
        "    stats.append(score)\n",
        "  alpha = 0.97\n",
        "  p = ((1.0-alpha)/2.0) * 100\n",
        "  lower = max(0.0, np.percentile(stats, p))\n",
        "  p = (alpha+((1.0-alpha)/2.0)) * 100\n",
        "  upper = min(1.0, np.percentile(stats, p))\n",
        "  main = np.mean(stats)\n",
        "  #print('%.1f confidence interval %.1f%% and %.1f%%' % (alpha*100, lower*100, upper*100))\n",
        "  return main, np.max([main-lower, upper-main])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0pUcz3TxaRJ"
      },
      "source": [
        "def feature_acc(model, str_m, Rows):\n",
        "  print(str_m)\n",
        "\n",
        "  feature_imp=pd.DataFrame((zip(model.feature_importances_, photo_columns+agr_feature)), columns=['Model','Feature'])\n",
        "  t = 3\n",
        "  feature = feature_imp.sort_values(by='Model', ascending=False).iloc[:t]['Feature'].values\n",
        "  X = df[feature].values\n",
        "\n",
        "  data_split = data_preparation(X, y, Rows, 0.8)\n",
        "  count = Rows//3\n",
        "\n",
        "  X_train, X_test = data_split[:2]\n",
        "  y_train, y_test = data_split[2:4]\n",
        "  train = np.concatenate((X_train, y_train.reshape((len(y_train), 1))), axis=1)\n",
        "  np.random.shuffle(train)\n",
        "\n",
        "  X_train, y_train = train[:,:-1], train[:,-1].astype('int')\n",
        "  X1_train, X1_test = data_split[4:6]\n",
        "  y1_train, y1_test = data_split[6:8]\n",
        "  X2_train, X2_test = data_split[8:10] \n",
        "  y2_train, y2_test = data_split[10:12]\n",
        "  X3_train, X3_test = data_split[12:14]\n",
        "  y3_train, y3_test = data_split[14:16]\n",
        "\n",
        "  X_valid   = np.concatenate((X1_test[count : 2*count], X2_test[count : 2*count], X3_test[count : 2*count]))\n",
        "  y_valid   = np.concatenate((y1_test[count : 2*count], y2_test[count : 2*count], y3_test[count : 2*count]))\n",
        "\n",
        "  robust = RobustScaler()\n",
        "\n",
        "  X_train_norm = robust.fit_transform(X_train)\n",
        "  X_test_norm = robust.transform(X_test)\n",
        "  X_valid_norm = robust.transform(X_valid)\n",
        "\n",
        "  acc, err = bootstrap(X_test_norm, y_test, X_valid_norm, y_valid)\n",
        "  with open('/content/drive/MyDrive/Научная работа/Data/hyperparametrs.txt', 'a') as f:\n",
        "    f.write('acc_feature '+str_m+': '+str(acc)+'+-'+str(err)+', ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUaTn8q9wItC"
      },
      "source": [
        "def ones(number_exp, Rows, Nd,\tNa,\tB,\tBV,\tmB,\tλsparse,\tNsteps,\tγ, learning_rate,\tdecay_rate,\tdecay_iterations,\tshared, decision, mask_type):\n",
        "  \n",
        "  with open('/content/drive/MyDrive/Научная работа/Data/hyperparametrs.txt', 'a') as f:\n",
        "    f.write('number: '+str(number_exp)+', ')\n",
        "  \n",
        "  #data\n",
        "  data_split = data_preparation(X, y, c=Rows//3)\n",
        "\n",
        "  X_train, X_test = data_split[:2]\n",
        "  y_train, y_test = data_split[2:4]\n",
        "\n",
        "  train = np.concatenate((X_train, y_train.reshape((len(y_train), 1))), axis=1)\n",
        "  np.random.shuffle(train)\n",
        "  X_train, y_train = train[:,:-1], train[:,-1].astype('int')\n",
        "\n",
        "  count = Rows//3\n",
        "\n",
        "  X1_train, X1_test = data_split[4:6]\n",
        "  y1_train, y1_test = data_split[6:8]\n",
        "  X2_train, X2_test = data_split[8:10] \n",
        "  y2_train, y2_test = data_split[10:12]\n",
        "  X3_train, X3_test = data_split[12:14]\n",
        "  y3_train, y3_test = data_split[14:16]\n",
        "\n",
        "  X_train_pred = np.concatenate((X1_test[2*count : 4*count], X2_test[2*count : 4*count], X3_test[2*count : 4*count])) ###############\n",
        "  X_val_pred   = np.concatenate((X1_test[count : 2*count], X2_test[count : 2*count], X3_test[count : 2*count]))\n",
        "  np.random.shuffle(X_train_pred)\n",
        "  np.random.shuffle(X_val_pred)\n",
        "\n",
        "  X_valid      = np.concatenate((X1_test[4*count : 5*count], X2_test[4*count : 5*count], X3_test[4*count : 5*count]))\n",
        "  y_valid      = np.concatenate((y1_test[4*count : 5*count], y2_test[4*count : 5*count], y3_test[4*count : 5*count]))\n",
        "\n",
        "  robust = RobustScaler()\n",
        "\n",
        "  X_train_norm = robust.fit_transform(X_train)\n",
        "  X_test_norm = robust.transform(X_test)\n",
        "  X_valid_norm = robust.transform(X_valid)\n",
        "\n",
        "\n",
        "  #classifier\n",
        "  tn = TabNetClassifier( n_d=Nd, n_a=Na,\n",
        "                          n_shared=shared, n_independent=decision,\n",
        "                          momentum=mB,\n",
        "                          optimizer_fn=torch.optim.Adam,\n",
        "                          optimizer_params=dict(lr=learning_rate),\n",
        "                          scheduler_params={\"step_size\":decay_iterations, # how to use learning rate scheduler\n",
        "                                            \"gamma\":decay_rate},\n",
        "                          scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
        "\n",
        "                          mask_type=mask_type,\n",
        "                          **{ 'gamma': γ,\n",
        "                              'lambda_sparse':λsparse,\n",
        "                              'n_steps': Nsteps}\n",
        "\n",
        "  )\n",
        "\n",
        "  max_epochs = 2000\n",
        "\n",
        "  patience=50\n",
        "  t = time()\n",
        "  tn.fit(\n",
        "      X_train=X_train, y_train=y_train,\n",
        "      #X_valid=X_valid, y_valid=y_valid,\n",
        "      eval_set=[(X_train, y_train), (X_test, y_test)],\n",
        "      eval_name=['train', 'valid'],\n",
        "      eval_metric=['logloss','accuracy'],\n",
        "      max_epochs=max_epochs , patience=patience,\n",
        "      batch_size=B, virtual_batch_size=BV,\n",
        "  ) \n",
        "  t = time()-t\n",
        "  with open('/content/drive/MyDrive/Научная работа/Data/hyperparametrs.txt', 'a') as f:\n",
        "    f.write('time TN: '+str(t)+', ')\n",
        "\n",
        "  gb = lgb.LGBMClassifier(  #ЛУЧШАЯ МОДЕЛЬ\n",
        "    **{'learning_rate': 0.0741521019613115,\n",
        "    'min_child_samples': 9+1,\n",
        "    'min_child_weight': 0.43858057836890685,\n",
        "    'n_estimators': 1000,\n",
        "    'num_leaves': 59+10}\n",
        "  )\n",
        "\n",
        "  t = time()\n",
        "  gb.fit(X_train_norm, y_train, eval_set=[(X_train_norm, y_train), (X_valid_norm, y_valid)],  **lgb_fit_params)\n",
        "  t = time()-t\n",
        "  with open('/content/drive/MyDrive/Научная работа/Data/hyperparametrs.txt', 'a') as f:\n",
        "    f.write('time GB: '+str(t)+', ')\n",
        "\n",
        "  #Accuracy\n",
        "  acc, err = bootstrap_accuracy(tn, X_test, y_test)\n",
        "  with open('/content/drive/MyDrive/Научная работа/Data/hyperparametrs.txt', 'a') as f:\n",
        "    f.write('acc TN: '+str(acc)+'+-'+str(err)+', ')\n",
        "  acc, err = bootstrap_accuracy(gb, X_test_norm, y_test)\n",
        "  with open('/content/drive/MyDrive/Научная работа/Data/hyperparametrs.txt', 'a') as f:\n",
        "    f.write('acc GB: '+str(acc)+'+-'+str(err)+', ')\n",
        "\n",
        "  #Feature importance\n",
        "  feature_acc(tn, 'TN', 9000)\n",
        "  feature_acc(gb, 'GB', 9000)\n",
        "\n",
        "  #save model\n",
        "\n",
        "  with open('/content/drive/MyDrive/Научная работа/Data/hyperparametrs.txt', 'a') as f:\n",
        "    f.write('\\n')\n",
        "  gb.booster_.save_model('/content/drive/MyDrive/Научная работа/Data/hyper/gb'+str(number_exp)+'.txt')\n",
        "  tn.save_model('/content/drive/MyDrive/Научная работа/Data/hyper/tn'+str(number_exp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BnB1167-DZ0"
      },
      "source": [
        "ones(number_exp=0, \n",
        "     Rows=30000, \n",
        "     Nd=64,\tNa=64,\t\n",
        "     B=2048,\tBV=512,\tmB=0.7,\t\n",
        "     λsparse=0.001,\tNsteps=3,\tγ=1.5, \n",
        "     learning_rate=0.02,\tdecay_rate=0.95,\tdecay_iterations=200,\t\n",
        "     shared=2, decision=2, \n",
        "     mask_type='entmax')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WQUysI2_Qfu"
      },
      "source": [
        "ones(number_exp=1, \n",
        "     Rows=30000, \n",
        "     Nd=64,\tNa=64,\t\n",
        "     B=2048,\tBV=512,\tmB=0.7,\t\n",
        "     λsparse=0.001,\tNsteps=5,\tγ=1.5, \n",
        "     learning_rate=0.02,\tdecay_rate=0.95,\tdecay_iterations=200,\t\n",
        "     shared=2, decision=2, \n",
        "     mask_type='entmax')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU_4XW1cErKy"
      },
      "source": [
        "ones(number_exp=2, \n",
        "     Rows=30000, \n",
        "     Nd=64,\tNa=64,\t\n",
        "     B=2048,\tBV=512,\tmB=0.7,\t\n",
        "     λsparse=0.001,\tNsteps=5,\tγ=1.5, \n",
        "     learning_rate=0.02,\tdecay_rate=0.95,\tdecay_iterations=20,\t\n",
        "     shared=2, decision=2, \n",
        "     mask_type='entmax')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7G1oUnsFPdU"
      },
      "source": [
        "ones(number_exp=3, \n",
        "     Rows=30000, \n",
        "     Nd=32,\tNa=32,\t\n",
        "     B=2048,\tBV=512,\tmB=0.7,\t\n",
        "     λsparse=0.001,\tNsteps=3,\tγ=1.5, \n",
        "     learning_rate=0.02,\tdecay_rate=0.95,\tdecay_iterations=200,\t\n",
        "     shared=2, decision=2, \n",
        "     mask_type='entmax')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_UFQFX_FZMH"
      },
      "source": [
        "ones(number_exp=4, \n",
        "     Rows=30000, \n",
        "     Nd=16,\tNa=16,\t\n",
        "     B=2048,\tBV=512,\tmB=0.7,\t\n",
        "     λsparse=0.001,\tNsteps=3,\tγ=1.5, \n",
        "     learning_rate=0.02,\tdecay_rate=0.95,\tdecay_iterations=200,\t\n",
        "     shared=2, decision=2, \n",
        "     mask_type='entmax')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9pxDTlfHi-Q"
      },
      "source": [
        "ones(number_exp=5, \n",
        "     Rows=30000, \n",
        "     Nd=64,\tNa=64,\t\n",
        "     B=2048,\tBV=512,\tmB=0.7,\t\n",
        "     λsparse=0.001,\tNsteps=5,\tγ=1.7, \n",
        "     learning_rate=0.02,\tdecay_rate=0.95,\tdecay_iterations=20,\t\n",
        "     shared=2, decision=2, \n",
        "     mask_type='entmax')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkLeovCoHp2P"
      },
      "source": [
        "ones(number_exp=6, \n",
        "     Rows=30000, \n",
        "     Nd=64,\tNa=64,\t\n",
        "     B=2048,\tBV=512,\tmB=0.7,\t\n",
        "     λsparse=0.001,\tNsteps=3,\tγ=1.2, \n",
        "     learning_rate=0.02,\tdecay_rate=0.95,\tdecay_iterations=20,\t\n",
        "     shared=2, decision=2, \n",
        "     mask_type='entmax')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9w7lgB0IYng"
      },
      "source": [
        "ones(number_exp=7, \n",
        "     Rows=30000, \n",
        "     Nd=128,\tNa=128,\t\n",
        "     B=2048,\tBV=512,\tmB=0.7,\t\n",
        "     λsparse=0.001,\tNsteps=3,\tγ=1.5, \n",
        "     learning_rate=0.02,\tdecay_rate=0.95,\tdecay_iterations=20,\t\n",
        "     shared=2, decision=2, \n",
        "     mask_type='entmax')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFy9iLyKIlVO"
      },
      "source": [
        "ones(number_exp=8, \n",
        "     Rows=30000, \n",
        "     Nd=128,\tNa=128,\t\n",
        "     B=2048,\tBV=512,\tmB=0.7,\t\n",
        "     λsparse=0.001,\tNsteps=5,\tγ=1.5, \n",
        "     learning_rate=0.02,\tdecay_rate=0.95,\tdecay_iterations=20,\t\n",
        "     shared=2, decision=2, \n",
        "     mask_type='entmax')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YzTgGm7JB0s"
      },
      "source": [
        "ones(number_exp=9, \n",
        "     Rows=30000, \n",
        "     Nd=64,\tNa=64,\t\n",
        "     B=2048,\tBV=512,\tmB=0.7,\t\n",
        "     λsparse=0.001,\tNsteps=7,\tγ=1.5, \n",
        "     learning_rate=0.02,\tdecay_rate=0.95,\tdecay_iterations=20,\t\n",
        "     shared=2, decision=2, \n",
        "     mask_type='entmax')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weawcLGoJaYl"
      },
      "source": [
        "ones(number_exp=10, \n",
        "     Rows=9000, \n",
        "     Nd=64,\tNa=64,\t\n",
        "     B=512,\tBV=128,\tmB=0.7,\t\n",
        "     λsparse=0.001,\tNsteps=5,\tγ=1.5, \n",
        "     learning_rate=0.02,\tdecay_rate=0.95,\tdecay_iterations=200,\t\n",
        "     shared=2, decision=2, \n",
        "     mask_type='entmax')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhZ__ntF_hOu"
      },
      "source": [
        "  number_exp=11\n",
        "  Rows=30000\n",
        "  Nd=64\n",
        "  Na=64\t\n",
        "  B=512\n",
        "  BV=128\n",
        "  mB=0.7\t\n",
        "  λsparse=0.001\n",
        "  Nsteps=5\n",
        "  γ=1.5 \n",
        "  learning_rate=0.02\n",
        "  decay_rate=0.95\n",
        "  decay_iterations=200\t\n",
        "  shared=2\n",
        "  decision=2\n",
        "  mask_type='entmax'\n",
        "\n",
        "  with open('/content/drive/MyDrive/Научная работа/Data/hyperparametrs.txt', 'a') as f:\n",
        "    f.write('number: '+str(11)+', ')\n",
        "  \n",
        "  #data\n",
        "  data_split = data_preparation(X, y, c=Rows//3)\n",
        "\n",
        "  X_train, X_test = data_split[:2]\n",
        "  y_train, y_test = data_split[2:4]\n",
        "\n",
        "  train = np.concatenate((X_train, y_train.reshape((len(y_train), 1))), axis=1)\n",
        "  np.random.shuffle(train)\n",
        "  X_train, y_train = train[:,:-1], train[:,-1].astype('int')\n",
        "\n",
        "  count = Rows//3\n",
        "\n",
        "  X1_train, X1_test = data_split[4:6]\n",
        "  y1_train, y1_test = data_split[6:8]\n",
        "  X2_train, X2_test = data_split[8:10] \n",
        "  y2_train, y2_test = data_split[10:12]\n",
        "  X3_train, X3_test = data_split[12:14]\n",
        "  y3_train, y3_test = data_split[14:16]\n",
        "\n",
        "  X_train_pred = np.concatenate((X1_test[2*count : 4*count], X2_test[2*count : 4*count], X3_test[2*count : 4*count])) ###############\n",
        "  X_val_pred   = np.concatenate((X1_test[count : 2*count], X2_test[count : 2*count], X3_test[count : 2*count]))\n",
        "  np.random.shuffle(X_train_pred)\n",
        "  np.random.shuffle(X_val_pred)\n",
        "\n",
        "  X_valid      = np.concatenate((X1_test[4*count : 5*count], X2_test[4*count : 5*count], X3_test[4*count : 5*count]))\n",
        "  y_valid      = np.concatenate((y1_test[4*count : 5*count], y2_test[4*count : 5*count], y3_test[4*count : 5*count]))\n",
        "\n",
        "  robust = RobustScaler()\n",
        "\n",
        "  X_train_norm = robust.fit_transform(X_train)\n",
        "  X_test_norm = robust.transform(X_test)\n",
        "  X_valid_norm = robust.transform(X_valid)\n",
        "\n",
        "\n",
        "  #classifier\n",
        "  tn = TabNetClassifier( n_d=Nd, n_a=Na,\n",
        "                          n_shared=shared, n_independent=decision,\n",
        "                          momentum=mB,\n",
        "                          optimizer_fn=torch.optim.Adam,\n",
        "                          optimizer_params=dict(lr=learning_rate),\n",
        "                          scheduler_params={\"step_size\":decay_iterations, # how to use learning rate scheduler\n",
        "                                            \"gamma\":decay_rate},\n",
        "                          scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
        "\n",
        "                          mask_type=mask_type,\n",
        "                          **{ 'gamma': γ,\n",
        "                              'lambda_sparse':λsparse,\n",
        "                              'n_steps': Nsteps}\n",
        "\n",
        "  )\n",
        "\n",
        "  max_epochs = 2000\n",
        "  t = time()\n",
        "  tn.fit(\n",
        "      X_train=X_train, y_train=y_train,\n",
        "      #X_valid=X_valid, y_valid=y_valid,\n",
        "      eval_set=[(X_train, y_train), (X_test, y_test)],\n",
        "      eval_name=['train', 'valid'],\n",
        "      eval_metric=['logloss','accuracy'],\n",
        "      max_epochs=max_epochs , patience=20,\n",
        "      batch_size=B, virtual_batch_size=BV,\n",
        "  ) \n",
        "  t = time()-t\n",
        "  with open('/content/drive/MyDrive/Научная работа/Data/hyperparametrs.txt', 'a') as f:\n",
        "    f.write('time TN: '+str(t)+', ')\n",
        "\n",
        "  gb = lgb.LGBMClassifier(  #ЛУЧШАЯ МОДЕЛЬ\n",
        "    **{'colsample_bytree': 0.6437405148446416,\n",
        "    'learning_rate': 0.0741521019613115,\n",
        "    'min_child_samples': 9+1,\n",
        "    'min_child_weight': 0.43858057836890685,\n",
        "    'n_estimators': 100,\n",
        "    'num_leaves': 59+10}\n",
        "  )\n",
        "\n",
        "  t = time()\n",
        "  gb.fit(X_train_norm, y_train, eval_set=[(X_train_norm, y_train), (X_valid_norm, y_valid)],  **lgb_fit_params)\n",
        "  t = time()-t\n",
        "  with open('/content/drive/MyDrive/Научная работа/Data/hyperparametrs.txt', 'a') as f:\n",
        "    f.write('time GB: '+str(t)+', ')\n",
        "\n",
        "  #Accuracy\n",
        "  acc, err = bootstrap_accuracy(tn, X_test, y_test)\n",
        "  with open('/content/drive/MyDrive/Научная работа/Data/hyperparametrs.txt', 'a') as f:\n",
        "    f.write('acc TN: '+str(acc)+'+-'+str(err)+', ')\n",
        "  acc, err = bootstrap_accuracy(gb, X_test_norm, y_test)\n",
        "  with open('/content/drive/MyDrive/Научная работа/Data/hyperparametrs.txt', 'a') as f:\n",
        "    f.write('acc GB: '+str(acc)+'+-'+str(err)+', ')\n",
        "\n",
        "  #Feature importance\n",
        "  feature_acc(tn, 'TN', Rows)\n",
        "  feature_acc(gb, 'GB', Rows)\n",
        "\n",
        "  #save model\n",
        "\n",
        "  with open('/content/drive/MyDrive/Научная работа/Data/hyperparametrs.txt', 'a') as f:\n",
        "    f.write('\\n')\n",
        "  gb.booster_.save_model('/content/drive/MyDrive/Научная работа/Data/hyper/gb'+str(number_exp)+'.txt')\n",
        "  tn.save_model('/content/drive/MyDrive/Научная работа/Data/hyper/tn'+str(number_exp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdmZ-Md1uTFA"
      },
      "source": [
        "ones(number_exp=12, \n",
        "     Rows=30000, \n",
        "     Nd=16,\tNa=16,\t\n",
        "     B=2048,\tBV=512,\tmB=0.7,\t\n",
        "     λsparse=0.001,\tNsteps=3,\tγ=1.5, \n",
        "     learning_rate=0.02,\tdecay_rate=0.95,\tdecay_iterations=200,\t\n",
        "     shared=2, decision=2, \n",
        "     mask_type='sparsemax')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ldqGo0H1-Gq"
      },
      "source": [
        "ones(number_exp=13, \n",
        "     Rows=30000, \n",
        "     Nd=16,\tNa=16,\t\n",
        "     B=2048,\tBV=128,\tmB=0.7,\t\n",
        "     λsparse=0.001,\tNsteps=3,\tγ=1.2, \n",
        "     learning_rate=0.02,\tdecay_rate=0.95,\tdecay_iterations=200,\t\n",
        "     shared=2, decision=2, \n",
        "     mask_type='entmax')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yeKGjsIi6NLC",
        "outputId": "fd218ec2-bf6b-473d-c4e3-7dea7e527628"
      },
      "source": [
        "ones(number_exp=14, \n",
        "     Rows=300000, \n",
        "     Nd=16,\tNa=16,\t\n",
        "     B=16384,\tBV=512,\tmB=0.7,\t\n",
        "     λsparse=0.001,\tNsteps=3,\tγ=1.2, \n",
        "     learning_rate=0.02,\tdecay_rate=0.95,\tdecay_iterations=200,\t\n",
        "     shared=2, decision=2, \n",
        "     mask_type='entmax')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device used : cuda\n",
            "epoch 0  | loss: 0.64086 | train_logloss: 8.10103 | train_accuracy: 0.32102 | valid_logloss: 8.10236 | valid_accuracy: 0.32096 |  0:00:11s\n",
            "epoch 1  | loss: 0.36108 | train_logloss: 2.46956 | train_accuracy: 0.50289 | valid_logloss: 2.47166 | valid_accuracy: 0.50304 |  0:00:23s\n",
            "epoch 2  | loss: 0.33227 | train_logloss: 6.48805 | train_accuracy: 0.18171 | valid_logloss: 6.4795  | valid_accuracy: 0.18392 |  0:00:34s\n",
            "epoch 3  | loss: 0.3219  | train_logloss: 2.64671 | train_accuracy: 0.35143 | valid_logloss: 2.64231 | valid_accuracy: 0.35206 |  0:00:46s\n",
            "epoch 4  | loss: 0.31253 | train_logloss: 2.006   | train_accuracy: 0.37547 | valid_logloss: 2.00072 | valid_accuracy: 0.37642 |  0:00:58s\n",
            "epoch 5  | loss: 0.30635 | train_logloss: 2.46675 | train_accuracy: 0.22537 | valid_logloss: 2.46554 | valid_accuracy: 0.22494 |  0:01:10s\n",
            "epoch 6  | loss: 0.30025 | train_logloss: 1.67759 | train_accuracy: 0.33518 | valid_logloss: 1.67998 | valid_accuracy: 0.335   |  0:01:21s\n",
            "epoch 7  | loss: 0.29606 | train_logloss: 1.37041 | train_accuracy: 0.32466 | valid_logloss: 1.37006 | valid_accuracy: 0.3252  |  0:01:33s\n",
            "epoch 8  | loss: 0.29715 | train_logloss: 1.25631 | train_accuracy: 0.57986 | valid_logloss: 1.25645 | valid_accuracy: 0.58004 |  0:01:44s\n",
            "epoch 9  | loss: 0.29115 | train_logloss: 1.00233 | train_accuracy: 0.54976 | valid_logloss: 1.00425 | valid_accuracy: 0.54947 |  0:01:56s\n",
            "epoch 10 | loss: 0.289   | train_logloss: 0.9474  | train_accuracy: 0.50338 | valid_logloss: 0.9479  | valid_accuracy: 0.50384 |  0:02:08s\n",
            "epoch 11 | loss: 0.28694 | train_logloss: 0.73253 | train_accuracy: 0.67307 | valid_logloss: 0.73189 | valid_accuracy: 0.67443 |  0:02:19s\n",
            "epoch 12 | loss: 0.28437 | train_logloss: 0.59925 | train_accuracy: 0.77615 | valid_logloss: 0.59874 | valid_accuracy: 0.7769  |  0:02:31s\n",
            "epoch 13 | loss: 0.2805  | train_logloss: 0.5343  | train_accuracy: 0.77756 | valid_logloss: 0.53517 | valid_accuracy: 0.77727 |  0:02:42s\n",
            "epoch 14 | loss: 0.2795  | train_logloss: 0.43529 | train_accuracy: 0.84057 | valid_logloss: 0.43752 | valid_accuracy: 0.83973 |  0:02:54s\n",
            "epoch 15 | loss: 0.27787 | train_logloss: 0.41698 | train_accuracy: 0.84283 | valid_logloss: 0.41994 | valid_accuracy: 0.84094 |  0:03:06s\n",
            "epoch 16 | loss: 0.27752 | train_logloss: 0.34644 | train_accuracy: 0.87372 | valid_logloss: 0.34993 | valid_accuracy: 0.87342 |  0:03:17s\n",
            "epoch 17 | loss: 0.27703 | train_logloss: 0.32697 | train_accuracy: 0.87683 | valid_logloss: 0.33077 | valid_accuracy: 0.87604 |  0:03:29s\n",
            "epoch 18 | loss: 0.27499 | train_logloss: 0.31103 | train_accuracy: 0.88402 | valid_logloss: 0.31474 | valid_accuracy: 0.88328 |  0:03:41s\n",
            "epoch 19 | loss: 0.27477 | train_logloss: 0.29385 | train_accuracy: 0.88787 | valid_logloss: 0.29882 | valid_accuracy: 0.88707 |  0:03:52s\n",
            "epoch 20 | loss: 0.27414 | train_logloss: 0.28358 | train_accuracy: 0.89175 | valid_logloss: 0.2889  | valid_accuracy: 0.89118 |  0:04:04s\n",
            "epoch 21 | loss: 0.2751  | train_logloss: 0.28057 | train_accuracy: 0.89243 | valid_logloss: 0.28616 | valid_accuracy: 0.89188 |  0:04:16s\n",
            "epoch 22 | loss: 0.27276 | train_logloss: 0.27935 | train_accuracy: 0.89344 | valid_logloss: 0.28499 | valid_accuracy: 0.89217 |  0:04:27s\n",
            "epoch 23 | loss: 0.27201 | train_logloss: 0.27365 | train_accuracy: 0.89435 | valid_logloss: 0.27986 | valid_accuracy: 0.8931  |  0:04:39s\n",
            "epoch 24 | loss: 0.2716  | train_logloss: 0.27009 | train_accuracy: 0.89644 | valid_logloss: 0.27792 | valid_accuracy: 0.89521 |  0:04:50s\n",
            "epoch 25 | loss: 0.27071 | train_logloss: 0.26808 | train_accuracy: 0.89694 | valid_logloss: 0.2749  | valid_accuracy: 0.89554 |  0:05:02s\n",
            "epoch 26 | loss: 0.26976 | train_logloss: 0.26775 | train_accuracy: 0.89756 | valid_logloss: 0.27523 | valid_accuracy: 0.89585 |  0:05:14s\n",
            "epoch 27 | loss: 0.26892 | train_logloss: 0.26664 | train_accuracy: 0.89829 | valid_logloss: 0.27427 | valid_accuracy: 0.89689 |  0:05:25s\n",
            "epoch 28 | loss: 0.26798 | train_logloss: 0.26578 | train_accuracy: 0.89828 | valid_logloss: 0.27376 | valid_accuracy: 0.89655 |  0:05:37s\n",
            "epoch 29 | loss: 0.26771 | train_logloss: 0.26603 | train_accuracy: 0.89842 | valid_logloss: 0.27325 | valid_accuracy: 0.89666 |  0:05:48s\n",
            "epoch 30 | loss: 0.2675  | train_logloss: 0.27122 | train_accuracy: 0.89509 | valid_logloss: 0.27969 | valid_accuracy: 0.8934  |  0:06:00s\n",
            "epoch 31 | loss: 0.26728 | train_logloss: 0.26746 | train_accuracy: 0.89727 | valid_logloss: 0.27523 | valid_accuracy: 0.89561 |  0:06:11s\n",
            "epoch 32 | loss: 0.26766 | train_logloss: 0.26536 | train_accuracy: 0.89856 | valid_logloss: 0.27308 | valid_accuracy: 0.89726 |  0:06:23s\n",
            "epoch 33 | loss: 0.26641 | train_logloss: 0.26303 | train_accuracy: 0.89957 | valid_logloss: 0.27089 | valid_accuracy: 0.8981  |  0:06:35s\n",
            "epoch 34 | loss: 0.26547 | train_logloss: 0.25993 | train_accuracy: 0.90002 | valid_logloss: 0.26836 | valid_accuracy: 0.89846 |  0:06:46s\n",
            "epoch 35 | loss: 0.26479 | train_logloss: 0.26251 | train_accuracy: 0.89933 | valid_logloss: 0.27137 | valid_accuracy: 0.89791 |  0:06:58s\n",
            "epoch 36 | loss: 0.26746 | train_logloss: 0.26253 | train_accuracy: 0.89904 | valid_logloss: 0.27042 | valid_accuracy: 0.89728 |  0:07:09s\n",
            "epoch 37 | loss: 0.26515 | train_logloss: 0.25955 | train_accuracy: 0.90052 | valid_logloss: 0.26842 | valid_accuracy: 0.89888 |  0:07:21s\n",
            "epoch 38 | loss: 0.26358 | train_logloss: 0.25905 | train_accuracy: 0.90093 | valid_logloss: 0.26724 | valid_accuracy: 0.89879 |  0:07:33s\n",
            "epoch 39 | loss: 0.26365 | train_logloss: 0.25997 | train_accuracy: 0.90054 | valid_logloss: 0.26909 | valid_accuracy: 0.89849 |  0:07:45s\n",
            "epoch 40 | loss: 0.26298 | train_logloss: 0.26022 | train_accuracy: 0.90012 | valid_logloss: 0.26992 | valid_accuracy: 0.89794 |  0:07:56s\n",
            "epoch 41 | loss: 0.26249 | train_logloss: 0.2591  | train_accuracy: 0.90083 | valid_logloss: 0.26834 | valid_accuracy: 0.8985  |  0:08:08s\n",
            "epoch 42 | loss: 0.26285 | train_logloss: 0.25949 | train_accuracy: 0.90056 | valid_logloss: 0.26845 | valid_accuracy: 0.89898 |  0:08:20s\n",
            "epoch 43 | loss: 0.26345 | train_logloss: 0.25892 | train_accuracy: 0.90065 | valid_logloss: 0.26797 | valid_accuracy: 0.89865 |  0:08:31s\n",
            "epoch 44 | loss: 0.26276 | train_logloss: 0.25879 | train_accuracy: 0.90081 | valid_logloss: 0.26739 | valid_accuracy: 0.89917 |  0:08:43s\n",
            "epoch 45 | loss: 0.26189 | train_logloss: 0.25706 | train_accuracy: 0.90139 | valid_logloss: 0.26665 | valid_accuracy: 0.89931 |  0:08:55s\n",
            "epoch 46 | loss: 0.27407 | train_logloss: 0.27994 | train_accuracy: 0.89426 | valid_logloss: 0.28576 | valid_accuracy: 0.89332 |  0:09:06s\n",
            "epoch 47 | loss: 0.27977 | train_logloss: 0.26885 | train_accuracy: 0.89812 | valid_logloss: 0.27578 | valid_accuracy: 0.89706 |  0:09:18s\n",
            "epoch 48 | loss: 0.27234 | train_logloss: 0.26765 | train_accuracy: 0.89813 | valid_logloss: 0.27428 | valid_accuracy: 0.89691 |  0:09:30s\n",
            "epoch 49 | loss: 0.2696  | train_logloss: 0.26223 | train_accuracy: 0.89989 | valid_logloss: 0.26926 | valid_accuracy: 0.89854 |  0:09:41s\n",
            "epoch 50 | loss: 0.26741 | train_logloss: 0.26467 | train_accuracy: 0.89917 | valid_logloss: 0.27117 | valid_accuracy: 0.89801 |  0:09:53s\n",
            "epoch 51 | loss: 0.26643 | train_logloss: 0.26009 | train_accuracy: 0.90068 | valid_logloss: 0.26882 | valid_accuracy: 0.89883 |  0:10:05s\n",
            "epoch 52 | loss: 0.2649  | train_logloss: 0.26173 | train_accuracy: 0.90015 | valid_logloss: 0.2689  | valid_accuracy: 0.89875 |  0:10:16s\n",
            "epoch 53 | loss: 0.26407 | train_logloss: 0.26437 | train_accuracy: 0.89809 | valid_logloss: 0.27286 | valid_accuracy: 0.89608 |  0:10:28s\n",
            "epoch 54 | loss: 0.26378 | train_logloss: 0.25792 | train_accuracy: 0.90124 | valid_logloss: 0.26642 | valid_accuracy: 0.89949 |  0:10:40s\n",
            "epoch 55 | loss: 0.26208 | train_logloss: 0.25714 | train_accuracy: 0.90158 | valid_logloss: 0.26651 | valid_accuracy: 0.89926 |  0:10:51s\n",
            "epoch 56 | loss: 0.26124 | train_logloss: 0.25712 | train_accuracy: 0.90102 | valid_logloss: 0.26632 | valid_accuracy: 0.89917 |  0:11:03s\n",
            "epoch 57 | loss: 0.26196 | train_logloss: 0.25969 | train_accuracy: 0.90063 | valid_logloss: 0.26842 | valid_accuracy: 0.89842 |  0:11:15s\n",
            "epoch 58 | loss: 0.26194 | train_logloss: 0.26053 | train_accuracy: 0.89989 | valid_logloss: 0.26901 | valid_accuracy: 0.89786 |  0:11:26s\n",
            "epoch 59 | loss: 0.26295 | train_logloss: 0.26099 | train_accuracy: 0.90044 | valid_logloss: 0.26892 | valid_accuracy: 0.89839 |  0:11:38s\n",
            "epoch 60 | loss: 0.26327 | train_logloss: 0.25724 | train_accuracy: 0.90175 | valid_logloss: 0.266   | valid_accuracy: 0.89994 |  0:11:49s\n",
            "epoch 61 | loss: 0.26156 | train_logloss: 0.25629 | train_accuracy: 0.90173 | valid_logloss: 0.26535 | valid_accuracy: 0.90003 |  0:12:01s\n",
            "epoch 62 | loss: 0.26033 | train_logloss: 0.25932 | train_accuracy: 0.90123 | valid_logloss: 0.26889 | valid_accuracy: 0.89927 |  0:12:13s\n",
            "epoch 63 | loss: 0.26418 | train_logloss: 0.25984 | train_accuracy: 0.90094 | valid_logloss: 0.26773 | valid_accuracy: 0.899   |  0:12:24s\n",
            "epoch 64 | loss: 0.26147 | train_logloss: 0.25755 | train_accuracy: 0.9017  | valid_logloss: 0.26613 | valid_accuracy: 0.89976 |  0:12:36s\n",
            "epoch 65 | loss: 0.26059 | train_logloss: 0.25733 | train_accuracy: 0.90169 | valid_logloss: 0.2666  | valid_accuracy: 0.89964 |  0:12:47s\n",
            "epoch 66 | loss: 0.25934 | train_logloss: 0.25428 | train_accuracy: 0.90248 | valid_logloss: 0.26367 | valid_accuracy: 0.89989 |  0:12:59s\n",
            "epoch 67 | loss: 0.25905 | train_logloss: 0.25496 | train_accuracy: 0.90208 | valid_logloss: 0.26469 | valid_accuracy: 0.90006 |  0:13:10s\n",
            "epoch 68 | loss: 0.25919 | train_logloss: 0.25701 | train_accuracy: 0.90185 | valid_logloss: 0.26706 | valid_accuracy: 0.89949 |  0:13:22s\n",
            "epoch 69 | loss: 0.25852 | train_logloss: 0.25382 | train_accuracy: 0.90274 | valid_logloss: 0.26324 | valid_accuracy: 0.90054 |  0:13:34s\n",
            "epoch 70 | loss: 0.25904 | train_logloss: 0.25618 | train_accuracy: 0.90149 | valid_logloss: 0.26637 | valid_accuracy: 0.89915 |  0:13:45s\n",
            "epoch 71 | loss: 0.25977 | train_logloss: 0.25323 | train_accuracy: 0.90274 | valid_logloss: 0.26328 | valid_accuracy: 0.90033 |  0:13:57s\n",
            "epoch 72 | loss: 0.25882 | train_logloss: 0.25395 | train_accuracy: 0.90301 | valid_logloss: 0.26364 | valid_accuracy: 0.90044 |  0:14:08s\n",
            "epoch 73 | loss: 0.25726 | train_logloss: 0.25334 | train_accuracy: 0.90207 | valid_logloss: 0.26339 | valid_accuracy: 0.89946 |  0:14:20s\n",
            "epoch 74 | loss: 0.25695 | train_logloss: 0.25258 | train_accuracy: 0.90326 | valid_logloss: 0.26325 | valid_accuracy: 0.90026 |  0:14:32s\n",
            "epoch 75 | loss: 0.25644 | train_logloss: 0.252   | train_accuracy: 0.9032  | valid_logloss: 0.26341 | valid_accuracy: 0.90041 |  0:14:43s\n",
            "epoch 76 | loss: 0.25714 | train_logloss: 0.25308 | train_accuracy: 0.90235 | valid_logloss: 0.26407 | valid_accuracy: 0.90009 |  0:14:55s\n",
            "epoch 77 | loss: 0.25694 | train_logloss: 0.25164 | train_accuracy: 0.90382 | valid_logloss: 0.26223 | valid_accuracy: 0.90081 |  0:15:07s\n",
            "epoch 78 | loss: 0.25609 | train_logloss: 0.25169 | train_accuracy: 0.90325 | valid_logloss: 0.26289 | valid_accuracy: 0.90046 |  0:15:18s\n",
            "epoch 79 | loss: 0.25618 | train_logloss: 0.2508  | train_accuracy: 0.90374 | valid_logloss: 0.263   | valid_accuracy: 0.9007  |  0:15:30s\n",
            "epoch 80 | loss: 0.26295 | train_logloss: 0.25753 | train_accuracy: 0.90127 | valid_logloss: 0.26664 | valid_accuracy: 0.8996  |  0:15:42s\n",
            "epoch 81 | loss: 0.26205 | train_logloss: 0.25799 | train_accuracy: 0.90108 | valid_logloss: 0.26744 | valid_accuracy: 0.89888 |  0:15:53s\n",
            "epoch 82 | loss: 0.25912 | train_logloss: 0.25502 | train_accuracy: 0.90214 | valid_logloss: 0.2649  | valid_accuracy: 0.9     |  0:16:05s\n",
            "epoch 83 | loss: 0.2574  | train_logloss: 0.25444 | train_accuracy: 0.90266 | valid_logloss: 0.2654  | valid_accuracy: 0.89946 |  0:16:17s\n",
            "epoch 84 | loss: 0.25701 | train_logloss: 0.25456 | train_accuracy: 0.90221 | valid_logloss: 0.26551 | valid_accuracy: 0.89942 |  0:16:28s\n",
            "epoch 85 | loss: 0.25611 | train_logloss: 0.25236 | train_accuracy: 0.90329 | valid_logloss: 0.26263 | valid_accuracy: 0.90024 |  0:16:40s\n",
            "epoch 86 | loss: 0.25584 | train_logloss: 0.25166 | train_accuracy: 0.90368 | valid_logloss: 0.26313 | valid_accuracy: 0.90035 |  0:16:52s\n",
            "epoch 87 | loss: 0.25594 | train_logloss: 0.2528  | train_accuracy: 0.90252 | valid_logloss: 0.26388 | valid_accuracy: 0.89948 |  0:17:03s\n",
            "epoch 88 | loss: 0.25664 | train_logloss: 0.25102 | train_accuracy: 0.90365 | valid_logloss: 0.26279 | valid_accuracy: 0.90071 |  0:17:15s\n",
            "epoch 89 | loss: 0.25575 | train_logloss: 0.25105 | train_accuracy: 0.90359 | valid_logloss: 0.26252 | valid_accuracy: 0.90068 |  0:17:26s\n",
            "epoch 90 | loss: 0.25562 | train_logloss: 0.25059 | train_accuracy: 0.90383 | valid_logloss: 0.26323 | valid_accuracy: 0.90039 |  0:17:38s\n",
            "epoch 91 | loss: 0.25473 | train_logloss: 0.25047 | train_accuracy: 0.90369 | valid_logloss: 0.26288 | valid_accuracy: 0.9009  |  0:17:50s\n",
            "epoch 92 | loss: 0.2554  | train_logloss: 0.25876 | train_accuracy: 0.9018  | valid_logloss: 0.27004 | valid_accuracy: 0.89895 |  0:18:01s\n",
            "epoch 93 | loss: 0.25998 | train_logloss: 0.25771 | train_accuracy: 0.902   | valid_logloss: 0.26762 | valid_accuracy: 0.8995  |  0:18:13s\n",
            "epoch 94 | loss: 0.2582  | train_logloss: 0.25438 | train_accuracy: 0.90235 | valid_logloss: 0.26518 | valid_accuracy: 0.89972 |  0:18:25s\n",
            "epoch 95 | loss: 0.25677 | train_logloss: 0.25122 | train_accuracy: 0.90369 | valid_logloss: 0.26251 | valid_accuracy: 0.90049 |  0:18:36s\n",
            "epoch 96 | loss: 0.25649 | train_logloss: 0.25329 | train_accuracy: 0.9029  | valid_logloss: 0.26452 | valid_accuracy: 0.90041 |  0:18:48s\n",
            "epoch 97 | loss: 0.25618 | train_logloss: 0.25074 | train_accuracy: 0.90394 | valid_logloss: 0.26295 | valid_accuracy: 0.90074 |  0:19:00s\n",
            "epoch 98 | loss: 0.25576 | train_logloss: 0.25413 | train_accuracy: 0.90206 | valid_logloss: 0.26509 | valid_accuracy: 0.89953 |  0:19:11s\n",
            "epoch 99 | loss: 0.25545 | train_logloss: 0.25326 | train_accuracy: 0.90205 | valid_logloss: 0.26473 | valid_accuracy: 0.89931 |  0:19:23s\n",
            "epoch 100| loss: 0.25602 | train_logloss: 0.25105 | train_accuracy: 0.90422 | valid_logloss: 0.26317 | valid_accuracy: 0.90111 |  0:19:35s\n",
            "epoch 101| loss: 0.25538 | train_logloss: 0.25332 | train_accuracy: 0.90334 | valid_logloss: 0.26488 | valid_accuracy: 0.90043 |  0:19:46s\n",
            "epoch 102| loss: 0.2555  | train_logloss: 0.25265 | train_accuracy: 0.90276 | valid_logloss: 0.26449 | valid_accuracy: 0.89982 |  0:19:58s\n",
            "epoch 103| loss: 0.25606 | train_logloss: 0.25034 | train_accuracy: 0.90384 | valid_logloss: 0.26275 | valid_accuracy: 0.90102 |  0:20:10s\n",
            "epoch 104| loss: 0.25451 | train_logloss: 0.24893 | train_accuracy: 0.90424 | valid_logloss: 0.26184 | valid_accuracy: 0.90085 |  0:20:21s\n",
            "epoch 105| loss: 0.25419 | train_logloss: 0.25388 | train_accuracy: 0.90201 | valid_logloss: 0.26738 | valid_accuracy: 0.89823 |  0:20:33s\n",
            "epoch 106| loss: 0.25469 | train_logloss: 0.25037 | train_accuracy: 0.90384 | valid_logloss: 0.2625  | valid_accuracy: 0.90045 |  0:20:45s\n",
            "epoch 107| loss: 0.25355 | train_logloss: 0.24879 | train_accuracy: 0.90443 | valid_logloss: 0.26174 | valid_accuracy: 0.90106 |  0:20:56s\n",
            "epoch 108| loss: 0.25254 | train_logloss: 0.24973 | train_accuracy: 0.90403 | valid_logloss: 0.26252 | valid_accuracy: 0.90053 |  0:21:08s\n",
            "epoch 109| loss: 0.25315 | train_logloss: 0.24786 | train_accuracy: 0.90477 | valid_logloss: 0.26193 | valid_accuracy: 0.90119 |  0:21:20s\n",
            "epoch 110| loss: 0.25273 | train_logloss: 0.25067 | train_accuracy: 0.90324 | valid_logloss: 0.26517 | valid_accuracy: 0.89958 |  0:21:32s\n",
            "epoch 111| loss: 0.25279 | train_logloss: 0.24724 | train_accuracy: 0.905   | valid_logloss: 0.26091 | valid_accuracy: 0.90129 |  0:21:43s\n",
            "epoch 112| loss: 0.2546  | train_logloss: 0.25001 | train_accuracy: 0.90416 | valid_logloss: 0.26314 | valid_accuracy: 0.90063 |  0:21:55s\n",
            "epoch 113| loss: 0.25442 | train_logloss: 0.25382 | train_accuracy: 0.90264 | valid_logloss: 0.26771 | valid_accuracy: 0.8988  |  0:22:06s\n",
            "epoch 114| loss: 0.25376 | train_logloss: 0.24889 | train_accuracy: 0.90419 | valid_logloss: 0.26181 | valid_accuracy: 0.90112 |  0:22:18s\n",
            "epoch 115| loss: 0.25314 | train_logloss: 0.25035 | train_accuracy: 0.9039  | valid_logloss: 0.26358 | valid_accuracy: 0.90055 |  0:22:29s\n",
            "epoch 116| loss: 0.25253 | train_logloss: 0.24839 | train_accuracy: 0.90456 | valid_logloss: 0.26231 | valid_accuracy: 0.90086 |  0:22:41s\n",
            "epoch 117| loss: 0.25203 | train_logloss: 0.2477  | train_accuracy: 0.90445 | valid_logloss: 0.26187 | valid_accuracy: 0.90055 |  0:22:53s\n",
            "epoch 118| loss: 0.25131 | train_logloss: 0.2493  | train_accuracy: 0.90386 | valid_logloss: 0.26374 | valid_accuracy: 0.8999  |  0:23:04s\n",
            "epoch 119| loss: 0.25161 | train_logloss: 0.2467  | train_accuracy: 0.90497 | valid_logloss: 0.26207 | valid_accuracy: 0.90072 |  0:23:16s\n",
            "epoch 120| loss: 0.25163 | train_logloss: 0.24792 | train_accuracy: 0.90487 | valid_logloss: 0.26272 | valid_accuracy: 0.90067 |  0:23:28s\n",
            "epoch 121| loss: 0.2521  | train_logloss: 0.2482  | train_accuracy: 0.90462 | valid_logloss: 0.26287 | valid_accuracy: 0.90061 |  0:23:39s\n",
            "epoch 122| loss: 0.25216 | train_logloss: 0.2515  | train_accuracy: 0.90253 | valid_logloss: 0.26714 | valid_accuracy: 0.8985  |  0:23:51s\n",
            "epoch 123| loss: 0.25158 | train_logloss: 0.24709 | train_accuracy: 0.9048  | valid_logloss: 0.2621  | valid_accuracy: 0.90073 |  0:24:03s\n",
            "epoch 124| loss: 0.25066 | train_logloss: 0.24787 | train_accuracy: 0.90476 | valid_logloss: 0.26309 | valid_accuracy: 0.90051 |  0:24:14s\n",
            "epoch 125| loss: 0.25148 | train_logloss: 0.24765 | train_accuracy: 0.9042  | valid_logloss: 0.26232 | valid_accuracy: 0.90059 |  0:24:26s\n",
            "epoch 126| loss: 0.25109 | train_logloss: 0.24702 | train_accuracy: 0.90513 | valid_logloss: 0.26201 | valid_accuracy: 0.90134 |  0:24:38s\n",
            "epoch 127| loss: 0.25129 | train_logloss: 0.24617 | train_accuracy: 0.90547 | valid_logloss: 0.26148 | valid_accuracy: 0.9012  |  0:24:49s\n",
            "epoch 128| loss: 0.25051 | train_logloss: 0.2473  | train_accuracy: 0.90506 | valid_logloss: 0.26265 | valid_accuracy: 0.9008  |  0:25:01s\n",
            "epoch 129| loss: 0.25156 | train_logloss: 0.24674 | train_accuracy: 0.90521 | valid_logloss: 0.26303 | valid_accuracy: 0.90078 |  0:25:12s\n",
            "epoch 130| loss: 0.25183 | train_logloss: 0.24875 | train_accuracy: 0.90445 | valid_logloss: 0.26378 | valid_accuracy: 0.90079 |  0:25:24s\n",
            "epoch 131| loss: 0.25127 | train_logloss: 0.24907 | train_accuracy: 0.90459 | valid_logloss: 0.26459 | valid_accuracy: 0.90037 |  0:25:36s\n",
            "epoch 132| loss: 0.25195 | train_logloss: 0.25075 | train_accuracy: 0.90414 | valid_logloss: 0.26551 | valid_accuracy: 0.90058 |  0:25:47s\n",
            "epoch 133| loss: 0.25211 | train_logloss: 0.24826 | train_accuracy: 0.90432 | valid_logloss: 0.26321 | valid_accuracy: 0.90061 |  0:25:59s\n",
            "epoch 134| loss: 0.25108 | train_logloss: 0.24625 | train_accuracy: 0.90526 | valid_logloss: 0.26206 | valid_accuracy: 0.9011  |  0:26:10s\n",
            "epoch 135| loss: 0.25119 | train_logloss: 0.24645 | train_accuracy: 0.90529 | valid_logloss: 0.26163 | valid_accuracy: 0.90143 |  0:26:22s\n",
            "epoch 136| loss: 0.24974 | train_logloss: 0.24651 | train_accuracy: 0.90578 | valid_logloss: 0.26233 | valid_accuracy: 0.90127 |  0:26:34s\n",
            "epoch 137| loss: 0.25024 | train_logloss: 0.24763 | train_accuracy: 0.9049  | valid_logloss: 0.26518 | valid_accuracy: 0.90027 |  0:26:45s\n",
            "epoch 138| loss: 0.25031 | train_logloss: 0.24513 | train_accuracy: 0.90558 | valid_logloss: 0.26194 | valid_accuracy: 0.90096 |  0:26:57s\n",
            "epoch 139| loss: 0.25005 | train_logloss: 0.24529 | train_accuracy: 0.90557 | valid_logloss: 0.2626  | valid_accuracy: 0.90093 |  0:27:08s\n",
            "epoch 140| loss: 0.24966 | train_logloss: 0.24727 | train_accuracy: 0.90486 | valid_logloss: 0.2624  | valid_accuracy: 0.90046 |  0:27:20s\n",
            "epoch 141| loss: 0.25107 | train_logloss: 0.24861 | train_accuracy: 0.90456 | valid_logloss: 0.26445 | valid_accuracy: 0.90054 |  0:27:32s\n",
            "epoch 142| loss: 0.25049 | train_logloss: 0.24543 | train_accuracy: 0.90563 | valid_logloss: 0.26183 | valid_accuracy: 0.90116 |  0:27:43s\n",
            "epoch 143| loss: 0.24985 | train_logloss: 0.24627 | train_accuracy: 0.90549 | valid_logloss: 0.26271 | valid_accuracy: 0.90105 |  0:27:55s\n",
            "epoch 144| loss: 0.25032 | train_logloss: 0.24633 | train_accuracy: 0.9053  | valid_logloss: 0.26308 | valid_accuracy: 0.90105 |  0:28:07s\n",
            "epoch 145| loss: 0.25005 | train_logloss: 0.24854 | train_accuracy: 0.90477 | valid_logloss: 0.2634  | valid_accuracy: 0.9005  |  0:28:18s\n",
            "epoch 146| loss: 0.25004 | train_logloss: 0.24697 | train_accuracy: 0.90508 | valid_logloss: 0.26301 | valid_accuracy: 0.90083 |  0:28:30s\n",
            "epoch 147| loss: 0.25002 | train_logloss: 0.24716 | train_accuracy: 0.90416 | valid_logloss: 0.26388 | valid_accuracy: 0.89988 |  0:28:42s\n",
            "epoch 148| loss: 0.24983 | train_logloss: 0.2454  | train_accuracy: 0.90593 | valid_logloss: 0.26243 | valid_accuracy: 0.90109 |  0:28:53s\n",
            "epoch 149| loss: 0.2501  | train_logloss: 0.24551 | train_accuracy: 0.90537 | valid_logloss: 0.26266 | valid_accuracy: 0.90082 |  0:29:05s\n",
            "epoch 150| loss: 0.2498  | train_logloss: 0.24679 | train_accuracy: 0.90524 | valid_logloss: 0.26389 | valid_accuracy: 0.90006 |  0:29:17s\n",
            "epoch 151| loss: 0.25099 | train_logloss: 0.24869 | train_accuracy: 0.90492 | valid_logloss: 0.26615 | valid_accuracy: 0.90031 |  0:29:29s\n",
            "epoch 152| loss: 0.25254 | train_logloss: 0.24839 | train_accuracy: 0.90423 | valid_logloss: 0.26341 | valid_accuracy: 0.89981 |  0:29:40s\n",
            "epoch 153| loss: 0.2516  | train_logloss: 0.2474  | train_accuracy: 0.90446 | valid_logloss: 0.26432 | valid_accuracy: 0.90015 |  0:29:52s\n",
            "epoch 154| loss: 0.25058 | train_logloss: 0.24443 | train_accuracy: 0.90612 | valid_logloss: 0.26238 | valid_accuracy: 0.90114 |  0:30:03s\n",
            "epoch 155| loss: 0.24849 | train_logloss: 0.24621 | train_accuracy: 0.90519 | valid_logloss: 0.26352 | valid_accuracy: 0.90063 |  0:30:15s\n",
            "epoch 156| loss: 0.25179 | train_logloss: 0.25161 | train_accuracy: 0.90329 | valid_logloss: 0.26709 | valid_accuracy: 0.89924 |  0:30:27s\n",
            "epoch 157| loss: 0.25875 | train_logloss: 0.26605 | train_accuracy: 0.89967 | valid_logloss: 0.2775  | valid_accuracy: 0.89696 |  0:30:38s\n",
            "epoch 158| loss: 0.26527 | train_logloss: 0.25609 | train_accuracy: 0.90206 | valid_logloss: 0.26704 | valid_accuracy: 0.89933 |  0:30:50s\n",
            "epoch 159| loss: 0.25853 | train_logloss: 0.25322 | train_accuracy: 0.90258 | valid_logloss: 0.26518 | valid_accuracy: 0.89936 |  0:31:02s\n",
            "epoch 160| loss: 0.25562 | train_logloss: 0.24925 | train_accuracy: 0.90432 | valid_logloss: 0.26238 | valid_accuracy: 0.90054 |  0:31:13s\n",
            "epoch 161| loss: 0.2534  | train_logloss: 0.24988 | train_accuracy: 0.90415 | valid_logloss: 0.26385 | valid_accuracy: 0.90034 |  0:31:25s\n",
            "epoch 162| loss: 0.25315 | train_logloss: 0.25008 | train_accuracy: 0.90418 | valid_logloss: 0.2642  | valid_accuracy: 0.90039 |  0:31:37s\n",
            "epoch 163| loss: 0.2529  | train_logloss: 0.24991 | train_accuracy: 0.90394 | valid_logloss: 0.26337 | valid_accuracy: 0.9003  |  0:31:48s\n",
            "epoch 164| loss: 0.25331 | train_logloss: 0.25351 | train_accuracy: 0.90265 | valid_logloss: 0.26777 | valid_accuracy: 0.89895 |  0:32:00s\n",
            "epoch 165| loss: 0.25323 | train_logloss: 0.24893 | train_accuracy: 0.90429 | valid_logloss: 0.26412 | valid_accuracy: 0.90086 |  0:32:12s\n",
            "epoch 166| loss: 0.25293 | train_logloss: 0.25005 | train_accuracy: 0.90407 | valid_logloss: 0.2652  | valid_accuracy: 0.89993 |  0:32:23s\n",
            "epoch 167| loss: 0.25231 | train_logloss: 0.24896 | train_accuracy: 0.90471 | valid_logloss: 0.26406 | valid_accuracy: 0.90037 |  0:32:35s\n",
            "epoch 168| loss: 0.25115 | train_logloss: 0.24607 | train_accuracy: 0.90582 | valid_logloss: 0.26172 | valid_accuracy: 0.90134 |  0:32:46s\n",
            "epoch 169| loss: 0.25522 | train_logloss: 0.25219 | train_accuracy: 0.90386 | valid_logloss: 0.26633 | valid_accuracy: 0.90009 |  0:32:58s\n",
            "epoch 170| loss: 0.26409 | train_logloss: 0.2872  | train_accuracy: 0.8935  | valid_logloss: 0.29462 | valid_accuracy: 0.89152 |  0:33:10s\n",
            "epoch 171| loss: 0.28028 | train_logloss: 0.26748 | train_accuracy: 0.89892 | valid_logloss: 0.27498 | valid_accuracy: 0.89706 |  0:33:21s\n",
            "epoch 172| loss: 0.26859 | train_logloss: 0.25972 | train_accuracy: 0.9011  | valid_logloss: 0.26814 | valid_accuracy: 0.89929 |  0:33:33s\n",
            "epoch 173| loss: 0.26285 | train_logloss: 0.25687 | train_accuracy: 0.90188 | valid_logloss: 0.26692 | valid_accuracy: 0.8998  |  0:33:45s\n",
            "epoch 174| loss: 0.25959 | train_logloss: 0.25454 | train_accuracy: 0.90273 | valid_logloss: 0.26499 | valid_accuracy: 0.90027 |  0:33:56s\n",
            "epoch 175| loss: 0.25762 | train_logloss: 0.25289 | train_accuracy: 0.90292 | valid_logloss: 0.26394 | valid_accuracy: 0.90008 |  0:34:08s\n",
            "epoch 176| loss: 0.256   | train_logloss: 0.25174 | train_accuracy: 0.9036  | valid_logloss: 0.26346 | valid_accuracy: 0.90063 |  0:34:20s\n",
            "epoch 177| loss: 0.2554  | train_logloss: 0.25013 | train_accuracy: 0.90412 | valid_logloss: 0.26232 | valid_accuracy: 0.9013  |  0:34:31s\n",
            "epoch 178| loss: 0.25436 | train_logloss: 0.25592 | train_accuracy: 0.90171 | valid_logloss: 0.26818 | valid_accuracy: 0.89826 |  0:34:43s\n",
            "epoch 179| loss: 0.2544  | train_logloss: 0.24988 | train_accuracy: 0.90425 | valid_logloss: 0.26308 | valid_accuracy: 0.90103 |  0:34:55s\n",
            "epoch 180| loss: 0.25342 | train_logloss: 0.25035 | train_accuracy: 0.90371 | valid_logloss: 0.26425 | valid_accuracy: 0.90021 |  0:35:07s\n",
            "epoch 181| loss: 0.25471 | train_logloss: 0.25248 | train_accuracy: 0.90335 | valid_logloss: 0.26557 | valid_accuracy: 0.9002  |  0:35:19s\n",
            "epoch 182| loss: 0.25596 | train_logloss: 0.25051 | train_accuracy: 0.90385 | valid_logloss: 0.26434 | valid_accuracy: 0.90026 |  0:35:30s\n",
            "epoch 183| loss: 0.25406 | train_logloss: 0.25163 | train_accuracy: 0.90326 | valid_logloss: 0.26421 | valid_accuracy: 0.90049 |  0:35:42s\n",
            "epoch 184| loss: 0.25471 | train_logloss: 0.24935 | train_accuracy: 0.90439 | valid_logloss: 0.26218 | valid_accuracy: 0.90121 |  0:35:54s\n",
            "epoch 185| loss: 0.25343 | train_logloss: 0.24843 | train_accuracy: 0.9049  | valid_logloss: 0.262   | valid_accuracy: 0.90139 |  0:36:06s\n",
            "\n",
            "Early stopping occurred at epoch 185 with best_epoch = 135 and best_valid_accuracy = 0.90143\n",
            "Best weights from best epoch are automatically used!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-34c5d0c7832e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m      \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m,\u001b[0m        \u001b[0mdecay_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m        \u001b[0mdecay_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m      \u001b[0mshared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m      mask_type='entmax')\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-62cc0fd29aa8>\u001b[0m in \u001b[0;36mones\u001b[0;34m(number_exp, Rows, Nd, Na, B, BV, mB, λsparse, Nsteps, γ, learning_rate, decay_rate, decay_iterations, shared, decision, mask_type)\u001b[0m\n\u001b[1;32m     68\u001b[0m       \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvirtual_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   ) \n\u001b[0;32m---> 70\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Научная работа/Data/hyperparametrs.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time TN: '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m', '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 't' referenced before assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoG5VV95VlNY"
      },
      "source": [
        "ones(number_exp=15, \n",
        "     Rows=300000, \n",
        "     Nd=16,\tNa=16,\t\n",
        "     B=16384,\tBV=1024,\tmB=0.7,\t\n",
        "     λsparse=0.001,\tNsteps=3,\tγ=1.7, \n",
        "     learning_rate=0.02,\tdecay_rate=0.95,\tdecay_iterations=200,\t\n",
        "     shared=2, decision=2, \n",
        "     mask_type='entmax')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltTzu3W1fva9"
      },
      "source": [
        "ones(number_exp=14, \n",
        "     Rows=30000, \n",
        "     Nd=16,\tNa=16,\t\n",
        "     B=2048,\tBV=512,\tmB=0.7,\t\n",
        "     λsparse=0.001,\tNsteps=3,\tγ=1.7, \n",
        "     learning_rate=0.02,\tdecay_rate=0.95,\tdecay_iterations=200,\t\n",
        "     shared=2, decision=2, \n",
        "     mask_type='entmax')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RezXgsvA_0Te",
        "outputId": "e5e6e167-ddce-48e1-e6fb-9db4cd83e97e"
      },
      "source": [
        "ones(number_exp=16, \n",
        "     Rows=30000, \n",
        "     Nd=16,\tNa=16,\t\n",
        "     B=2048,\tBV=512,\tmB=0.7,\t\n",
        "     λsparse=0.001,\tNsteps=5,\tγ=1.7, \n",
        "     learning_rate=0.02,\tdecay_rate=0.95,\tdecay_iterations=200,\t\n",
        "     shared=2, decision=2, \n",
        "     mask_type='entmax')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device used : cuda\n",
            "epoch 0  | loss: 1.07899 | train_logloss: 16.10763| train_accuracy: 0.36503 | valid_logloss: 16.06683| valid_accuracy: 0.3691  |  0:00:02s\n",
            "epoch 1  | loss: 0.61676 | train_logloss: 6.73377 | train_accuracy: 0.46913 | valid_logloss: 6.67126 | valid_accuracy: 0.4731  |  0:00:04s\n",
            "epoch 2  | loss: 0.51035 | train_logloss: 3.21475 | train_accuracy: 0.3945  | valid_logloss: 3.27889 | valid_accuracy: 0.39143 |  0:00:06s\n",
            "epoch 3  | loss: 0.47394 | train_logloss: 3.77001 | train_accuracy: 0.382   | valid_logloss: 3.71168 | valid_accuracy: 0.38347 |  0:00:08s\n",
            "epoch 4  | loss: 0.41743 | train_logloss: 2.41424 | train_accuracy: 0.36523 | valid_logloss: 2.4196  | valid_accuracy: 0.36487 |  0:00:10s\n",
            "epoch 5  | loss: 0.41772 | train_logloss: 1.25983 | train_accuracy: 0.52977 | valid_logloss: 1.25954 | valid_accuracy: 0.52567 |  0:00:12s\n",
            "epoch 6  | loss: 0.38943 | train_logloss: 1.25853 | train_accuracy: 0.48813 | valid_logloss: 1.26784 | valid_accuracy: 0.48097 |  0:00:15s\n",
            "epoch 7  | loss: 0.38543 | train_logloss: 1.25784 | train_accuracy: 0.52477 | valid_logloss: 1.25795 | valid_accuracy: 0.5233  |  0:00:17s\n",
            "epoch 8  | loss: 0.37285 | train_logloss: 1.57069 | train_accuracy: 0.24347 | valid_logloss: 1.57944 | valid_accuracy: 0.244   |  0:00:19s\n",
            "epoch 9  | loss: 0.37328 | train_logloss: 0.97582 | train_accuracy: 0.53387 | valid_logloss: 0.98561 | valid_accuracy: 0.52473 |  0:00:21s\n",
            "epoch 10 | loss: 0.36511 | train_logloss: 0.79256 | train_accuracy: 0.6219  | valid_logloss: 0.80158 | valid_accuracy: 0.6144  |  0:00:23s\n",
            "epoch 11 | loss: 0.3594  | train_logloss: 0.72101 | train_accuracy: 0.7034  | valid_logloss: 0.73154 | valid_accuracy: 0.6953  |  0:00:25s\n",
            "epoch 12 | loss: 0.37024 | train_logloss: 0.62674 | train_accuracy: 0.75833 | valid_logloss: 0.63575 | valid_accuracy: 0.75297 |  0:00:27s\n",
            "epoch 13 | loss: 0.35638 | train_logloss: 0.56201 | train_accuracy: 0.77523 | valid_logloss: 0.57476 | valid_accuracy: 0.76957 |  0:00:30s\n",
            "epoch 14 | loss: 0.34658 | train_logloss: 0.62627 | train_accuracy: 0.71933 | valid_logloss: 0.64245 | valid_accuracy: 0.7119  |  0:00:32s\n",
            "epoch 15 | loss: 0.34085 | train_logloss: 0.57781 | train_accuracy: 0.76257 | valid_logloss: 0.58851 | valid_accuracy: 0.76013 |  0:00:34s\n",
            "epoch 16 | loss: 0.33788 | train_logloss: 0.52519 | train_accuracy: 0.80417 | valid_logloss: 0.53699 | valid_accuracy: 0.8014  |  0:00:36s\n",
            "epoch 17 | loss: 0.3419  | train_logloss: 0.44748 | train_accuracy: 0.8255  | valid_logloss: 0.45921 | valid_accuracy: 0.82083 |  0:00:38s\n",
            "epoch 18 | loss: 0.33617 | train_logloss: 0.42444 | train_accuracy: 0.84163 | valid_logloss: 0.43875 | valid_accuracy: 0.83597 |  0:00:40s\n",
            "epoch 19 | loss: 0.3333  | train_logloss: 0.42084 | train_accuracy: 0.83653 | valid_logloss: 0.42862 | valid_accuracy: 0.83253 |  0:00:42s\n",
            "epoch 20 | loss: 0.32884 | train_logloss: 0.39245 | train_accuracy: 0.85583 | valid_logloss: 0.39949 | valid_accuracy: 0.85487 |  0:00:45s\n",
            "epoch 21 | loss: 0.329   | train_logloss: 0.36784 | train_accuracy: 0.86453 | valid_logloss: 0.37659 | valid_accuracy: 0.86127 |  0:00:47s\n",
            "epoch 22 | loss: 0.32127 | train_logloss: 0.34844 | train_accuracy: 0.8742  | valid_logloss: 0.36099 | valid_accuracy: 0.86997 |  0:00:49s\n",
            "epoch 23 | loss: 0.31967 | train_logloss: 0.33717 | train_accuracy: 0.87627 | valid_logloss: 0.34854 | valid_accuracy: 0.87343 |  0:00:51s\n",
            "epoch 24 | loss: 0.32423 | train_logloss: 0.32732 | train_accuracy: 0.87867 | valid_logloss: 0.34083 | valid_accuracy: 0.87387 |  0:00:53s\n",
            "epoch 25 | loss: 0.32169 | train_logloss: 0.32745 | train_accuracy: 0.8762  | valid_logloss: 0.33938 | valid_accuracy: 0.87463 |  0:00:55s\n",
            "epoch 26 | loss: 0.32693 | train_logloss: 0.33703 | train_accuracy: 0.87377 | valid_logloss: 0.35306 | valid_accuracy: 0.8698  |  0:00:57s\n",
            "epoch 27 | loss: 0.32821 | train_logloss: 0.33771 | train_accuracy: 0.87743 | valid_logloss: 0.35163 | valid_accuracy: 0.87343 |  0:01:00s\n",
            "epoch 28 | loss: 0.3279  | train_logloss: 0.32159 | train_accuracy: 0.88037 | valid_logloss: 0.33625 | valid_accuracy: 0.8762  |  0:01:02s\n",
            "epoch 29 | loss: 0.32471 | train_logloss: 0.32553 | train_accuracy: 0.87907 | valid_logloss: 0.34085 | valid_accuracy: 0.87493 |  0:01:04s\n",
            "epoch 30 | loss: 0.32676 | train_logloss: 0.32965 | train_accuracy: 0.87487 | valid_logloss: 0.34121 | valid_accuracy: 0.87187 |  0:01:06s\n",
            "epoch 31 | loss: 0.32552 | train_logloss: 0.32994 | train_accuracy: 0.87857 | valid_logloss: 0.34135 | valid_accuracy: 0.8754  |  0:01:08s\n",
            "epoch 32 | loss: 0.32638 | train_logloss: 0.32165 | train_accuracy: 0.88093 | valid_logloss: 0.33501 | valid_accuracy: 0.877   |  0:01:10s\n",
            "epoch 33 | loss: 0.32659 | train_logloss: 0.32409 | train_accuracy: 0.8795  | valid_logloss: 0.33791 | valid_accuracy: 0.874   |  0:01:12s\n",
            "epoch 34 | loss: 0.32366 | train_logloss: 0.32287 | train_accuracy: 0.87953 | valid_logloss: 0.33895 | valid_accuracy: 0.8743  |  0:01:14s\n",
            "epoch 35 | loss: 0.31823 | train_logloss: 0.31023 | train_accuracy: 0.88493 | valid_logloss: 0.32678 | valid_accuracy: 0.8782  |  0:01:17s\n",
            "epoch 36 | loss: 0.32243 | train_logloss: 0.31721 | train_accuracy: 0.88477 | valid_logloss: 0.33182 | valid_accuracy: 0.87697 |  0:01:19s\n",
            "epoch 37 | loss: 0.32081 | train_logloss: 0.31512 | train_accuracy: 0.88267 | valid_logloss: 0.33116 | valid_accuracy: 0.87753 |  0:01:21s\n",
            "epoch 38 | loss: 0.31626 | train_logloss: 0.30882 | train_accuracy: 0.88337 | valid_logloss: 0.32501 | valid_accuracy: 0.88013 |  0:01:23s\n",
            "epoch 39 | loss: 0.31682 | train_logloss: 0.31649 | train_accuracy: 0.88063 | valid_logloss: 0.33489 | valid_accuracy: 0.877   |  0:01:25s\n",
            "epoch 40 | loss: 0.32168 | train_logloss: 0.30978 | train_accuracy: 0.88403 | valid_logloss: 0.32738 | valid_accuracy: 0.87873 |  0:01:27s\n",
            "epoch 41 | loss: 0.31807 | train_logloss: 0.31694 | train_accuracy: 0.881   | valid_logloss: 0.33313 | valid_accuracy: 0.87757 |  0:01:29s\n",
            "epoch 42 | loss: 0.318   | train_logloss: 0.31321 | train_accuracy: 0.88307 | valid_logloss: 0.3309  | valid_accuracy: 0.87717 |  0:01:32s\n",
            "epoch 43 | loss: 0.31268 | train_logloss: 0.30909 | train_accuracy: 0.88423 | valid_logloss: 0.3276  | valid_accuracy: 0.87897 |  0:01:34s\n",
            "epoch 44 | loss: 0.31487 | train_logloss: 0.31439 | train_accuracy: 0.883   | valid_logloss: 0.32873 | valid_accuracy: 0.87743 |  0:01:36s\n",
            "epoch 45 | loss: 0.31365 | train_logloss: 0.30339 | train_accuracy: 0.88693 | valid_logloss: 0.31745 | valid_accuracy: 0.8801  |  0:01:38s\n",
            "epoch 46 | loss: 0.3125  | train_logloss: 0.30778 | train_accuracy: 0.8862  | valid_logloss: 0.32148 | valid_accuracy: 0.8809  |  0:01:40s\n",
            "epoch 47 | loss: 0.31793 | train_logloss: 0.31404 | train_accuracy: 0.882   | valid_logloss: 0.32692 | valid_accuracy: 0.87923 |  0:01:42s\n",
            "epoch 48 | loss: 0.31324 | train_logloss: 0.3068  | train_accuracy: 0.88367 | valid_logloss: 0.31978 | valid_accuracy: 0.87947 |  0:01:44s\n",
            "epoch 49 | loss: 0.31173 | train_logloss: 0.31397 | train_accuracy: 0.88347 | valid_logloss: 0.32424 | valid_accuracy: 0.8793  |  0:01:47s\n",
            "epoch 50 | loss: 0.31888 | train_logloss: 0.30639 | train_accuracy: 0.886   | valid_logloss: 0.31837 | valid_accuracy: 0.88053 |  0:01:49s\n",
            "epoch 51 | loss: 0.30972 | train_logloss: 0.30371 | train_accuracy: 0.88703 | valid_logloss: 0.31713 | valid_accuracy: 0.881   |  0:01:51s\n",
            "epoch 52 | loss: 0.3051  | train_logloss: 0.30025 | train_accuracy: 0.88783 | valid_logloss: 0.31608 | valid_accuracy: 0.8814  |  0:01:53s\n",
            "epoch 53 | loss: 0.30597 | train_logloss: 0.30116 | train_accuracy: 0.88697 | valid_logloss: 0.3164  | valid_accuracy: 0.88203 |  0:01:55s\n",
            "epoch 54 | loss: 0.30247 | train_logloss: 0.29474 | train_accuracy: 0.88897 | valid_logloss: 0.31407 | valid_accuracy: 0.8824  |  0:01:57s\n",
            "epoch 55 | loss: 0.30068 | train_logloss: 0.29555 | train_accuracy: 0.88923 | valid_logloss: 0.31529 | valid_accuracy: 0.8831  |  0:01:59s\n",
            "epoch 56 | loss: 0.2987  | train_logloss: 0.29306 | train_accuracy: 0.88977 | valid_logloss: 0.31473 | valid_accuracy: 0.88233 |  0:02:01s\n",
            "epoch 57 | loss: 0.2973  | train_logloss: 0.2911  | train_accuracy: 0.8905  | valid_logloss: 0.31155 | valid_accuracy: 0.88513 |  0:02:04s\n",
            "epoch 58 | loss: 0.29587 | train_logloss: 0.29074 | train_accuracy: 0.89103 | valid_logloss: 0.31133 | valid_accuracy: 0.88373 |  0:02:06s\n",
            "epoch 59 | loss: 0.29407 | train_logloss: 0.28681 | train_accuracy: 0.89153 | valid_logloss: 0.30942 | valid_accuracy: 0.88393 |  0:02:08s\n",
            "epoch 60 | loss: 0.29191 | train_logloss: 0.28753 | train_accuracy: 0.89133 | valid_logloss: 0.31383 | valid_accuracy: 0.8841  |  0:02:10s\n",
            "epoch 61 | loss: 0.29055 | train_logloss: 0.28483 | train_accuracy: 0.89193 | valid_logloss: 0.30588 | valid_accuracy: 0.88447 |  0:02:12s\n",
            "epoch 62 | loss: 0.2942  | train_logloss: 0.28672 | train_accuracy: 0.8906  | valid_logloss: 0.30853 | valid_accuracy: 0.883   |  0:02:14s\n",
            "epoch 63 | loss: 0.29382 | train_logloss: 0.28572 | train_accuracy: 0.89153 | valid_logloss: 0.30767 | valid_accuracy: 0.88523 |  0:02:16s\n",
            "epoch 64 | loss: 0.29072 | train_logloss: 0.28498 | train_accuracy: 0.8914  | valid_logloss: 0.30566 | valid_accuracy: 0.88333 |  0:02:18s\n",
            "epoch 65 | loss: 0.28791 | train_logloss: 0.29194 | train_accuracy: 0.88873 | valid_logloss: 0.31489 | valid_accuracy: 0.8839  |  0:02:20s\n",
            "epoch 66 | loss: 0.28832 | train_logloss: 0.28138 | train_accuracy: 0.89367 | valid_logloss: 0.30548 | valid_accuracy: 0.88693 |  0:02:23s\n",
            "epoch 67 | loss: 0.2844  | train_logloss: 0.28075 | train_accuracy: 0.89293 | valid_logloss: 0.30643 | valid_accuracy: 0.88617 |  0:02:25s\n",
            "epoch 68 | loss: 0.28578 | train_logloss: 0.27986 | train_accuracy: 0.8951  | valid_logloss: 0.30638 | valid_accuracy: 0.88593 |  0:02:27s\n",
            "epoch 69 | loss: 0.28432 | train_logloss: 0.28058 | train_accuracy: 0.89373 | valid_logloss: 0.30738 | valid_accuracy: 0.887   |  0:02:29s\n",
            "epoch 70 | loss: 0.2894  | train_logloss: 0.29457 | train_accuracy: 0.8914  | valid_logloss: 0.31486 | valid_accuracy: 0.88567 |  0:02:31s\n",
            "epoch 71 | loss: 0.29392 | train_logloss: 0.28588 | train_accuracy: 0.8911  | valid_logloss: 0.30685 | valid_accuracy: 0.88563 |  0:02:33s\n",
            "epoch 72 | loss: 0.29493 | train_logloss: 0.28982 | train_accuracy: 0.89003 | valid_logloss: 0.31047 | valid_accuracy: 0.88433 |  0:02:35s\n",
            "epoch 73 | loss: 0.29068 | train_logloss: 0.28249 | train_accuracy: 0.89223 | valid_logloss: 0.30749 | valid_accuracy: 0.88657 |  0:02:37s\n",
            "epoch 74 | loss: 0.28819 | train_logloss: 0.27708 | train_accuracy: 0.8948  | valid_logloss: 0.30123 | valid_accuracy: 0.8868  |  0:02:39s\n",
            "epoch 75 | loss: 0.28341 | train_logloss: 0.28132 | train_accuracy: 0.89557 | valid_logloss: 0.30546 | valid_accuracy: 0.88733 |  0:02:41s\n",
            "epoch 76 | loss: 0.27984 | train_logloss: 0.27471 | train_accuracy: 0.89623 | valid_logloss: 0.30226 | valid_accuracy: 0.88643 |  0:02:43s\n",
            "epoch 77 | loss: 0.27841 | train_logloss: 0.2771  | train_accuracy: 0.89553 | valid_logloss: 0.30467 | valid_accuracy: 0.88817 |  0:02:45s\n",
            "epoch 78 | loss: 0.28005 | train_logloss: 0.27614 | train_accuracy: 0.89513 | valid_logloss: 0.30522 | valid_accuracy: 0.88613 |  0:02:47s\n",
            "epoch 79 | loss: 0.28018 | train_logloss: 0.27694 | train_accuracy: 0.89423 | valid_logloss: 0.30638 | valid_accuracy: 0.8854  |  0:02:49s\n",
            "epoch 80 | loss: 0.28927 | train_logloss: 0.28773 | train_accuracy: 0.8903  | valid_logloss: 0.31128 | valid_accuracy: 0.88357 |  0:02:51s\n",
            "epoch 81 | loss: 0.29167 | train_logloss: 0.28252 | train_accuracy: 0.8927  | valid_logloss: 0.3073  | valid_accuracy: 0.88683 |  0:02:53s\n",
            "epoch 82 | loss: 0.28803 | train_logloss: 0.28211 | train_accuracy: 0.89243 | valid_logloss: 0.30571 | valid_accuracy: 0.88583 |  0:02:55s\n",
            "epoch 83 | loss: 0.29491 | train_logloss: 0.29434 | train_accuracy: 0.89013 | valid_logloss: 0.31594 | valid_accuracy: 0.88503 |  0:02:57s\n",
            "epoch 84 | loss: 0.29946 | train_logloss: 0.30392 | train_accuracy: 0.8816  | valid_logloss: 0.32114 | valid_accuracy: 0.87723 |  0:02:59s\n",
            "epoch 85 | loss: 0.30395 | train_logloss: 0.29033 | train_accuracy: 0.8896  | valid_logloss: 0.31109 | valid_accuracy: 0.8854  |  0:03:01s\n",
            "epoch 86 | loss: 0.29646 | train_logloss: 0.28713 | train_accuracy: 0.88983 | valid_logloss: 0.30866 | valid_accuracy: 0.88583 |  0:03:03s\n",
            "epoch 87 | loss: 0.29078 | train_logloss: 0.28952 | train_accuracy: 0.89    | valid_logloss: 0.31056 | valid_accuracy: 0.88343 |  0:03:05s\n",
            "epoch 88 | loss: 0.29102 | train_logloss: 0.2902  | train_accuracy: 0.88993 | valid_logloss: 0.31334 | valid_accuracy: 0.88253 |  0:03:07s\n",
            "epoch 89 | loss: 0.29767 | train_logloss: 0.2927  | train_accuracy: 0.88907 | valid_logloss: 0.3165  | valid_accuracy: 0.88337 |  0:03:09s\n",
            "epoch 90 | loss: 0.29827 | train_logloss: 0.29298 | train_accuracy: 0.88977 | valid_logloss: 0.31523 | valid_accuracy: 0.88333 |  0:03:11s\n",
            "epoch 91 | loss: 0.30133 | train_logloss: 0.29714 | train_accuracy: 0.89003 | valid_logloss: 0.31485 | valid_accuracy: 0.8835  |  0:03:13s\n",
            "epoch 92 | loss: 0.30636 | train_logloss: 0.3079  | train_accuracy: 0.8868  | valid_logloss: 0.32584 | valid_accuracy: 0.8818  |  0:03:15s\n",
            "epoch 93 | loss: 0.30563 | train_logloss: 0.30149 | train_accuracy: 0.88687 | valid_logloss: 0.31989 | valid_accuracy: 0.8811  |  0:03:17s\n",
            "epoch 94 | loss: 0.30304 | train_logloss: 0.29217 | train_accuracy: 0.88997 | valid_logloss: 0.30993 | valid_accuracy: 0.8842  |  0:03:19s\n",
            "epoch 95 | loss: 0.30205 | train_logloss: 0.2958  | train_accuracy: 0.88847 | valid_logloss: 0.31489 | valid_accuracy: 0.88247 |  0:03:21s\n",
            "epoch 96 | loss: 0.30105 | train_logloss: 0.2964  | train_accuracy: 0.8852  | valid_logloss: 0.31211 | valid_accuracy: 0.88047 |  0:03:23s\n",
            "epoch 97 | loss: 0.2981  | train_logloss: 0.29069 | train_accuracy: 0.88873 | valid_logloss: 0.30909 | valid_accuracy: 0.8823  |  0:03:25s\n",
            "epoch 98 | loss: 0.29586 | train_logloss: 0.29727 | train_accuracy: 0.88743 | valid_logloss: 0.31302 | valid_accuracy: 0.88237 |  0:03:27s\n",
            "epoch 99 | loss: 0.30385 | train_logloss: 0.2941  | train_accuracy: 0.88823 | valid_logloss: 0.30919 | valid_accuracy: 0.88387 |  0:03:30s\n",
            "epoch 100| loss: 0.30631 | train_logloss: 0.31262 | train_accuracy: 0.88147 | valid_logloss: 0.33014 | valid_accuracy: 0.87533 |  0:03:32s\n",
            "epoch 101| loss: 0.3194  | train_logloss: 0.30847 | train_accuracy: 0.88183 | valid_logloss: 0.32028 | valid_accuracy: 0.87677 |  0:03:34s\n",
            "epoch 102| loss: 0.30552 | train_logloss: 0.29479 | train_accuracy: 0.88697 | valid_logloss: 0.30993 | valid_accuracy: 0.8812  |  0:03:36s\n",
            "epoch 103| loss: 0.29828 | train_logloss: 0.30733 | train_accuracy: 0.88533 | valid_logloss: 0.32386 | valid_accuracy: 0.87727 |  0:03:38s\n",
            "epoch 104| loss: 0.30692 | train_logloss: 0.32147 | train_accuracy: 0.87437 | valid_logloss: 0.33615 | valid_accuracy: 0.8688  |  0:03:40s\n",
            "epoch 105| loss: 0.31616 | train_logloss: 0.30657 | train_accuracy: 0.88193 | valid_logloss: 0.31986 | valid_accuracy: 0.87847 |  0:03:42s\n",
            "epoch 106| loss: 0.30584 | train_logloss: 0.29945 | train_accuracy: 0.8838  | valid_logloss: 0.31671 | valid_accuracy: 0.87903 |  0:03:44s\n",
            "epoch 107| loss: 0.30139 | train_logloss: 0.29618 | train_accuracy: 0.88683 | valid_logloss: 0.31132 | valid_accuracy: 0.8818  |  0:03:46s\n",
            "epoch 108| loss: 0.29806 | train_logloss: 0.28871 | train_accuracy: 0.88963 | valid_logloss: 0.30679 | valid_accuracy: 0.88323 |  0:03:48s\n",
            "epoch 109| loss: 0.29497 | train_logloss: 0.28876 | train_accuracy: 0.8888  | valid_logloss: 0.3069  | valid_accuracy: 0.88337 |  0:03:50s\n",
            "epoch 110| loss: 0.29016 | train_logloss: 0.28249 | train_accuracy: 0.89123 | valid_logloss: 0.30181 | valid_accuracy: 0.88483 |  0:03:52s\n",
            "epoch 111| loss: 0.28756 | train_logloss: 0.28825 | train_accuracy: 0.88943 | valid_logloss: 0.30789 | valid_accuracy: 0.88263 |  0:03:54s\n",
            "epoch 112| loss: 0.2927  | train_logloss: 0.28506 | train_accuracy: 0.88953 | valid_logloss: 0.30391 | valid_accuracy: 0.88317 |  0:03:56s\n",
            "epoch 113| loss: 0.28881 | train_logloss: 0.28243 | train_accuracy: 0.8929  | valid_logloss: 0.30242 | valid_accuracy: 0.8853  |  0:03:58s\n",
            "epoch 114| loss: 0.29988 | train_logloss: 0.29317 | train_accuracy: 0.88927 | valid_logloss: 0.31174 | valid_accuracy: 0.88277 |  0:04:00s\n",
            "epoch 115| loss: 0.29564 | train_logloss: 0.28156 | train_accuracy: 0.89307 | valid_logloss: 0.30052 | valid_accuracy: 0.88483 |  0:04:02s\n",
            "epoch 116| loss: 0.28751 | train_logloss: 0.2842  | train_accuracy: 0.89173 | valid_logloss: 0.30375 | valid_accuracy: 0.88297 |  0:04:04s\n",
            "epoch 117| loss: 0.28424 | train_logloss: 0.28461 | train_accuracy: 0.8915  | valid_logloss: 0.3053  | valid_accuracy: 0.88443 |  0:04:06s\n",
            "epoch 118| loss: 0.28863 | train_logloss: 0.28401 | train_accuracy: 0.89057 | valid_logloss: 0.30665 | valid_accuracy: 0.88297 |  0:04:08s\n",
            "epoch 119| loss: 0.28311 | train_logloss: 0.27904 | train_accuracy: 0.89227 | valid_logloss: 0.29957 | valid_accuracy: 0.88603 |  0:04:10s\n",
            "epoch 120| loss: 0.28339 | train_logloss: 0.27876 | train_accuracy: 0.8944  | valid_logloss: 0.30121 | valid_accuracy: 0.88787 |  0:04:12s\n",
            "epoch 121| loss: 0.28131 | train_logloss: 0.27629 | train_accuracy: 0.89417 | valid_logloss: 0.29791 | valid_accuracy: 0.8869  |  0:04:14s\n",
            "epoch 122| loss: 0.28061 | train_logloss: 0.27266 | train_accuracy: 0.89603 | valid_logloss: 0.29656 | valid_accuracy: 0.88863 |  0:04:16s\n",
            "epoch 123| loss: 0.2787  | train_logloss: 0.27292 | train_accuracy: 0.89607 | valid_logloss: 0.29612 | valid_accuracy: 0.88813 |  0:04:18s\n",
            "epoch 124| loss: 0.282   | train_logloss: 0.27479 | train_accuracy: 0.8963  | valid_logloss: 0.29496 | valid_accuracy: 0.88947 |  0:04:20s\n",
            "epoch 125| loss: 0.28281 | train_logloss: 0.27356 | train_accuracy: 0.89617 | valid_logloss: 0.29593 | valid_accuracy: 0.88803 |  0:04:23s\n",
            "epoch 126| loss: 0.27958 | train_logloss: 0.27162 | train_accuracy: 0.89483 | valid_logloss: 0.29393 | valid_accuracy: 0.88897 |  0:04:25s\n",
            "epoch 127| loss: 0.27704 | train_logloss: 0.27172 | train_accuracy: 0.89777 | valid_logloss: 0.2955  | valid_accuracy: 0.8897  |  0:04:27s\n",
            "epoch 128| loss: 0.27619 | train_logloss: 0.2689  | train_accuracy: 0.89777 | valid_logloss: 0.29246 | valid_accuracy: 0.88983 |  0:04:29s\n",
            "epoch 129| loss: 0.27672 | train_logloss: 0.27199 | train_accuracy: 0.896   | valid_logloss: 0.29491 | valid_accuracy: 0.88777 |  0:04:31s\n",
            "epoch 130| loss: 0.27508 | train_logloss: 0.26997 | train_accuracy: 0.89653 | valid_logloss: 0.29359 | valid_accuracy: 0.88953 |  0:04:33s\n",
            "epoch 131| loss: 0.27483 | train_logloss: 0.27609 | train_accuracy: 0.89453 | valid_logloss: 0.29826 | valid_accuracy: 0.886   |  0:04:35s\n",
            "epoch 132| loss: 0.28057 | train_logloss: 0.27223 | train_accuracy: 0.8967  | valid_logloss: 0.29379 | valid_accuracy: 0.88933 |  0:04:37s\n",
            "epoch 133| loss: 0.27576 | train_logloss: 0.26813 | train_accuracy: 0.89717 | valid_logloss: 0.29449 | valid_accuracy: 0.89097 |  0:04:39s\n",
            "epoch 134| loss: 0.28607 | train_logloss: 0.28368 | train_accuracy: 0.89197 | valid_logloss: 0.30742 | valid_accuracy: 0.88427 |  0:04:41s\n",
            "epoch 135| loss: 0.28927 | train_logloss: 0.27868 | train_accuracy: 0.89433 | valid_logloss: 0.30257 | valid_accuracy: 0.88577 |  0:04:43s\n",
            "epoch 136| loss: 0.28245 | train_logloss: 0.27525 | train_accuracy: 0.8935  | valid_logloss: 0.30274 | valid_accuracy: 0.88767 |  0:04:45s\n",
            "epoch 137| loss: 0.28296 | train_logloss: 0.2832  | train_accuracy: 0.8926  | valid_logloss: 0.30626 | valid_accuracy: 0.8837  |  0:04:47s\n",
            "epoch 138| loss: 0.28535 | train_logloss: 0.27669 | train_accuracy: 0.895   | valid_logloss: 0.30101 | valid_accuracy: 0.88717 |  0:04:49s\n",
            "epoch 139| loss: 0.28019 | train_logloss: 0.27636 | train_accuracy: 0.89553 | valid_logloss: 0.3026  | valid_accuracy: 0.88637 |  0:04:51s\n",
            "epoch 140| loss: 0.27665 | train_logloss: 0.26798 | train_accuracy: 0.89753 | valid_logloss: 0.29413 | valid_accuracy: 0.889   |  0:04:53s\n",
            "epoch 141| loss: 0.27305 | train_logloss: 0.26712 | train_accuracy: 0.89723 | valid_logloss: 0.29446 | valid_accuracy: 0.88753 |  0:04:55s\n",
            "epoch 142| loss: 0.27216 | train_logloss: 0.26594 | train_accuracy: 0.8988  | valid_logloss: 0.29442 | valid_accuracy: 0.88877 |  0:04:57s\n",
            "epoch 143| loss: 0.2704  | train_logloss: 0.26702 | train_accuracy: 0.8983  | valid_logloss: 0.29758 | valid_accuracy: 0.8883  |  0:04:59s\n",
            "epoch 144| loss: 0.27212 | train_logloss: 0.26639 | train_accuracy: 0.8979  | valid_logloss: 0.29667 | valid_accuracy: 0.88987 |  0:05:01s\n",
            "epoch 145| loss: 0.27123 | train_logloss: 0.26228 | train_accuracy: 0.8999  | valid_logloss: 0.29207 | valid_accuracy: 0.8892  |  0:05:04s\n",
            "epoch 146| loss: 0.26863 | train_logloss: 0.26402 | train_accuracy: 0.90043 | valid_logloss: 0.29794 | valid_accuracy: 0.8884  |  0:05:06s\n",
            "epoch 147| loss: 0.26812 | train_logloss: 0.26096 | train_accuracy: 0.9008  | valid_logloss: 0.29343 | valid_accuracy: 0.89043 |  0:05:08s\n",
            "epoch 148| loss: 0.26833 | train_logloss: 0.26419 | train_accuracy: 0.90057 | valid_logloss: 0.29736 | valid_accuracy: 0.88793 |  0:05:10s\n",
            "epoch 149| loss: 0.26931 | train_logloss: 0.26262 | train_accuracy: 0.89923 | valid_logloss: 0.29685 | valid_accuracy: 0.8897  |  0:05:12s\n",
            "epoch 150| loss: 0.26534 | train_logloss: 0.25887 | train_accuracy: 0.902   | valid_logloss: 0.29299 | valid_accuracy: 0.89037 |  0:05:14s\n",
            "epoch 151| loss: 0.26647 | train_logloss: 0.2603  | train_accuracy: 0.90033 | valid_logloss: 0.29373 | valid_accuracy: 0.88997 |  0:05:16s\n",
            "epoch 152| loss: 0.26643 | train_logloss: 0.26696 | train_accuracy: 0.89913 | valid_logloss: 0.30118 | valid_accuracy: 0.88897 |  0:05:18s\n",
            "epoch 153| loss: 0.26699 | train_logloss: 0.26043 | train_accuracy: 0.901   | valid_logloss: 0.29529 | valid_accuracy: 0.89    |  0:05:20s\n",
            "epoch 154| loss: 0.26754 | train_logloss: 0.27952 | train_accuracy: 0.89373 | valid_logloss: 0.31198 | valid_accuracy: 0.88057 |  0:05:22s\n",
            "epoch 155| loss: 0.278   | train_logloss: 0.27266 | train_accuracy: 0.8957  | valid_logloss: 0.29935 | valid_accuracy: 0.88887 |  0:05:24s\n",
            "epoch 156| loss: 0.2814  | train_logloss: 0.27971 | train_accuracy: 0.89357 | valid_logloss: 0.304   | valid_accuracy: 0.88667 |  0:05:26s\n",
            "epoch 157| loss: 0.28359 | train_logloss: 0.27383 | train_accuracy: 0.89623 | valid_logloss: 0.3027  | valid_accuracy: 0.88627 |  0:05:28s\n",
            "epoch 158| loss: 0.27339 | train_logloss: 0.26535 | train_accuracy: 0.89873 | valid_logloss: 0.29639 | valid_accuracy: 0.88737 |  0:05:30s\n",
            "epoch 159| loss: 0.26865 | train_logloss: 0.26566 | train_accuracy: 0.8996  | valid_logloss: 0.29807 | valid_accuracy: 0.88847 |  0:05:32s\n",
            "epoch 160| loss: 0.27623 | train_logloss: 0.27525 | train_accuracy: 0.89527 | valid_logloss: 0.30175 | valid_accuracy: 0.88577 |  0:05:34s\n",
            "epoch 161| loss: 0.27492 | train_logloss: 0.26705 | train_accuracy: 0.89837 | valid_logloss: 0.2988  | valid_accuracy: 0.88867 |  0:05:36s\n",
            "epoch 162| loss: 0.271   | train_logloss: 0.26596 | train_accuracy: 0.89847 | valid_logloss: 0.29725 | valid_accuracy: 0.88827 |  0:05:38s\n",
            "epoch 163| loss: 0.26837 | train_logloss: 0.26175 | train_accuracy: 0.89943 | valid_logloss: 0.29535 | valid_accuracy: 0.8873  |  0:05:41s\n",
            "epoch 164| loss: 0.26539 | train_logloss: 0.25898 | train_accuracy: 0.90013 | valid_logloss: 0.29328 | valid_accuracy: 0.88957 |  0:05:43s\n",
            "epoch 165| loss: 0.26573 | train_logloss: 0.25895 | train_accuracy: 0.90033 | valid_logloss: 0.29032 | valid_accuracy: 0.89003 |  0:05:45s\n",
            "epoch 166| loss: 0.26584 | train_logloss: 0.26211 | train_accuracy: 0.89877 | valid_logloss: 0.29791 | valid_accuracy: 0.88797 |  0:05:47s\n",
            "epoch 167| loss: 0.26634 | train_logloss: 0.26197 | train_accuracy: 0.90093 | valid_logloss: 0.29521 | valid_accuracy: 0.88787 |  0:05:49s\n",
            "epoch 168| loss: 0.26415 | train_logloss: 0.2565  | train_accuracy: 0.9019  | valid_logloss: 0.29131 | valid_accuracy: 0.88947 |  0:05:51s\n",
            "epoch 169| loss: 0.26375 | train_logloss: 0.26103 | train_accuracy: 0.9004  | valid_logloss: 0.29747 | valid_accuracy: 0.8872  |  0:05:53s\n",
            "epoch 170| loss: 0.26052 | train_logloss: 0.25397 | train_accuracy: 0.90433 | valid_logloss: 0.28958 | valid_accuracy: 0.8911  |  0:05:55s\n",
            "epoch 171| loss: 0.26192 | train_logloss: 0.25373 | train_accuracy: 0.90247 | valid_logloss: 0.29358 | valid_accuracy: 0.8892  |  0:05:57s\n",
            "epoch 172| loss: 0.2598  | train_logloss: 0.25286 | train_accuracy: 0.90317 | valid_logloss: 0.28933 | valid_accuracy: 0.89207 |  0:05:59s\n",
            "epoch 173| loss: 0.26122 | train_logloss: 0.25385 | train_accuracy: 0.9021  | valid_logloss: 0.29259 | valid_accuracy: 0.88987 |  0:06:01s\n",
            "epoch 174| loss: 0.26208 | train_logloss: 0.25596 | train_accuracy: 0.90237 | valid_logloss: 0.29276 | valid_accuracy: 0.88883 |  0:06:03s\n",
            "epoch 175| loss: 0.2591  | train_logloss: 0.25343 | train_accuracy: 0.90217 | valid_logloss: 0.29127 | valid_accuracy: 0.8909  |  0:06:05s\n",
            "epoch 176| loss: 0.25868 | train_logloss: 0.25609 | train_accuracy: 0.9031  | valid_logloss: 0.29462 | valid_accuracy: 0.89097 |  0:06:07s\n",
            "epoch 177| loss: 0.26373 | train_logloss: 0.25519 | train_accuracy: 0.9013  | valid_logloss: 0.2937  | valid_accuracy: 0.8896  |  0:06:09s\n",
            "epoch 178| loss: 0.26497 | train_logloss: 0.26465 | train_accuracy: 0.90017 | valid_logloss: 0.30067 | valid_accuracy: 0.8891  |  0:06:11s\n",
            "epoch 179| loss: 0.27052 | train_logloss: 0.26019 | train_accuracy: 0.89927 | valid_logloss: 0.29721 | valid_accuracy: 0.88943 |  0:06:13s\n",
            "epoch 180| loss: 0.26543 | train_logloss: 0.25671 | train_accuracy: 0.9019  | valid_logloss: 0.29509 | valid_accuracy: 0.89147 |  0:06:15s\n",
            "epoch 181| loss: 0.26243 | train_logloss: 0.25501 | train_accuracy: 0.90327 | valid_logloss: 0.29255 | valid_accuracy: 0.89187 |  0:06:18s\n",
            "epoch 182| loss: 0.26182 | train_logloss: 0.25475 | train_accuracy: 0.9025  | valid_logloss: 0.29662 | valid_accuracy: 0.89    |  0:06:20s\n",
            "epoch 183| loss: 0.25899 | train_logloss: 0.25327 | train_accuracy: 0.90327 | valid_logloss: 0.29369 | valid_accuracy: 0.89107 |  0:06:22s\n",
            "epoch 184| loss: 0.26007 | train_logloss: 0.25578 | train_accuracy: 0.90063 | valid_logloss: 0.29836 | valid_accuracy: 0.88963 |  0:06:24s\n",
            "epoch 185| loss: 0.26127 | train_logloss: 0.25483 | train_accuracy: 0.90207 | valid_logloss: 0.29744 | valid_accuracy: 0.88973 |  0:06:26s\n",
            "epoch 186| loss: 0.26108 | train_logloss: 0.25488 | train_accuracy: 0.90337 | valid_logloss: 0.29425 | valid_accuracy: 0.89087 |  0:06:28s\n",
            "epoch 187| loss: 0.25702 | train_logloss: 0.2507  | train_accuracy: 0.90473 | valid_logloss: 0.29312 | valid_accuracy: 0.8918  |  0:06:30s\n",
            "epoch 188| loss: 0.2576  | train_logloss: 0.2499  | train_accuracy: 0.905   | valid_logloss: 0.29355 | valid_accuracy: 0.89187 |  0:06:32s\n",
            "epoch 189| loss: 0.25638 | train_logloss: 0.24756 | train_accuracy: 0.90543 | valid_logloss: 0.29116 | valid_accuracy: 0.89327 |  0:06:34s\n",
            "epoch 190| loss: 0.25392 | train_logloss: 0.24687 | train_accuracy: 0.90463 | valid_logloss: 0.29703 | valid_accuracy: 0.8904  |  0:06:36s\n",
            "epoch 191| loss: 0.25342 | train_logloss: 0.24856 | train_accuracy: 0.9046  | valid_logloss: 0.29693 | valid_accuracy: 0.8919  |  0:06:38s\n",
            "epoch 192| loss: 0.25768 | train_logloss: 0.25241 | train_accuracy: 0.90387 | valid_logloss: 0.30247 | valid_accuracy: 0.891   |  0:06:40s\n",
            "epoch 193| loss: 0.25772 | train_logloss: 0.24788 | train_accuracy: 0.90413 | valid_logloss: 0.2936  | valid_accuracy: 0.8921  |  0:06:42s\n",
            "epoch 194| loss: 0.25641 | train_logloss: 0.25142 | train_accuracy: 0.90353 | valid_logloss: 0.29757 | valid_accuracy: 0.89077 |  0:06:44s\n",
            "epoch 195| loss: 0.2591  | train_logloss: 0.25653 | train_accuracy: 0.90163 | valid_logloss: 0.29942 | valid_accuracy: 0.8912  |  0:06:46s\n",
            "epoch 196| loss: 0.26093 | train_logloss: 0.24897 | train_accuracy: 0.90283 | valid_logloss: 0.2917  | valid_accuracy: 0.89203 |  0:06:48s\n",
            "epoch 197| loss: 0.25746 | train_logloss: 0.24951 | train_accuracy: 0.90337 | valid_logloss: 0.29517 | valid_accuracy: 0.89107 |  0:06:50s\n",
            "epoch 198| loss: 0.25536 | train_logloss: 0.24511 | train_accuracy: 0.9053  | valid_logloss: 0.29291 | valid_accuracy: 0.89263 |  0:06:52s\n",
            "epoch 199| loss: 0.25346 | train_logloss: 0.24882 | train_accuracy: 0.90363 | valid_logloss: 0.29909 | valid_accuracy: 0.89033 |  0:06:55s\n",
            "epoch 200| loss: 0.25266 | train_logloss: 0.24539 | train_accuracy: 0.90503 | valid_logloss: 0.29629 | valid_accuracy: 0.89243 |  0:06:57s\n",
            "epoch 201| loss: 0.25206 | train_logloss: 0.25222 | train_accuracy: 0.90363 | valid_logloss: 0.30085 | valid_accuracy: 0.88813 |  0:06:59s\n",
            "epoch 202| loss: 0.25426 | train_logloss: 0.24727 | train_accuracy: 0.90443 | valid_logloss: 0.29852 | valid_accuracy: 0.89103 |  0:07:01s\n",
            "epoch 203| loss: 0.25287 | train_logloss: 0.24355 | train_accuracy: 0.9061  | valid_logloss: 0.29521 | valid_accuracy: 0.89103 |  0:07:03s\n",
            "epoch 204| loss: 0.24933 | train_logloss: 0.24463 | train_accuracy: 0.9059  | valid_logloss: 0.29727 | valid_accuracy: 0.8923  |  0:07:05s\n",
            "epoch 205| loss: 0.24937 | train_logloss: 0.24441 | train_accuracy: 0.90653 | valid_logloss: 0.30028 | valid_accuracy: 0.8906  |  0:07:07s\n",
            "epoch 206| loss: 0.24921 | train_logloss: 0.24274 | train_accuracy: 0.90557 | valid_logloss: 0.29764 | valid_accuracy: 0.89033 |  0:07:09s\n",
            "epoch 207| loss: 0.24699 | train_logloss: 0.24157 | train_accuracy: 0.90573 | valid_logloss: 0.29675 | valid_accuracy: 0.8903  |  0:07:11s\n",
            "epoch 208| loss: 0.24792 | train_logloss: 0.24135 | train_accuracy: 0.9067  | valid_logloss: 0.29548 | valid_accuracy: 0.8918  |  0:07:13s\n",
            "epoch 209| loss: 0.248   | train_logloss: 0.23955 | train_accuracy: 0.9078  | valid_logloss: 0.29906 | valid_accuracy: 0.89    |  0:07:15s\n",
            "epoch 210| loss: 0.24892 | train_logloss: 0.24556 | train_accuracy: 0.90567 | valid_logloss: 0.30108 | valid_accuracy: 0.89133 |  0:07:17s\n",
            "epoch 211| loss: 0.25205 | train_logloss: 0.24566 | train_accuracy: 0.90407 | valid_logloss: 0.29534 | valid_accuracy: 0.8913  |  0:07:19s\n",
            "epoch 212| loss: 0.25013 | train_logloss: 0.24566 | train_accuracy: 0.9028  | valid_logloss: 0.30461 | valid_accuracy: 0.88883 |  0:07:21s\n",
            "epoch 213| loss: 0.24682 | train_logloss: 0.2412  | train_accuracy: 0.9067  | valid_logloss: 0.29761 | valid_accuracy: 0.89157 |  0:07:23s\n",
            "epoch 214| loss: 0.24929 | train_logloss: 0.24242 | train_accuracy: 0.90757 | valid_logloss: 0.29796 | valid_accuracy: 0.89213 |  0:07:25s\n",
            "epoch 215| loss: 0.24592 | train_logloss: 0.2422  | train_accuracy: 0.90623 | valid_logloss: 0.30286 | valid_accuracy: 0.88837 |  0:07:27s\n",
            "epoch 216| loss: 0.24941 | train_logloss: 0.24068 | train_accuracy: 0.9065  | valid_logloss: 0.30102 | valid_accuracy: 0.89033 |  0:07:29s\n",
            "epoch 217| loss: 0.24735 | train_logloss: 0.24605 | train_accuracy: 0.9057  | valid_logloss: 0.30604 | valid_accuracy: 0.8901  |  0:07:31s\n",
            "epoch 218| loss: 0.25199 | train_logloss: 0.25033 | train_accuracy: 0.9035  | valid_logloss: 0.3115  | valid_accuracy: 0.8865  |  0:07:33s\n",
            "epoch 219| loss: 0.25076 | train_logloss: 0.24438 | train_accuracy: 0.9049  | valid_logloss: 0.29775 | valid_accuracy: 0.8912  |  0:07:36s\n",
            "epoch 220| loss: 0.24992 | train_logloss: 0.24196 | train_accuracy: 0.90683 | valid_logloss: 0.29755 | valid_accuracy: 0.8903  |  0:07:38s\n",
            "epoch 221| loss: 0.24962 | train_logloss: 0.24086 | train_accuracy: 0.90693 | valid_logloss: 0.29757 | valid_accuracy: 0.89063 |  0:07:40s\n",
            "epoch 222| loss: 0.24912 | train_logloss: 0.24144 | train_accuracy: 0.9075  | valid_logloss: 0.29955 | valid_accuracy: 0.8903  |  0:07:42s\n",
            "epoch 223| loss: 0.24701 | train_logloss: 0.2393  | train_accuracy: 0.90683 | valid_logloss: 0.29691 | valid_accuracy: 0.89123 |  0:07:44s\n",
            "epoch 224| loss: 0.24595 | train_logloss: 0.24324 | train_accuracy: 0.90583 | valid_logloss: 0.30041 | valid_accuracy: 0.8888  |  0:07:46s\n",
            "epoch 225| loss: 0.24651 | train_logloss: 0.24041 | train_accuracy: 0.90843 | valid_logloss: 0.29957 | valid_accuracy: 0.8908  |  0:07:48s\n",
            "epoch 226| loss: 0.24431 | train_logloss: 0.23859 | train_accuracy: 0.90817 | valid_logloss: 0.29825 | valid_accuracy: 0.89163 |  0:07:50s\n",
            "epoch 227| loss: 0.24592 | train_logloss: 0.23707 | train_accuracy: 0.9081  | valid_logloss: 0.30234 | valid_accuracy: 0.88883 |  0:07:52s\n",
            "epoch 228| loss: 0.24342 | train_logloss: 0.23452 | train_accuracy: 0.90957 | valid_logloss: 0.30084 | valid_accuracy: 0.8908  |  0:07:54s\n",
            "epoch 229| loss: 0.24252 | train_logloss: 0.23508 | train_accuracy: 0.90893 | valid_logloss: 0.30011 | valid_accuracy: 0.88993 |  0:07:56s\n",
            "epoch 230| loss: 0.24406 | train_logloss: 0.23483 | train_accuracy: 0.90923 | valid_logloss: 0.30038 | valid_accuracy: 0.8897  |  0:07:58s\n",
            "epoch 231| loss: 0.24368 | train_logloss: 0.23764 | train_accuracy: 0.90993 | valid_logloss: 0.30151 | valid_accuracy: 0.89047 |  0:08:00s\n",
            "epoch 232| loss: 0.24278 | train_logloss: 0.23368 | train_accuracy: 0.9112  | valid_logloss: 0.30176 | valid_accuracy: 0.8902  |  0:08:02s\n",
            "epoch 233| loss: 0.24292 | train_logloss: 0.23507 | train_accuracy: 0.90853 | valid_logloss: 0.30469 | valid_accuracy: 0.88877 |  0:08:04s\n",
            "epoch 234| loss: 0.24203 | train_logloss: 0.23814 | train_accuracy: 0.90777 | valid_logloss: 0.30329 | valid_accuracy: 0.88863 |  0:08:06s\n",
            "epoch 235| loss: 0.24314 | train_logloss: 0.23263 | train_accuracy: 0.9091  | valid_logloss: 0.30234 | valid_accuracy: 0.8906  |  0:08:08s\n",
            "epoch 236| loss: 0.24092 | train_logloss: 0.23803 | train_accuracy: 0.91023 | valid_logloss: 0.30571 | valid_accuracy: 0.88853 |  0:08:10s\n",
            "epoch 237| loss: 0.24094 | train_logloss: 0.23449 | train_accuracy: 0.90953 | valid_logloss: 0.30685 | valid_accuracy: 0.88963 |  0:08:12s\n",
            "epoch 238| loss: 0.23909 | train_logloss: 0.23057 | train_accuracy: 0.9101  | valid_logloss: 0.30409 | valid_accuracy: 0.89087 |  0:08:14s\n",
            "epoch 239| loss: 0.23809 | train_logloss: 0.22995 | train_accuracy: 0.91237 | valid_logloss: 0.30312 | valid_accuracy: 0.88933 |  0:08:17s\n",
            "\n",
            "Early stopping occurred at epoch 239 with best_epoch = 189 and best_valid_accuracy = 0.89327\n",
            "Best weights from best epoch are automatically used!\n",
            "TN\n",
            "GB\n",
            "Successfully saved model at /content/drive/MyDrive/Научная работа/Data/hyper/tn16.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkvhQ62bxm6d",
        "outputId": "21ebd229-c695-4508-da06-50e38615808c"
      },
      "source": [
        "ones(number_exp=17, \n",
        "     Rows=30000, \n",
        "     Nd=16,\tNa=16,\t\n",
        "     B=2048,\tBV=512,\tmB=0.9,\t\n",
        "     λsparse=0.001,\tNsteps=5,\tγ=1.7, \n",
        "     learning_rate=0.02,\tdecay_rate=0.95,\tdecay_iterations=200,\t\n",
        "     shared=2, decision=2, \n",
        "     mask_type='entmax')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device used : cuda\n",
            "epoch 0  | loss: 1.07515 | train_logloss: 15.61666| train_accuracy: 0.40127 | valid_logloss: 15.62071| valid_accuracy: 0.4015  |  0:00:02s\n",
            "epoch 1  | loss: 0.61204 | train_logloss: 22.99017| train_accuracy: 0.33367 | valid_logloss: 22.98541| valid_accuracy: 0.3337  |  0:00:04s\n",
            "epoch 2  | loss: 0.52328 | train_logloss: 9.73707 | train_accuracy: 0.29887 | valid_logloss: 9.83167 | valid_accuracy: 0.29647 |  0:00:06s\n",
            "epoch 3  | loss: 0.47488 | train_logloss: 10.96129| train_accuracy: 0.2991  | valid_logloss: 11.01346| valid_accuracy: 0.30263 |  0:00:08s\n",
            "epoch 4  | loss: 0.4553  | train_logloss: 6.16226 | train_accuracy: 0.51473 | valid_logloss: 6.23659 | valid_accuracy: 0.5146  |  0:00:10s\n",
            "epoch 5  | loss: 0.46163 | train_logloss: 4.28868 | train_accuracy: 0.4412  | valid_logloss: 4.31423 | valid_accuracy: 0.44427 |  0:00:12s\n",
            "epoch 6  | loss: 0.43387 | train_logloss: 5.13905 | train_accuracy: 0.3385  | valid_logloss: 5.17095 | valid_accuracy: 0.3398  |  0:00:14s\n",
            "epoch 7  | loss: 0.44616 | train_logloss: 1.96762 | train_accuracy: 0.41657 | valid_logloss: 1.98188 | valid_accuracy: 0.41657 |  0:00:16s\n",
            "epoch 8  | loss: 0.40334 | train_logloss: 1.05431 | train_accuracy: 0.5747  | valid_logloss: 1.0693  | valid_accuracy: 0.57237 |  0:00:18s\n",
            "epoch 9  | loss: 0.3875  | train_logloss: 0.70837 | train_accuracy: 0.72933 | valid_logloss: 0.72189 | valid_accuracy: 0.72447 |  0:00:20s\n",
            "epoch 10 | loss: 0.38589 | train_logloss: 0.78232 | train_accuracy: 0.69807 | valid_logloss: 0.78669 | valid_accuracy: 0.69327 |  0:00:22s\n",
            "epoch 11 | loss: 0.38968 | train_logloss: 0.63572 | train_accuracy: 0.73753 | valid_logloss: 0.64055 | valid_accuracy: 0.73363 |  0:00:24s\n",
            "epoch 12 | loss: 0.38217 | train_logloss: 0.60006 | train_accuracy: 0.76377 | valid_logloss: 0.61161 | valid_accuracy: 0.75733 |  0:00:26s\n",
            "epoch 13 | loss: 0.37433 | train_logloss: 0.64434 | train_accuracy: 0.7623  | valid_logloss: 0.65417 | valid_accuracy: 0.75717 |  0:00:28s\n",
            "epoch 14 | loss: 0.37494 | train_logloss: 0.58745 | train_accuracy: 0.7836  | valid_logloss: 0.59599 | valid_accuracy: 0.78323 |  0:00:30s\n",
            "epoch 15 | loss: 0.37509 | train_logloss: 0.54783 | train_accuracy: 0.79503 | valid_logloss: 0.56071 | valid_accuracy: 0.78633 |  0:00:32s\n",
            "epoch 16 | loss: 0.37783 | train_logloss: 0.47619 | train_accuracy: 0.8318  | valid_logloss: 0.48875 | valid_accuracy: 0.82673 |  0:00:34s\n",
            "epoch 17 | loss: 0.37266 | train_logloss: 0.49532 | train_accuracy: 0.81553 | valid_logloss: 0.50624 | valid_accuracy: 0.81013 |  0:00:36s\n",
            "epoch 18 | loss: 0.37214 | train_logloss: 0.4464  | train_accuracy: 0.83533 | valid_logloss: 0.45528 | valid_accuracy: 0.8316  |  0:00:38s\n",
            "epoch 19 | loss: 0.36759 | train_logloss: 0.39006 | train_accuracy: 0.85937 | valid_logloss: 0.39885 | valid_accuracy: 0.85683 |  0:00:40s\n",
            "epoch 20 | loss: 0.36107 | train_logloss: 0.38548 | train_accuracy: 0.85577 | valid_logloss: 0.3972  | valid_accuracy: 0.85103 |  0:00:42s\n",
            "epoch 21 | loss: 0.35737 | train_logloss: 0.39633 | train_accuracy: 0.85937 | valid_logloss: 0.41125 | valid_accuracy: 0.85547 |  0:00:44s\n",
            "epoch 22 | loss: 0.359   | train_logloss: 0.40442 | train_accuracy: 0.85623 | valid_logloss: 0.42029 | valid_accuracy: 0.85177 |  0:00:47s\n",
            "epoch 23 | loss: 0.36789 | train_logloss: 0.37413 | train_accuracy: 0.86237 | valid_logloss: 0.38661 | valid_accuracy: 0.85767 |  0:00:49s\n",
            "epoch 24 | loss: 0.37201 | train_logloss: 0.37038 | train_accuracy: 0.85933 | valid_logloss: 0.38242 | valid_accuracy: 0.8561  |  0:00:51s\n",
            "epoch 25 | loss: 0.36257 | train_logloss: 0.37472 | train_accuracy: 0.85757 | valid_logloss: 0.38322 | valid_accuracy: 0.85597 |  0:00:53s\n",
            "epoch 26 | loss: 0.35987 | train_logloss: 0.35927 | train_accuracy: 0.86333 | valid_logloss: 0.37222 | valid_accuracy: 0.85947 |  0:00:55s\n",
            "epoch 27 | loss: 0.35172 | train_logloss: 0.3503  | train_accuracy: 0.86907 | valid_logloss: 0.36536 | valid_accuracy: 0.86363 |  0:00:57s\n",
            "epoch 28 | loss: 0.35762 | train_logloss: 0.35452 | train_accuracy: 0.8669  | valid_logloss: 0.36799 | valid_accuracy: 0.8619  |  0:00:59s\n",
            "epoch 29 | loss: 0.35495 | train_logloss: 0.35563 | train_accuracy: 0.86613 | valid_logloss: 0.36832 | valid_accuracy: 0.8629  |  0:01:01s\n",
            "epoch 30 | loss: 0.3512  | train_logloss: 0.34824 | train_accuracy: 0.86913 | valid_logloss: 0.36424 | valid_accuracy: 0.86423 |  0:01:03s\n",
            "epoch 31 | loss: 0.34759 | train_logloss: 0.34623 | train_accuracy: 0.8695  | valid_logloss: 0.36196 | valid_accuracy: 0.86417 |  0:01:05s\n",
            "epoch 32 | loss: 0.35056 | train_logloss: 0.35473 | train_accuracy: 0.86383 | valid_logloss: 0.36765 | valid_accuracy: 0.8606  |  0:01:07s\n",
            "epoch 33 | loss: 0.34505 | train_logloss: 0.34044 | train_accuracy: 0.8712  | valid_logloss: 0.35667 | valid_accuracy: 0.86697 |  0:01:09s\n",
            "epoch 34 | loss: 0.34314 | train_logloss: 0.34053 | train_accuracy: 0.86943 | valid_logloss: 0.35477 | valid_accuracy: 0.86667 |  0:01:11s\n",
            "epoch 35 | loss: 0.34447 | train_logloss: 0.35044 | train_accuracy: 0.86677 | valid_logloss: 0.36282 | valid_accuracy: 0.86123 |  0:01:13s\n",
            "epoch 36 | loss: 0.35824 | train_logloss: 0.35597 | train_accuracy: 0.86897 | valid_logloss: 0.36785 | valid_accuracy: 0.86163 |  0:01:15s\n",
            "epoch 37 | loss: 0.3577  | train_logloss: 0.35455 | train_accuracy: 0.867   | valid_logloss: 0.36722 | valid_accuracy: 0.86073 |  0:01:17s\n",
            "epoch 38 | loss: 0.35469 | train_logloss: 0.34898 | train_accuracy: 0.86913 | valid_logloss: 0.36201 | valid_accuracy: 0.865   |  0:01:19s\n",
            "epoch 39 | loss: 0.35008 | train_logloss: 0.3459  | train_accuracy: 0.87243 | valid_logloss: 0.35898 | valid_accuracy: 0.86677 |  0:01:21s\n",
            "epoch 40 | loss: 0.34691 | train_logloss: 0.33711 | train_accuracy: 0.87283 | valid_logloss: 0.35433 | valid_accuracy: 0.86853 |  0:01:23s\n",
            "epoch 41 | loss: 0.34181 | train_logloss: 0.33594 | train_accuracy: 0.87373 | valid_logloss: 0.35323 | valid_accuracy: 0.86797 |  0:01:25s\n",
            "epoch 42 | loss: 0.33847 | train_logloss: 0.33097 | train_accuracy: 0.8771  | valid_logloss: 0.34766 | valid_accuracy: 0.87077 |  0:01:27s\n",
            "epoch 43 | loss: 0.3399  | train_logloss: 0.34279 | train_accuracy: 0.86787 | valid_logloss: 0.35556 | valid_accuracy: 0.86573 |  0:01:29s\n",
            "epoch 44 | loss: 0.34285 | train_logloss: 0.33878 | train_accuracy: 0.87203 | valid_logloss: 0.35233 | valid_accuracy: 0.86883 |  0:01:31s\n",
            "epoch 45 | loss: 0.33919 | train_logloss: 0.33204 | train_accuracy: 0.874   | valid_logloss: 0.34563 | valid_accuracy: 0.87167 |  0:01:33s\n",
            "epoch 46 | loss: 0.3402  | train_logloss: 0.33768 | train_accuracy: 0.8734  | valid_logloss: 0.35033 | valid_accuracy: 0.87023 |  0:01:35s\n",
            "epoch 47 | loss: 0.341   | train_logloss: 0.33371 | train_accuracy: 0.87207 | valid_logloss: 0.34877 | valid_accuracy: 0.8694  |  0:01:37s\n",
            "epoch 48 | loss: 0.33986 | train_logloss: 0.34265 | train_accuracy: 0.87077 | valid_logloss: 0.35566 | valid_accuracy: 0.8657  |  0:01:39s\n",
            "epoch 49 | loss: 0.34875 | train_logloss: 0.34695 | train_accuracy: 0.86837 | valid_logloss: 0.35768 | valid_accuracy: 0.86547 |  0:01:41s\n",
            "epoch 50 | loss: 0.34975 | train_logloss: 0.34527 | train_accuracy: 0.86893 | valid_logloss: 0.35701 | valid_accuracy: 0.86217 |  0:01:43s\n",
            "epoch 51 | loss: 0.3503  | train_logloss: 0.35284 | train_accuracy: 0.8638  | valid_logloss: 0.35954 | valid_accuracy: 0.86237 |  0:01:45s\n",
            "epoch 52 | loss: 0.35135 | train_logloss: 0.34846 | train_accuracy: 0.8687  | valid_logloss: 0.36089 | valid_accuracy: 0.86297 |  0:01:47s\n",
            "epoch 53 | loss: 0.35205 | train_logloss: 0.35409 | train_accuracy: 0.8668  | valid_logloss: 0.36468 | valid_accuracy: 0.8639  |  0:01:49s\n",
            "epoch 54 | loss: 0.35626 | train_logloss: 0.35615 | train_accuracy: 0.8681  | valid_logloss: 0.36614 | valid_accuracy: 0.86417 |  0:01:51s\n",
            "epoch 55 | loss: 0.35423 | train_logloss: 0.3474  | train_accuracy: 0.87047 | valid_logloss: 0.35864 | valid_accuracy: 0.8661  |  0:01:53s\n",
            "epoch 56 | loss: 0.34721 | train_logloss: 0.34239 | train_accuracy: 0.87053 | valid_logloss: 0.35505 | valid_accuracy: 0.8662  |  0:01:55s\n",
            "epoch 57 | loss: 0.34315 | train_logloss: 0.34225 | train_accuracy: 0.86853 | valid_logloss: 0.35604 | valid_accuracy: 0.86273 |  0:01:57s\n",
            "epoch 58 | loss: 0.34318 | train_logloss: 0.33959 | train_accuracy: 0.87393 | valid_logloss: 0.35444 | valid_accuracy: 0.86703 |  0:01:59s\n",
            "epoch 59 | loss: 0.34143 | train_logloss: 0.33559 | train_accuracy: 0.87297 | valid_logloss: 0.34997 | valid_accuracy: 0.868   |  0:02:01s\n",
            "epoch 60 | loss: 0.33862 | train_logloss: 0.33507 | train_accuracy: 0.87387 | valid_logloss: 0.34923 | valid_accuracy: 0.867   |  0:02:03s\n",
            "epoch 61 | loss: 0.33604 | train_logloss: 0.34066 | train_accuracy: 0.86987 | valid_logloss: 0.35496 | valid_accuracy: 0.86573 |  0:02:05s\n",
            "epoch 62 | loss: 0.34597 | train_logloss: 0.34168 | train_accuracy: 0.87147 | valid_logloss: 0.35555 | valid_accuracy: 0.86547 |  0:02:07s\n",
            "epoch 63 | loss: 0.34904 | train_logloss: 0.35313 | train_accuracy: 0.86643 | valid_logloss: 0.36628 | valid_accuracy: 0.86137 |  0:02:09s\n",
            "epoch 64 | loss: 0.34793 | train_logloss: 0.33956 | train_accuracy: 0.87157 | valid_logloss: 0.35358 | valid_accuracy: 0.8649  |  0:02:11s\n",
            "epoch 65 | loss: 0.33986 | train_logloss: 0.3379  | train_accuracy: 0.8715  | valid_logloss: 0.35378 | valid_accuracy: 0.86633 |  0:02:13s\n",
            "epoch 66 | loss: 0.33712 | train_logloss: 0.34736 | train_accuracy: 0.86763 | valid_logloss: 0.36139 | valid_accuracy: 0.86233 |  0:02:15s\n",
            "epoch 67 | loss: 0.33566 | train_logloss: 0.3321  | train_accuracy: 0.87643 | valid_logloss: 0.34807 | valid_accuracy: 0.87117 |  0:02:18s\n",
            "epoch 68 | loss: 0.33215 | train_logloss: 0.33393 | train_accuracy: 0.8759  | valid_logloss: 0.35123 | valid_accuracy: 0.8711  |  0:02:19s\n",
            "epoch 69 | loss: 0.3329  | train_logloss: 0.33396 | train_accuracy: 0.8756  | valid_logloss: 0.3472  | valid_accuracy: 0.87073 |  0:02:22s\n",
            "epoch 70 | loss: 0.33857 | train_logloss: 0.33852 | train_accuracy: 0.87673 | valid_logloss: 0.35167 | valid_accuracy: 0.8692  |  0:02:24s\n",
            "epoch 71 | loss: 0.33666 | train_logloss: 0.33233 | train_accuracy: 0.87563 | valid_logloss: 0.34688 | valid_accuracy: 0.87097 |  0:02:26s\n",
            "epoch 72 | loss: 0.33209 | train_logloss: 0.32533 | train_accuracy: 0.87823 | valid_logloss: 0.34114 | valid_accuracy: 0.873   |  0:02:28s\n",
            "epoch 73 | loss: 0.32816 | train_logloss: 0.32584 | train_accuracy: 0.87657 | valid_logloss: 0.34104 | valid_accuracy: 0.8723  |  0:02:30s\n",
            "epoch 74 | loss: 0.32753 | train_logloss: 0.32674 | train_accuracy: 0.8776  | valid_logloss: 0.34149 | valid_accuracy: 0.8725  |  0:02:32s\n",
            "epoch 75 | loss: 0.32871 | train_logloss: 0.32779 | train_accuracy: 0.8752  | valid_logloss: 0.34095 | valid_accuracy: 0.87233 |  0:02:34s\n",
            "epoch 76 | loss: 0.3256  | train_logloss: 0.32127 | train_accuracy: 0.87923 | valid_logloss: 0.33545 | valid_accuracy: 0.87337 |  0:02:36s\n",
            "epoch 77 | loss: 0.32367 | train_logloss: 0.32124 | train_accuracy: 0.87793 | valid_logloss: 0.33825 | valid_accuracy: 0.8732  |  0:02:38s\n",
            "epoch 78 | loss: 0.32809 | train_logloss: 0.33262 | train_accuracy: 0.87603 | valid_logloss: 0.34278 | valid_accuracy: 0.87157 |  0:02:40s\n",
            "epoch 79 | loss: 0.34003 | train_logloss: 0.33238 | train_accuracy: 0.87423 | valid_logloss: 0.34355 | valid_accuracy: 0.87083 |  0:02:42s\n",
            "epoch 80 | loss: 0.33612 | train_logloss: 0.32922 | train_accuracy: 0.87433 | valid_logloss: 0.34107 | valid_accuracy: 0.8718  |  0:02:44s\n",
            "epoch 81 | loss: 0.33285 | train_logloss: 0.33347 | train_accuracy: 0.87637 | valid_logloss: 0.34445 | valid_accuracy: 0.87277 |  0:02:46s\n",
            "epoch 82 | loss: 0.33166 | train_logloss: 0.32827 | train_accuracy: 0.87777 | valid_logloss: 0.34341 | valid_accuracy: 0.87273 |  0:02:48s\n",
            "epoch 83 | loss: 0.32659 | train_logloss: 0.32117 | train_accuracy: 0.8792  | valid_logloss: 0.33387 | valid_accuracy: 0.87593 |  0:02:50s\n",
            "epoch 84 | loss: 0.3253  | train_logloss: 0.32482 | train_accuracy: 0.878   | valid_logloss: 0.33684 | valid_accuracy: 0.8733  |  0:02:52s\n",
            "epoch 85 | loss: 0.32166 | train_logloss: 0.31791 | train_accuracy: 0.879   | valid_logloss: 0.33348 | valid_accuracy: 0.8752  |  0:02:54s\n",
            "epoch 86 | loss: 0.31877 | train_logloss: 0.31573 | train_accuracy: 0.87987 | valid_logloss: 0.33242 | valid_accuracy: 0.87583 |  0:02:56s\n",
            "epoch 87 | loss: 0.31933 | train_logloss: 0.31702 | train_accuracy: 0.8792  | valid_logloss: 0.33541 | valid_accuracy: 0.87457 |  0:02:58s\n",
            "epoch 88 | loss: 0.32825 | train_logloss: 0.32533 | train_accuracy: 0.88027 | valid_logloss: 0.33807 | valid_accuracy: 0.87583 |  0:03:00s\n",
            "epoch 89 | loss: 0.32619 | train_logloss: 0.32567 | train_accuracy: 0.87707 | valid_logloss: 0.3401  | valid_accuracy: 0.8742  |  0:03:02s\n",
            "epoch 90 | loss: 0.32347 | train_logloss: 0.32184 | train_accuracy: 0.87743 | valid_logloss: 0.33834 | valid_accuracy: 0.8713  |  0:03:04s\n",
            "epoch 91 | loss: 0.324   | train_logloss: 0.31708 | train_accuracy: 0.8796  | valid_logloss: 0.33185 | valid_accuracy: 0.87277 |  0:03:06s\n",
            "epoch 92 | loss: 0.31792 | train_logloss: 0.31535 | train_accuracy: 0.88117 | valid_logloss: 0.3303  | valid_accuracy: 0.87503 |  0:03:08s\n",
            "epoch 93 | loss: 0.31981 | train_logloss: 0.31451 | train_accuracy: 0.8797  | valid_logloss: 0.33049 | valid_accuracy: 0.87477 |  0:03:10s\n",
            "epoch 94 | loss: 0.31668 | train_logloss: 0.31179 | train_accuracy: 0.881   | valid_logloss: 0.33006 | valid_accuracy: 0.87547 |  0:03:12s\n",
            "epoch 95 | loss: 0.31637 | train_logloss: 0.31803 | train_accuracy: 0.88003 | valid_logloss: 0.33519 | valid_accuracy: 0.87473 |  0:03:14s\n",
            "epoch 96 | loss: 0.31854 | train_logloss: 0.32231 | train_accuracy: 0.87633 | valid_logloss: 0.33716 | valid_accuracy: 0.8733  |  0:03:16s\n",
            "epoch 97 | loss: 0.32599 | train_logloss: 0.31536 | train_accuracy: 0.87937 | valid_logloss: 0.32902 | valid_accuracy: 0.87457 |  0:03:18s\n",
            "epoch 98 | loss: 0.31662 | train_logloss: 0.31012 | train_accuracy: 0.88007 | valid_logloss: 0.32534 | valid_accuracy: 0.87667 |  0:03:20s\n",
            "epoch 99 | loss: 0.3137  | train_logloss: 0.30743 | train_accuracy: 0.8807  | valid_logloss: 0.32062 | valid_accuracy: 0.87743 |  0:03:22s\n",
            "epoch 100| loss: 0.30985 | train_logloss: 0.3101  | train_accuracy: 0.88123 | valid_logloss: 0.32589 | valid_accuracy: 0.87537 |  0:03:24s\n",
            "epoch 101| loss: 0.30762 | train_logloss: 0.30304 | train_accuracy: 0.8826  | valid_logloss: 0.32037 | valid_accuracy: 0.87883 |  0:03:26s\n",
            "epoch 102| loss: 0.3143  | train_logloss: 0.30681 | train_accuracy: 0.88253 | valid_logloss: 0.32537 | valid_accuracy: 0.87623 |  0:03:28s\n",
            "epoch 103| loss: 0.30919 | train_logloss: 0.30069 | train_accuracy: 0.88493 | valid_logloss: 0.31864 | valid_accuracy: 0.87923 |  0:03:30s\n",
            "epoch 104| loss: 0.30414 | train_logloss: 0.29784 | train_accuracy: 0.8857  | valid_logloss: 0.31683 | valid_accuracy: 0.87933 |  0:03:32s\n",
            "epoch 105| loss: 0.30206 | train_logloss: 0.30136 | train_accuracy: 0.8838  | valid_logloss: 0.32256 | valid_accuracy: 0.87687 |  0:03:34s\n",
            "epoch 106| loss: 0.30319 | train_logloss: 0.29975 | train_accuracy: 0.88487 | valid_logloss: 0.31904 | valid_accuracy: 0.8789  |  0:03:36s\n",
            "epoch 107| loss: 0.29836 | train_logloss: 0.29286 | train_accuracy: 0.88633 | valid_logloss: 0.31322 | valid_accuracy: 0.88043 |  0:03:38s\n",
            "epoch 108| loss: 0.29727 | train_logloss: 0.2999  | train_accuracy: 0.88617 | valid_logloss: 0.31869 | valid_accuracy: 0.87983 |  0:03:40s\n",
            "epoch 109| loss: 0.2988  | train_logloss: 0.29352 | train_accuracy: 0.88593 | valid_logloss: 0.3155  | valid_accuracy: 0.8788  |  0:03:42s\n",
            "epoch 110| loss: 0.29538 | train_logloss: 0.29535 | train_accuracy: 0.88667 | valid_logloss: 0.31818 | valid_accuracy: 0.8804  |  0:03:44s\n",
            "epoch 111| loss: 0.30206 | train_logloss: 0.29977 | train_accuracy: 0.8858  | valid_logloss: 0.31827 | valid_accuracy: 0.87957 |  0:03:46s\n",
            "epoch 112| loss: 0.30227 | train_logloss: 0.29869 | train_accuracy: 0.88467 | valid_logloss: 0.31808 | valid_accuracy: 0.87967 |  0:03:48s\n",
            "epoch 113| loss: 0.29639 | train_logloss: 0.29334 | train_accuracy: 0.88633 | valid_logloss: 0.31514 | valid_accuracy: 0.8783  |  0:03:50s\n",
            "epoch 114| loss: 0.29601 | train_logloss: 0.29306 | train_accuracy: 0.8873  | valid_logloss: 0.31381 | valid_accuracy: 0.87903 |  0:03:52s\n",
            "epoch 115| loss: 0.29452 | train_logloss: 0.29326 | train_accuracy: 0.88623 | valid_logloss: 0.31696 | valid_accuracy: 0.8776  |  0:03:54s\n",
            "epoch 116| loss: 0.29356 | train_logloss: 0.29396 | train_accuracy: 0.888   | valid_logloss: 0.31442 | valid_accuracy: 0.8809  |  0:03:56s\n",
            "epoch 117| loss: 0.29424 | train_logloss: 0.2863  | train_accuracy: 0.8882  | valid_logloss: 0.30751 | valid_accuracy: 0.88093 |  0:03:58s\n",
            "epoch 118| loss: 0.29143 | train_logloss: 0.2886  | train_accuracy: 0.8887  | valid_logloss: 0.30819 | valid_accuracy: 0.88097 |  0:04:00s\n",
            "epoch 119| loss: 0.28995 | train_logloss: 0.28538 | train_accuracy: 0.88933 | valid_logloss: 0.30839 | valid_accuracy: 0.8813  |  0:04:02s\n",
            "epoch 120| loss: 0.2917  | train_logloss: 0.28313 | train_accuracy: 0.89017 | valid_logloss: 0.3068  | valid_accuracy: 0.88253 |  0:04:04s\n",
            "epoch 121| loss: 0.28835 | train_logloss: 0.28452 | train_accuracy: 0.88983 | valid_logloss: 0.3103  | valid_accuracy: 0.88127 |  0:04:06s\n",
            "epoch 122| loss: 0.28885 | train_logloss: 0.2876  | train_accuracy: 0.8889  | valid_logloss: 0.3096  | valid_accuracy: 0.88067 |  0:04:08s\n",
            "epoch 123| loss: 0.28731 | train_logloss: 0.28319 | train_accuracy: 0.89077 | valid_logloss: 0.30673 | valid_accuracy: 0.8814  |  0:04:10s\n",
            "epoch 124| loss: 0.28572 | train_logloss: 0.28319 | train_accuracy: 0.89117 | valid_logloss: 0.30799 | valid_accuracy: 0.88283 |  0:04:12s\n",
            "epoch 125| loss: 0.28834 | train_logloss: 0.28617 | train_accuracy: 0.8892  | valid_logloss: 0.31038 | valid_accuracy: 0.88163 |  0:04:14s\n",
            "epoch 126| loss: 0.28871 | train_logloss: 0.28516 | train_accuracy: 0.8889  | valid_logloss: 0.30971 | valid_accuracy: 0.8804  |  0:04:16s\n",
            "epoch 127| loss: 0.28744 | train_logloss: 0.28235 | train_accuracy: 0.8902  | valid_logloss: 0.30766 | valid_accuracy: 0.88297 |  0:04:18s\n",
            "epoch 128| loss: 0.28565 | train_logloss: 0.28143 | train_accuracy: 0.89203 | valid_logloss: 0.30551 | valid_accuracy: 0.8832  |  0:04:20s\n",
            "epoch 129| loss: 0.28786 | train_logloss: 0.28318 | train_accuracy: 0.89063 | valid_logloss: 0.31028 | valid_accuracy: 0.88197 |  0:04:22s\n",
            "epoch 130| loss: 0.28589 | train_logloss: 0.28033 | train_accuracy: 0.89077 | valid_logloss: 0.30615 | valid_accuracy: 0.88377 |  0:04:24s\n",
            "epoch 131| loss: 0.28225 | train_logloss: 0.2781  | train_accuracy: 0.89297 | valid_logloss: 0.30586 | valid_accuracy: 0.88313 |  0:04:26s\n",
            "epoch 132| loss: 0.28268 | train_logloss: 0.27947 | train_accuracy: 0.89073 | valid_logloss: 0.30606 | valid_accuracy: 0.88467 |  0:04:28s\n",
            "epoch 133| loss: 0.2815  | train_logloss: 0.27503 | train_accuracy: 0.8936  | valid_logloss: 0.30208 | valid_accuracy: 0.8837  |  0:04:30s\n",
            "epoch 134| loss: 0.27872 | train_logloss: 0.27734 | train_accuracy: 0.8927  | valid_logloss: 0.30364 | valid_accuracy: 0.88467 |  0:04:32s\n",
            "epoch 135| loss: 0.28126 | train_logloss: 0.2781  | train_accuracy: 0.89277 | valid_logloss: 0.30397 | valid_accuracy: 0.88377 |  0:04:34s\n",
            "epoch 136| loss: 0.28669 | train_logloss: 0.288   | train_accuracy: 0.88787 | valid_logloss: 0.31217 | valid_accuracy: 0.8798  |  0:04:36s\n",
            "epoch 137| loss: 0.28741 | train_logloss: 0.27995 | train_accuracy: 0.89153 | valid_logloss: 0.30653 | valid_accuracy: 0.88307 |  0:04:38s\n",
            "epoch 138| loss: 0.28242 | train_logloss: 0.27802 | train_accuracy: 0.8925  | valid_logloss: 0.30224 | valid_accuracy: 0.8849  |  0:04:40s\n",
            "epoch 139| loss: 0.28788 | train_logloss: 0.2855  | train_accuracy: 0.8907  | valid_logloss: 0.30924 | valid_accuracy: 0.88243 |  0:04:43s\n",
            "epoch 140| loss: 0.28553 | train_logloss: 0.27697 | train_accuracy: 0.892   | valid_logloss: 0.30232 | valid_accuracy: 0.8833  |  0:04:45s\n",
            "epoch 141| loss: 0.28263 | train_logloss: 0.27382 | train_accuracy: 0.89513 | valid_logloss: 0.30196 | valid_accuracy: 0.88483 |  0:04:46s\n",
            "epoch 142| loss: 0.27797 | train_logloss: 0.27549 | train_accuracy: 0.89433 | valid_logloss: 0.30343 | valid_accuracy: 0.88583 |  0:04:49s\n",
            "epoch 143| loss: 0.27805 | train_logloss: 0.27347 | train_accuracy: 0.89463 | valid_logloss: 0.30259 | valid_accuracy: 0.88487 |  0:04:51s\n",
            "epoch 144| loss: 0.27635 | train_logloss: 0.2765  | train_accuracy: 0.89463 | valid_logloss: 0.3106  | valid_accuracy: 0.88397 |  0:04:53s\n",
            "epoch 145| loss: 0.28036 | train_logloss: 0.27885 | train_accuracy: 0.89427 | valid_logloss: 0.30532 | valid_accuracy: 0.88353 |  0:04:55s\n",
            "epoch 146| loss: 0.28542 | train_logloss: 0.27642 | train_accuracy: 0.8946  | valid_logloss: 0.30409 | valid_accuracy: 0.8841  |  0:04:57s\n",
            "epoch 147| loss: 0.28036 | train_logloss: 0.2742  | train_accuracy: 0.89613 | valid_logloss: 0.30054 | valid_accuracy: 0.88647 |  0:04:59s\n",
            "epoch 148| loss: 0.28368 | train_logloss: 0.2883  | train_accuracy: 0.89233 | valid_logloss: 0.31108 | valid_accuracy: 0.88363 |  0:05:01s\n",
            "epoch 149| loss: 0.28349 | train_logloss: 0.28199 | train_accuracy: 0.89047 | valid_logloss: 0.30536 | valid_accuracy: 0.88477 |  0:05:03s\n",
            "epoch 150| loss: 0.28165 | train_logloss: 0.27699 | train_accuracy: 0.89377 | valid_logloss: 0.30604 | valid_accuracy: 0.88527 |  0:05:05s\n",
            "epoch 151| loss: 0.288   | train_logloss: 0.28828 | train_accuracy: 0.88957 | valid_logloss: 0.31105 | valid_accuracy: 0.88117 |  0:05:07s\n",
            "epoch 152| loss: 0.28732 | train_logloss: 0.28441 | train_accuracy: 0.8897  | valid_logloss: 0.30627 | valid_accuracy: 0.8829  |  0:05:09s\n",
            "epoch 153| loss: 0.28591 | train_logloss: 0.2835  | train_accuracy: 0.89103 | valid_logloss: 0.30912 | valid_accuracy: 0.88177 |  0:05:11s\n",
            "epoch 154| loss: 0.2858  | train_logloss: 0.28119 | train_accuracy: 0.89283 | valid_logloss: 0.30462 | valid_accuracy: 0.88353 |  0:05:13s\n",
            "epoch 155| loss: 0.28411 | train_logloss: 0.28784 | train_accuracy: 0.8888  | valid_logloss: 0.30852 | valid_accuracy: 0.8814  |  0:05:15s\n",
            "epoch 156| loss: 0.28708 | train_logloss: 0.28682 | train_accuracy: 0.88977 | valid_logloss: 0.30995 | valid_accuracy: 0.88313 |  0:05:17s\n",
            "epoch 157| loss: 0.28937 | train_logloss: 0.28164 | train_accuracy: 0.89223 | valid_logloss: 0.3066  | valid_accuracy: 0.88357 |  0:05:19s\n",
            "epoch 158| loss: 0.28445 | train_logloss: 0.27721 | train_accuracy: 0.8944  | valid_logloss: 0.30146 | valid_accuracy: 0.8857  |  0:05:21s\n",
            "epoch 159| loss: 0.28265 | train_logloss: 0.28366 | train_accuracy: 0.89217 | valid_logloss: 0.30736 | valid_accuracy: 0.88477 |  0:05:23s\n",
            "epoch 160| loss: 0.28073 | train_logloss: 0.27823 | train_accuracy: 0.89547 | valid_logloss: 0.30452 | valid_accuracy: 0.88637 |  0:05:25s\n",
            "epoch 161| loss: 0.2851  | train_logloss: 0.28708 | train_accuracy: 0.89107 | valid_logloss: 0.30807 | valid_accuracy: 0.8839  |  0:05:27s\n",
            "epoch 162| loss: 0.28996 | train_logloss: 0.28107 | train_accuracy: 0.89257 | valid_logloss: 0.30069 | valid_accuracy: 0.88497 |  0:05:29s\n",
            "epoch 163| loss: 0.28704 | train_logloss: 0.27699 | train_accuracy: 0.89453 | valid_logloss: 0.29718 | valid_accuracy: 0.8861  |  0:05:31s\n",
            "epoch 164| loss: 0.28012 | train_logloss: 0.27465 | train_accuracy: 0.89523 | valid_logloss: 0.29598 | valid_accuracy: 0.88773 |  0:05:33s\n",
            "epoch 165| loss: 0.28424 | train_logloss: 0.28667 | train_accuracy: 0.89267 | valid_logloss: 0.3063  | valid_accuracy: 0.88483 |  0:05:35s\n",
            "epoch 166| loss: 0.28397 | train_logloss: 0.28199 | train_accuracy: 0.89407 | valid_logloss: 0.30378 | valid_accuracy: 0.88533 |  0:05:37s\n",
            "epoch 167| loss: 0.28482 | train_logloss: 0.27872 | train_accuracy: 0.89203 | valid_logloss: 0.29965 | valid_accuracy: 0.8856  |  0:05:38s\n",
            "epoch 168| loss: 0.28044 | train_logloss: 0.27652 | train_accuracy: 0.8951  | valid_logloss: 0.29769 | valid_accuracy: 0.8857  |  0:05:41s\n",
            "epoch 169| loss: 0.27788 | train_logloss: 0.27248 | train_accuracy: 0.8958  | valid_logloss: 0.29738 | valid_accuracy: 0.88753 |  0:05:43s\n",
            "epoch 170| loss: 0.27572 | train_logloss: 0.26996 | train_accuracy: 0.8952  | valid_logloss: 0.29703 | valid_accuracy: 0.88693 |  0:05:44s\n",
            "epoch 171| loss: 0.27422 | train_logloss: 0.27501 | train_accuracy: 0.8949  | valid_logloss: 0.30026 | valid_accuracy: 0.8873  |  0:05:47s\n",
            "epoch 172| loss: 0.27308 | train_logloss: 0.27399 | train_accuracy: 0.89523 | valid_logloss: 0.29724 | valid_accuracy: 0.88823 |  0:05:49s\n",
            "epoch 173| loss: 0.27442 | train_logloss: 0.27032 | train_accuracy: 0.89617 | valid_logloss: 0.2981  | valid_accuracy: 0.88753 |  0:05:51s\n",
            "epoch 174| loss: 0.2722  | train_logloss: 0.27346 | train_accuracy: 0.8954  | valid_logloss: 0.30013 | valid_accuracy: 0.88613 |  0:05:53s\n",
            "epoch 175| loss: 0.27984 | train_logloss: 0.27767 | train_accuracy: 0.89443 | valid_logloss: 0.29768 | valid_accuracy: 0.88833 |  0:05:55s\n",
            "epoch 176| loss: 0.28134 | train_logloss: 0.27571 | train_accuracy: 0.8946  | valid_logloss: 0.29831 | valid_accuracy: 0.8873  |  0:05:57s\n",
            "epoch 177| loss: 0.2792  | train_logloss: 0.27304 | train_accuracy: 0.8968  | valid_logloss: 0.29854 | valid_accuracy: 0.88823 |  0:05:59s\n",
            "epoch 178| loss: 0.27533 | train_logloss: 0.26797 | train_accuracy: 0.89727 | valid_logloss: 0.29478 | valid_accuracy: 0.88917 |  0:06:01s\n",
            "epoch 179| loss: 0.27357 | train_logloss: 0.26743 | train_accuracy: 0.89663 | valid_logloss: 0.29184 | valid_accuracy: 0.89047 |  0:06:03s\n",
            "epoch 180| loss: 0.27151 | train_logloss: 0.26754 | train_accuracy: 0.89763 | valid_logloss: 0.29368 | valid_accuracy: 0.88903 |  0:06:05s\n",
            "epoch 181| loss: 0.27074 | train_logloss: 0.26627 | train_accuracy: 0.897   | valid_logloss: 0.29417 | valid_accuracy: 0.88897 |  0:06:07s\n",
            "epoch 182| loss: 0.27341 | train_logloss: 0.29526 | train_accuracy: 0.8917  | valid_logloss: 0.318   | valid_accuracy: 0.88433 |  0:06:09s\n",
            "epoch 183| loss: 0.30255 | train_logloss: 0.29804 | train_accuracy: 0.88907 | valid_logloss: 0.3214  | valid_accuracy: 0.88303 |  0:06:11s\n",
            "epoch 184| loss: 0.28973 | train_logloss: 0.27836 | train_accuracy: 0.89433 | valid_logloss: 0.29982 | valid_accuracy: 0.88723 |  0:06:13s\n",
            "epoch 185| loss: 0.28239 | train_logloss: 0.2732  | train_accuracy: 0.8952  | valid_logloss: 0.29596 | valid_accuracy: 0.8883  |  0:06:15s\n",
            "epoch 186| loss: 0.27708 | train_logloss: 0.27564 | train_accuracy: 0.89543 | valid_logloss: 0.2972  | valid_accuracy: 0.8877  |  0:06:17s\n",
            "epoch 187| loss: 0.27703 | train_logloss: 0.26915 | train_accuracy: 0.89833 | valid_logloss: 0.29701 | valid_accuracy: 0.8889  |  0:06:19s\n",
            "epoch 188| loss: 0.27379 | train_logloss: 0.26937 | train_accuracy: 0.8975  | valid_logloss: 0.29569 | valid_accuracy: 0.8887  |  0:06:21s\n",
            "epoch 189| loss: 0.27282 | train_logloss: 0.27002 | train_accuracy: 0.89683 | valid_logloss: 0.29678 | valid_accuracy: 0.889   |  0:06:23s\n",
            "epoch 190| loss: 0.27112 | train_logloss: 0.26332 | train_accuracy: 0.89863 | valid_logloss: 0.29287 | valid_accuracy: 0.8904  |  0:06:25s\n",
            "epoch 191| loss: 0.26819 | train_logloss: 0.26604 | train_accuracy: 0.89823 | valid_logloss: 0.29366 | valid_accuracy: 0.88983 |  0:06:27s\n",
            "epoch 192| loss: 0.26751 | train_logloss: 0.2715  | train_accuracy: 0.89653 | valid_logloss: 0.29987 | valid_accuracy: 0.88767 |  0:06:29s\n",
            "epoch 193| loss: 0.27216 | train_logloss: 0.26468 | train_accuracy: 0.8973  | valid_logloss: 0.29234 | valid_accuracy: 0.88947 |  0:06:31s\n",
            "epoch 194| loss: 0.26972 | train_logloss: 0.26146 | train_accuracy: 0.90017 | valid_logloss: 0.29183 | valid_accuracy: 0.88897 |  0:06:33s\n",
            "epoch 195| loss: 0.26704 | train_logloss: 0.26106 | train_accuracy: 0.9009  | valid_logloss: 0.29001 | valid_accuracy: 0.8926  |  0:06:35s\n",
            "epoch 196| loss: 0.26741 | train_logloss: 0.2625  | train_accuracy: 0.89943 | valid_logloss: 0.29173 | valid_accuracy: 0.88977 |  0:06:37s\n",
            "epoch 197| loss: 0.26912 | train_logloss: 0.25925 | train_accuracy: 0.901   | valid_logloss: 0.29001 | valid_accuracy: 0.89077 |  0:06:39s\n",
            "epoch 198| loss: 0.26393 | train_logloss: 0.26054 | train_accuracy: 0.90013 | valid_logloss: 0.28996 | valid_accuracy: 0.8901  |  0:06:41s\n",
            "epoch 199| loss: 0.26434 | train_logloss: 0.26427 | train_accuracy: 0.89693 | valid_logloss: 0.29788 | valid_accuracy: 0.88777 |  0:06:43s\n",
            "epoch 200| loss: 0.27957 | train_logloss: 0.26931 | train_accuracy: 0.89617 | valid_logloss: 0.29727 | valid_accuracy: 0.88713 |  0:06:45s\n",
            "epoch 201| loss: 0.27228 | train_logloss: 0.27414 | train_accuracy: 0.89513 | valid_logloss: 0.30013 | valid_accuracy: 0.88813 |  0:06:47s\n",
            "epoch 202| loss: 0.27735 | train_logloss: 0.27047 | train_accuracy: 0.8962  | valid_logloss: 0.29951 | valid_accuracy: 0.8867  |  0:06:49s\n",
            "epoch 203| loss: 0.27495 | train_logloss: 0.27408 | train_accuracy: 0.89463 | valid_logloss: 0.29968 | valid_accuracy: 0.88577 |  0:06:51s\n",
            "epoch 204| loss: 0.27057 | train_logloss: 0.26514 | train_accuracy: 0.8971  | valid_logloss: 0.29203 | valid_accuracy: 0.88977 |  0:06:53s\n",
            "epoch 205| loss: 0.26881 | train_logloss: 0.26421 | train_accuracy: 0.89793 | valid_logloss: 0.29371 | valid_accuracy: 0.88997 |  0:06:55s\n",
            "epoch 206| loss: 0.27023 | train_logloss: 0.26706 | train_accuracy: 0.8962  | valid_logloss: 0.2977  | valid_accuracy: 0.88723 |  0:06:57s\n",
            "epoch 207| loss: 0.2702  | train_logloss: 0.2658  | train_accuracy: 0.89767 | valid_logloss: 0.296   | valid_accuracy: 0.8894  |  0:06:59s\n",
            "epoch 208| loss: 0.26882 | train_logloss: 0.26419 | train_accuracy: 0.89713 | valid_logloss: 0.29317 | valid_accuracy: 0.8885  |  0:07:01s\n",
            "epoch 209| loss: 0.26666 | train_logloss: 0.26099 | train_accuracy: 0.8996  | valid_logloss: 0.29307 | valid_accuracy: 0.88957 |  0:07:03s\n",
            "epoch 210| loss: 0.26589 | train_logloss: 0.25995 | train_accuracy: 0.89843 | valid_logloss: 0.29262 | valid_accuracy: 0.89007 |  0:07:05s\n",
            "epoch 211| loss: 0.26569 | train_logloss: 0.25978 | train_accuracy: 0.8985  | valid_logloss: 0.29092 | valid_accuracy: 0.89127 |  0:07:07s\n",
            "epoch 212| loss: 0.26343 | train_logloss: 0.25797 | train_accuracy: 0.89987 | valid_logloss: 0.28821 | valid_accuracy: 0.89087 |  0:07:09s\n",
            "epoch 213| loss: 0.264   | train_logloss: 0.25724 | train_accuracy: 0.9001  | valid_logloss: 0.29001 | valid_accuracy: 0.89003 |  0:07:11s\n",
            "epoch 214| loss: 0.26343 | train_logloss: 0.26481 | train_accuracy: 0.8983  | valid_logloss: 0.29383 | valid_accuracy: 0.8893  |  0:07:13s\n",
            "epoch 215| loss: 0.26428 | train_logloss: 0.25579 | train_accuracy: 0.9003  | valid_logloss: 0.28854 | valid_accuracy: 0.8918  |  0:07:15s\n",
            "epoch 216| loss: 0.2632  | train_logloss: 0.27258 | train_accuracy: 0.89423 | valid_logloss: 0.30016 | valid_accuracy: 0.88497 |  0:07:17s\n",
            "epoch 217| loss: 0.27913 | train_logloss: 0.27412 | train_accuracy: 0.89537 | valid_logloss: 0.29687 | valid_accuracy: 0.88767 |  0:07:19s\n",
            "epoch 218| loss: 0.28689 | train_logloss: 0.29804 | train_accuracy: 0.88667 | valid_logloss: 0.31993 | valid_accuracy: 0.88093 |  0:07:21s\n",
            "epoch 219| loss: 0.29416 | train_logloss: 0.28439 | train_accuracy: 0.88903 | valid_logloss: 0.30713 | valid_accuracy: 0.88263 |  0:07:23s\n",
            "epoch 220| loss: 0.29085 | train_logloss: 0.29592 | train_accuracy: 0.88703 | valid_logloss: 0.31433 | valid_accuracy: 0.8823  |  0:07:25s\n",
            "epoch 221| loss: 0.29377 | train_logloss: 0.28096 | train_accuracy: 0.89207 | valid_logloss: 0.29895 | valid_accuracy: 0.88587 |  0:07:27s\n",
            "epoch 222| loss: 0.28261 | train_logloss: 0.27603 | train_accuracy: 0.8948  | valid_logloss: 0.2976  | valid_accuracy: 0.88757 |  0:07:29s\n",
            "epoch 223| loss: 0.2771  | train_logloss: 0.2703  | train_accuracy: 0.896   | valid_logloss: 0.29417 | valid_accuracy: 0.88783 |  0:07:31s\n",
            "epoch 224| loss: 0.27434 | train_logloss: 0.27262 | train_accuracy: 0.8961  | valid_logloss: 0.29151 | valid_accuracy: 0.88927 |  0:07:33s\n",
            "epoch 225| loss: 0.27197 | train_logloss: 0.26906 | train_accuracy: 0.8964  | valid_logloss: 0.29357 | valid_accuracy: 0.88843 |  0:07:35s\n",
            "epoch 226| loss: 0.27172 | train_logloss: 0.27187 | train_accuracy: 0.89507 | valid_logloss: 0.2999  | valid_accuracy: 0.8857  |  0:07:37s\n",
            "epoch 227| loss: 0.27453 | train_logloss: 0.27007 | train_accuracy: 0.89687 | valid_logloss: 0.2946  | valid_accuracy: 0.88833 |  0:07:39s\n",
            "epoch 228| loss: 0.27143 | train_logloss: 0.26541 | train_accuracy: 0.89863 | valid_logloss: 0.29274 | valid_accuracy: 0.8902  |  0:07:41s\n",
            "epoch 229| loss: 0.26697 | train_logloss: 0.26652 | train_accuracy: 0.89847 | valid_logloss: 0.29501 | valid_accuracy: 0.88963 |  0:07:43s\n",
            "epoch 230| loss: 0.26842 | train_logloss: 0.26864 | train_accuracy: 0.89573 | valid_logloss: 0.29824 | valid_accuracy: 0.88753 |  0:07:45s\n",
            "epoch 231| loss: 0.26783 | train_logloss: 0.26672 | train_accuracy: 0.89793 | valid_logloss: 0.29991 | valid_accuracy: 0.8877  |  0:07:47s\n",
            "epoch 232| loss: 0.27117 | train_logloss: 0.27305 | train_accuracy: 0.89877 | valid_logloss: 0.29813 | valid_accuracy: 0.88903 |  0:07:49s\n",
            "epoch 233| loss: 0.27605 | train_logloss: 0.27496 | train_accuracy: 0.89527 | valid_logloss: 0.30178 | valid_accuracy: 0.88727 |  0:07:51s\n",
            "epoch 234| loss: 0.26978 | train_logloss: 0.26977 | train_accuracy: 0.898   | valid_logloss: 0.2981  | valid_accuracy: 0.8873  |  0:07:53s\n",
            "epoch 235| loss: 0.27873 | train_logloss: 0.27646 | train_accuracy: 0.8958  | valid_logloss: 0.29989 | valid_accuracy: 0.8884  |  0:07:55s\n",
            "epoch 236| loss: 0.27742 | train_logloss: 0.27227 | train_accuracy: 0.8952  | valid_logloss: 0.29222 | valid_accuracy: 0.88923 |  0:07:57s\n",
            "epoch 237| loss: 0.27258 | train_logloss: 0.26689 | train_accuracy: 0.89833 | valid_logloss: 0.28873 | valid_accuracy: 0.89077 |  0:07:59s\n",
            "epoch 238| loss: 0.26976 | train_logloss: 0.26903 | train_accuracy: 0.89627 | valid_logloss: 0.29601 | valid_accuracy: 0.88953 |  0:08:01s\n",
            "epoch 239| loss: 0.26651 | train_logloss: 0.26101 | train_accuracy: 0.89923 | valid_logloss: 0.29194 | valid_accuracy: 0.89037 |  0:08:03s\n",
            "epoch 240| loss: 0.26565 | train_logloss: 0.26529 | train_accuracy: 0.89777 | valid_logloss: 0.2974  | valid_accuracy: 0.89037 |  0:08:05s\n",
            "epoch 241| loss: 0.27387 | train_logloss: 0.27394 | train_accuracy: 0.89647 | valid_logloss: 0.30104 | valid_accuracy: 0.88717 |  0:08:07s\n",
            "epoch 242| loss: 0.27443 | train_logloss: 0.26604 | train_accuracy: 0.89767 | valid_logloss: 0.29354 | valid_accuracy: 0.89143 |  0:08:09s\n",
            "epoch 243| loss: 0.27175 | train_logloss: 0.268   | train_accuracy: 0.89753 | valid_logloss: 0.29172 | valid_accuracy: 0.88963 |  0:08:11s\n",
            "epoch 244| loss: 0.27384 | train_logloss: 0.26792 | train_accuracy: 0.89793 | valid_logloss: 0.29288 | valid_accuracy: 0.8897  |  0:08:13s\n",
            "epoch 245| loss: 0.27788 | train_logloss: 0.2868  | train_accuracy: 0.88697 | valid_logloss: 0.30974 | valid_accuracy: 0.88013 |  0:08:15s\n",
            "\n",
            "Early stopping occurred at epoch 245 with best_epoch = 195 and best_valid_accuracy = 0.8926\n",
            "Best weights from best epoch are automatically used!\n",
            "TN\n",
            "GB\n",
            "Successfully saved model at /content/drive/MyDrive/Научная работа/Data/hyper/tn17.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRBx3JDt-Veh",
        "outputId": "68751604-cf81-4204-d315-2d0aeb61cfe6"
      },
      "source": [
        "ones(number_exp=18, \n",
        "     Rows=30000, \n",
        "     Nd=16,\tNa=16,\t\n",
        "     B=2048,\tBV=512,\tmB=0.7,\t\n",
        "     λsparse=0.0001,\tNsteps=5,\tγ=1.7, \n",
        "     learning_rate=0.02,\tdecay_rate=0.95,\tdecay_iterations=200,\t\n",
        "     shared=2, decision=2, \n",
        "     mask_type='entmax')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device used : cuda\n",
            "epoch 0  | loss: 1.0721  | train_logloss: 20.48473| train_accuracy: 0.3116  | valid_logloss: 20.52434| valid_accuracy: 0.31487 |  0:00:02s\n",
            "epoch 1  | loss: 0.62702 | train_logloss: 7.26988 | train_accuracy: 0.28423 | valid_logloss: 7.35665 | valid_accuracy: 0.28297 |  0:00:04s\n",
            "epoch 2  | loss: 0.4926  | train_logloss: 4.78337 | train_accuracy: 0.3647  | valid_logloss: 4.88082 | valid_accuracy: 0.36347 |  0:00:06s\n",
            "epoch 3  | loss: 0.44313 | train_logloss: 3.25561 | train_accuracy: 0.29043 | valid_logloss: 3.28029 | valid_accuracy: 0.29257 |  0:00:08s\n",
            "epoch 4  | loss: 0.4382  | train_logloss: 5.81552 | train_accuracy: 0.35523 | valid_logloss: 5.85558 | valid_accuracy: 0.35263 |  0:00:10s\n",
            "epoch 5  | loss: 0.42124 | train_logloss: 3.80157 | train_accuracy: 0.3198  | valid_logloss: 3.82596 | valid_accuracy: 0.32247 |  0:00:12s\n",
            "epoch 6  | loss: 0.40068 | train_logloss: 2.142   | train_accuracy: 0.3114  | valid_logloss: 2.15032 | valid_accuracy: 0.31263 |  0:00:14s\n",
            "epoch 7  | loss: 0.39334 | train_logloss: 1.34959 | train_accuracy: 0.4055  | valid_logloss: 1.36478 | valid_accuracy: 0.40283 |  0:00:16s\n",
            "epoch 8  | loss: 0.38421 | train_logloss: 2.04112 | train_accuracy: 0.2778  | valid_logloss: 2.0746  | valid_accuracy: 0.27353 |  0:00:18s\n",
            "epoch 9  | loss: 0.36923 | train_logloss: 1.39782 | train_accuracy: 0.4167  | valid_logloss: 1.41947 | valid_accuracy: 0.40707 |  0:00:20s\n",
            "epoch 10 | loss: 0.35991 | train_logloss: 0.93261 | train_accuracy: 0.6835  | valid_logloss: 0.94757 | valid_accuracy: 0.67823 |  0:00:22s\n",
            "epoch 11 | loss: 0.36143 | train_logloss: 0.92531 | train_accuracy: 0.67113 | valid_logloss: 0.94228 | valid_accuracy: 0.66313 |  0:00:24s\n",
            "epoch 12 | loss: 0.36208 | train_logloss: 0.75854 | train_accuracy: 0.63137 | valid_logloss: 0.77162 | valid_accuracy: 0.62067 |  0:00:26s\n",
            "epoch 13 | loss: 0.35072 | train_logloss: 0.65422 | train_accuracy: 0.72803 | valid_logloss: 0.66262 | valid_accuracy: 0.72177 |  0:00:28s\n",
            "epoch 14 | loss: 0.34479 | train_logloss: 0.64139 | train_accuracy: 0.77137 | valid_logloss: 0.65007 | valid_accuracy: 0.76677 |  0:00:30s\n",
            "epoch 15 | loss: 0.33878 | train_logloss: 0.54607 | train_accuracy: 0.8126  | valid_logloss: 0.55488 | valid_accuracy: 0.80833 |  0:00:33s\n",
            "epoch 16 | loss: 0.33383 | train_logloss: 0.49983 | train_accuracy: 0.8259  | valid_logloss: 0.50804 | valid_accuracy: 0.82147 |  0:00:35s\n",
            "epoch 17 | loss: 0.33658 | train_logloss: 0.39857 | train_accuracy: 0.85717 | valid_logloss: 0.40424 | valid_accuracy: 0.8565  |  0:00:37s\n",
            "epoch 18 | loss: 0.34441 | train_logloss: 0.39084 | train_accuracy: 0.8579  | valid_logloss: 0.39665 | valid_accuracy: 0.8559  |  0:00:39s\n",
            "epoch 19 | loss: 0.33534 | train_logloss: 0.39496 | train_accuracy: 0.86057 | valid_logloss: 0.39884 | valid_accuracy: 0.8598  |  0:00:41s\n",
            "epoch 20 | loss: 0.34243 | train_logloss: 0.37095 | train_accuracy: 0.86187 | valid_logloss: 0.37499 | valid_accuracy: 0.85943 |  0:00:43s\n",
            "epoch 21 | loss: 0.35844 | train_logloss: 0.36074 | train_accuracy: 0.8628  | valid_logloss: 0.36884 | valid_accuracy: 0.861   |  0:00:45s\n",
            "epoch 22 | loss: 0.34144 | train_logloss: 0.35265 | train_accuracy: 0.8701  | valid_logloss: 0.36195 | valid_accuracy: 0.86793 |  0:00:47s\n",
            "epoch 23 | loss: 0.33422 | train_logloss: 0.34395 | train_accuracy: 0.8682  | valid_logloss: 0.35279 | valid_accuracy: 0.86477 |  0:00:49s\n",
            "epoch 24 | loss: 0.32953 | train_logloss: 0.3424  | train_accuracy: 0.87227 | valid_logloss: 0.35381 | valid_accuracy: 0.86943 |  0:00:51s\n",
            "epoch 25 | loss: 0.33326 | train_logloss: 0.34047 | train_accuracy: 0.871   | valid_logloss: 0.35438 | valid_accuracy: 0.86863 |  0:00:53s\n",
            "epoch 26 | loss: 0.32762 | train_logloss: 0.33234 | train_accuracy: 0.87097 | valid_logloss: 0.34278 | valid_accuracy: 0.86967 |  0:00:55s\n",
            "epoch 27 | loss: 0.32341 | train_logloss: 0.32039 | train_accuracy: 0.87537 | valid_logloss: 0.33346 | valid_accuracy: 0.8721  |  0:00:57s\n",
            "epoch 28 | loss: 0.32219 | train_logloss: 0.32146 | train_accuracy: 0.87773 | valid_logloss: 0.33367 | valid_accuracy: 0.87467 |  0:00:59s\n",
            "epoch 29 | loss: 0.32317 | train_logloss: 0.31209 | train_accuracy: 0.8778  | valid_logloss: 0.32736 | valid_accuracy: 0.87483 |  0:01:02s\n",
            "epoch 30 | loss: 0.31925 | train_logloss: 0.31908 | train_accuracy: 0.87643 | valid_logloss: 0.33484 | valid_accuracy: 0.8716  |  0:01:04s\n",
            "epoch 31 | loss: 0.31853 | train_logloss: 0.31679 | train_accuracy: 0.87993 | valid_logloss: 0.33483 | valid_accuracy: 0.8722  |  0:01:06s\n",
            "epoch 32 | loss: 0.32118 | train_logloss: 0.32433 | train_accuracy: 0.87767 | valid_logloss: 0.33863 | valid_accuracy: 0.8734  |  0:01:08s\n",
            "epoch 33 | loss: 0.31992 | train_logloss: 0.31434 | train_accuracy: 0.88153 | valid_logloss: 0.32799 | valid_accuracy: 0.874   |  0:01:10s\n",
            "epoch 34 | loss: 0.3181  | train_logloss: 0.30971 | train_accuracy: 0.88043 | valid_logloss: 0.32648 | valid_accuracy: 0.8765  |  0:01:12s\n",
            "epoch 35 | loss: 0.31753 | train_logloss: 0.31938 | train_accuracy: 0.8773  | valid_logloss: 0.33488 | valid_accuracy: 0.87233 |  0:01:14s\n",
            "epoch 36 | loss: 0.32233 | train_logloss: 0.31166 | train_accuracy: 0.8807  | valid_logloss: 0.32691 | valid_accuracy: 0.8747  |  0:01:16s\n",
            "epoch 37 | loss: 0.31679 | train_logloss: 0.30835 | train_accuracy: 0.88147 | valid_logloss: 0.3208  | valid_accuracy: 0.87877 |  0:01:18s\n",
            "epoch 38 | loss: 0.31735 | train_logloss: 0.32477 | train_accuracy: 0.87737 | valid_logloss: 0.33791 | valid_accuracy: 0.87397 |  0:01:20s\n",
            "epoch 39 | loss: 0.3302  | train_logloss: 0.3245  | train_accuracy: 0.8773  | valid_logloss: 0.33604 | valid_accuracy: 0.873   |  0:01:22s\n",
            "epoch 40 | loss: 0.32972 | train_logloss: 0.3186  | train_accuracy: 0.8783  | valid_logloss: 0.32822 | valid_accuracy: 0.87497 |  0:01:24s\n",
            "epoch 41 | loss: 0.33287 | train_logloss: 0.33    | train_accuracy: 0.87767 | valid_logloss: 0.33803 | valid_accuracy: 0.87453 |  0:01:27s\n",
            "epoch 42 | loss: 0.3288  | train_logloss: 0.31949 | train_accuracy: 0.87983 | valid_logloss: 0.32887 | valid_accuracy: 0.87647 |  0:01:29s\n",
            "epoch 43 | loss: 0.33366 | train_logloss: 0.36999 | train_accuracy: 0.8547  | valid_logloss: 0.38024 | valid_accuracy: 0.8549  |  0:01:31s\n",
            "epoch 44 | loss: 0.36122 | train_logloss: 0.35163 | train_accuracy: 0.8677  | valid_logloss: 0.36271 | valid_accuracy: 0.86447 |  0:01:33s\n",
            "epoch 45 | loss: 0.36099 | train_logloss: 0.35869 | train_accuracy: 0.8667  | valid_logloss: 0.36364 | valid_accuracy: 0.8671  |  0:01:35s\n",
            "epoch 46 | loss: 0.36181 | train_logloss: 0.35149 | train_accuracy: 0.86917 | valid_logloss: 0.36073 | valid_accuracy: 0.86683 |  0:01:37s\n",
            "epoch 47 | loss: 0.34776 | train_logloss: 0.34358 | train_accuracy: 0.87183 | valid_logloss: 0.35279 | valid_accuracy: 0.8703  |  0:01:39s\n",
            "epoch 48 | loss: 0.34301 | train_logloss: 0.34459 | train_accuracy: 0.87073 | valid_logloss: 0.35203 | valid_accuracy: 0.8676  |  0:01:41s\n",
            "epoch 49 | loss: 0.34192 | train_logloss: 0.33294 | train_accuracy: 0.87473 | valid_logloss: 0.33943 | valid_accuracy: 0.8718  |  0:01:43s\n",
            "epoch 50 | loss: 0.34117 | train_logloss: 0.34001 | train_accuracy: 0.8708  | valid_logloss: 0.34509 | valid_accuracy: 0.86953 |  0:01:45s\n",
            "epoch 51 | loss: 0.33987 | train_logloss: 0.34442 | train_accuracy: 0.8704  | valid_logloss: 0.35111 | valid_accuracy: 0.86927 |  0:01:47s\n",
            "epoch 52 | loss: 0.34994 | train_logloss: 0.34002 | train_accuracy: 0.8726  | valid_logloss: 0.34634 | valid_accuracy: 0.87077 |  0:01:49s\n",
            "epoch 53 | loss: 0.3369  | train_logloss: 0.32543 | train_accuracy: 0.87647 | valid_logloss: 0.33239 | valid_accuracy: 0.87377 |  0:01:51s\n",
            "epoch 54 | loss: 0.33345 | train_logloss: 0.34132 | train_accuracy: 0.87113 | valid_logloss: 0.34995 | valid_accuracy: 0.86843 |  0:01:53s\n",
            "epoch 55 | loss: 0.33686 | train_logloss: 0.3314  | train_accuracy: 0.87517 | valid_logloss: 0.34065 | valid_accuracy: 0.8706  |  0:01:56s\n",
            "epoch 56 | loss: 0.32852 | train_logloss: 0.32283 | train_accuracy: 0.8765  | valid_logloss: 0.33137 | valid_accuracy: 0.87413 |  0:01:58s\n",
            "epoch 57 | loss: 0.32582 | train_logloss: 0.31916 | train_accuracy: 0.87847 | valid_logloss: 0.3293  | valid_accuracy: 0.87507 |  0:02:00s\n",
            "epoch 58 | loss: 0.32467 | train_logloss: 0.33451 | train_accuracy: 0.87117 | valid_logloss: 0.34933 | valid_accuracy: 0.86673 |  0:02:02s\n",
            "epoch 59 | loss: 0.33102 | train_logloss: 0.32348 | train_accuracy: 0.87717 | valid_logloss: 0.33785 | valid_accuracy: 0.873   |  0:02:04s\n",
            "epoch 60 | loss: 0.32731 | train_logloss: 0.32795 | train_accuracy: 0.87493 | valid_logloss: 0.33929 | valid_accuracy: 0.8715  |  0:02:06s\n",
            "epoch 61 | loss: 0.33617 | train_logloss: 0.32658 | train_accuracy: 0.877   | valid_logloss: 0.33882 | valid_accuracy: 0.87263 |  0:02:08s\n",
            "epoch 62 | loss: 0.32664 | train_logloss: 0.31847 | train_accuracy: 0.87857 | valid_logloss: 0.33201 | valid_accuracy: 0.87457 |  0:02:10s\n",
            "epoch 63 | loss: 0.32063 | train_logloss: 0.31143 | train_accuracy: 0.8811  | valid_logloss: 0.32449 | valid_accuracy: 0.87733 |  0:02:12s\n",
            "epoch 64 | loss: 0.32056 | train_logloss: 0.30953 | train_accuracy: 0.88197 | valid_logloss: 0.32281 | valid_accuracy: 0.8778  |  0:02:14s\n",
            "epoch 65 | loss: 0.31719 | train_logloss: 0.31554 | train_accuracy: 0.87957 | valid_logloss: 0.32795 | valid_accuracy: 0.87697 |  0:02:16s\n",
            "epoch 66 | loss: 0.32752 | train_logloss: 0.36298 | train_accuracy: 0.86153 | valid_logloss: 0.36992 | valid_accuracy: 0.86037 |  0:02:18s\n",
            "epoch 67 | loss: 0.34035 | train_logloss: 0.32633 | train_accuracy: 0.8742  | valid_logloss: 0.33685 | valid_accuracy: 0.87483 |  0:02:20s\n",
            "epoch 68 | loss: 0.32298 | train_logloss: 0.32032 | train_accuracy: 0.87837 | valid_logloss: 0.33164 | valid_accuracy: 0.8775  |  0:02:22s\n",
            "epoch 69 | loss: 0.32361 | train_logloss: 0.31667 | train_accuracy: 0.88057 | valid_logloss: 0.32589 | valid_accuracy: 0.87807 |  0:02:24s\n",
            "epoch 70 | loss: 0.31694 | train_logloss: 0.30773 | train_accuracy: 0.88093 | valid_logloss: 0.31684 | valid_accuracy: 0.88077 |  0:02:26s\n",
            "epoch 71 | loss: 0.31268 | train_logloss: 0.30908 | train_accuracy: 0.8823  | valid_logloss: 0.31715 | valid_accuracy: 0.8799  |  0:02:28s\n",
            "epoch 72 | loss: 0.31259 | train_logloss: 0.30612 | train_accuracy: 0.88053 | valid_logloss: 0.31917 | valid_accuracy: 0.87793 |  0:02:30s\n",
            "epoch 73 | loss: 0.30778 | train_logloss: 0.3011  | train_accuracy: 0.88453 | valid_logloss: 0.31364 | valid_accuracy: 0.8811  |  0:02:32s\n",
            "epoch 74 | loss: 0.30228 | train_logloss: 0.29713 | train_accuracy: 0.88537 | valid_logloss: 0.30912 | valid_accuracy: 0.88193 |  0:02:34s\n",
            "epoch 75 | loss: 0.30166 | train_logloss: 0.29897 | train_accuracy: 0.8848  | valid_logloss: 0.3109  | valid_accuracy: 0.88263 |  0:02:36s\n",
            "epoch 76 | loss: 0.30514 | train_logloss: 0.30238 | train_accuracy: 0.88397 | valid_logloss: 0.31618 | valid_accuracy: 0.88063 |  0:02:38s\n",
            "epoch 77 | loss: 0.30687 | train_logloss: 0.30146 | train_accuracy: 0.88403 | valid_logloss: 0.31432 | valid_accuracy: 0.87963 |  0:02:41s\n",
            "epoch 78 | loss: 0.30118 | train_logloss: 0.294   | train_accuracy: 0.88757 | valid_logloss: 0.30804 | valid_accuracy: 0.88373 |  0:02:42s\n",
            "epoch 79 | loss: 0.30063 | train_logloss: 0.29697 | train_accuracy: 0.88603 | valid_logloss: 0.31109 | valid_accuracy: 0.88293 |  0:02:45s\n",
            "epoch 80 | loss: 0.29783 | train_logloss: 0.29716 | train_accuracy: 0.8841  | valid_logloss: 0.31014 | valid_accuracy: 0.8827  |  0:02:47s\n",
            "epoch 81 | loss: 0.29859 | train_logloss: 0.29616 | train_accuracy: 0.88483 | valid_logloss: 0.31123 | valid_accuracy: 0.88183 |  0:02:49s\n",
            "epoch 82 | loss: 0.29977 | train_logloss: 0.29965 | train_accuracy: 0.88437 | valid_logloss: 0.31709 | valid_accuracy: 0.88147 |  0:02:51s\n",
            "epoch 83 | loss: 0.30154 | train_logloss: 0.2972  | train_accuracy: 0.88537 | valid_logloss: 0.31163 | valid_accuracy: 0.88233 |  0:02:53s\n",
            "epoch 84 | loss: 0.30465 | train_logloss: 0.29776 | train_accuracy: 0.88693 | valid_logloss: 0.31187 | valid_accuracy: 0.8831  |  0:02:55s\n",
            "epoch 85 | loss: 0.29823 | train_logloss: 0.30347 | train_accuracy: 0.8849  | valid_logloss: 0.31903 | valid_accuracy: 0.88023 |  0:02:57s\n",
            "epoch 86 | loss: 0.31783 | train_logloss: 0.31415 | train_accuracy: 0.8813  | valid_logloss: 0.32569 | valid_accuracy: 0.87683 |  0:02:59s\n",
            "epoch 87 | loss: 0.3147  | train_logloss: 0.31408 | train_accuracy: 0.878   | valid_logloss: 0.32479 | valid_accuracy: 0.87543 |  0:03:01s\n",
            "epoch 88 | loss: 0.30986 | train_logloss: 0.30321 | train_accuracy: 0.88353 | valid_logloss: 0.31575 | valid_accuracy: 0.87987 |  0:03:03s\n",
            "epoch 89 | loss: 0.30653 | train_logloss: 0.29653 | train_accuracy: 0.8853  | valid_logloss: 0.3098  | valid_accuracy: 0.88097 |  0:03:05s\n",
            "epoch 90 | loss: 0.29841 | train_logloss: 0.30086 | train_accuracy: 0.8864  | valid_logloss: 0.31523 | valid_accuracy: 0.8836  |  0:03:07s\n",
            "epoch 91 | loss: 0.30355 | train_logloss: 0.29664 | train_accuracy: 0.88593 | valid_logloss: 0.31054 | valid_accuracy: 0.88127 |  0:03:09s\n",
            "epoch 92 | loss: 0.29839 | train_logloss: 0.29472 | train_accuracy: 0.88503 | valid_logloss: 0.30962 | valid_accuracy: 0.88027 |  0:03:11s\n",
            "epoch 93 | loss: 0.29636 | train_logloss: 0.29552 | train_accuracy: 0.88707 | valid_logloss: 0.31089 | valid_accuracy: 0.88197 |  0:03:13s\n",
            "epoch 94 | loss: 0.29494 | train_logloss: 0.28877 | train_accuracy: 0.88867 | valid_logloss: 0.30618 | valid_accuracy: 0.88393 |  0:03:15s\n",
            "epoch 95 | loss: 0.29462 | train_logloss: 0.29225 | train_accuracy: 0.88807 | valid_logloss: 0.3087  | valid_accuracy: 0.88513 |  0:03:17s\n",
            "epoch 96 | loss: 0.29659 | train_logloss: 0.29097 | train_accuracy: 0.88827 | valid_logloss: 0.30521 | valid_accuracy: 0.885   |  0:03:19s\n",
            "epoch 97 | loss: 0.2951  | train_logloss: 0.28936 | train_accuracy: 0.8885  | valid_logloss: 0.30325 | valid_accuracy: 0.8861  |  0:03:21s\n",
            "epoch 98 | loss: 0.2923  | train_logloss: 0.28761 | train_accuracy: 0.88833 | valid_logloss: 0.30374 | valid_accuracy: 0.88543 |  0:03:23s\n",
            "epoch 99 | loss: 0.29853 | train_logloss: 0.29645 | train_accuracy: 0.88343 | valid_logloss: 0.30816 | valid_accuracy: 0.8824  |  0:03:25s\n",
            "epoch 100| loss: 0.29969 | train_logloss: 0.28781 | train_accuracy: 0.88757 | valid_logloss: 0.30166 | valid_accuracy: 0.8847  |  0:03:27s\n",
            "epoch 101| loss: 0.29417 | train_logloss: 0.29253 | train_accuracy: 0.88803 | valid_logloss: 0.30483 | valid_accuracy: 0.8845  |  0:03:29s\n",
            "epoch 102| loss: 0.2961  | train_logloss: 0.2885  | train_accuracy: 0.88847 | valid_logloss: 0.30063 | valid_accuracy: 0.88543 |  0:03:31s\n",
            "epoch 103| loss: 0.2927  | train_logloss: 0.28873 | train_accuracy: 0.88853 | valid_logloss: 0.30264 | valid_accuracy: 0.88657 |  0:03:33s\n",
            "epoch 104| loss: 0.28977 | train_logloss: 0.28468 | train_accuracy: 0.88973 | valid_logloss: 0.30263 | valid_accuracy: 0.88433 |  0:03:35s\n",
            "epoch 105| loss: 0.28876 | train_logloss: 0.28477 | train_accuracy: 0.88967 | valid_logloss: 0.30109 | valid_accuracy: 0.88523 |  0:03:37s\n",
            "epoch 106| loss: 0.28888 | train_logloss: 0.28333 | train_accuracy: 0.89023 | valid_logloss: 0.30089 | valid_accuracy: 0.8855  |  0:03:39s\n",
            "epoch 107| loss: 0.28863 | train_logloss: 0.28617 | train_accuracy: 0.8891  | valid_logloss: 0.30199 | valid_accuracy: 0.8842  |  0:03:41s\n",
            "epoch 108| loss: 0.29166 | train_logloss: 0.28963 | train_accuracy: 0.89037 | valid_logloss: 0.31013 | valid_accuracy: 0.88483 |  0:03:43s\n",
            "epoch 109| loss: 0.29072 | train_logloss: 0.28823 | train_accuracy: 0.89087 | valid_logloss: 0.30807 | valid_accuracy: 0.886   |  0:03:45s\n",
            "epoch 110| loss: 0.2899  | train_logloss: 0.29326 | train_accuracy: 0.88747 | valid_logloss: 0.3089  | valid_accuracy: 0.88283 |  0:03:47s\n",
            "epoch 111| loss: 0.29537 | train_logloss: 0.28919 | train_accuracy: 0.89003 | valid_logloss: 0.30315 | valid_accuracy: 0.88627 |  0:03:49s\n",
            "epoch 112| loss: 0.29401 | train_logloss: 0.29495 | train_accuracy: 0.88617 | valid_logloss: 0.30834 | valid_accuracy: 0.88313 |  0:03:51s\n",
            "epoch 113| loss: 0.2947  | train_logloss: 0.28594 | train_accuracy: 0.89043 | valid_logloss: 0.29893 | valid_accuracy: 0.8872  |  0:03:53s\n",
            "epoch 114| loss: 0.29162 | train_logloss: 0.2856  | train_accuracy: 0.88983 | valid_logloss: 0.30138 | valid_accuracy: 0.88673 |  0:03:55s\n",
            "epoch 115| loss: 0.29783 | train_logloss: 0.29854 | train_accuracy: 0.88473 | valid_logloss: 0.31239 | valid_accuracy: 0.88163 |  0:03:57s\n",
            "epoch 116| loss: 0.30822 | train_logloss: 0.30237 | train_accuracy: 0.88513 | valid_logloss: 0.31138 | valid_accuracy: 0.88223 |  0:03:59s\n",
            "epoch 117| loss: 0.30385 | train_logloss: 0.29642 | train_accuracy: 0.88597 | valid_logloss: 0.31085 | valid_accuracy: 0.8825  |  0:04:01s\n",
            "epoch 118| loss: 0.29666 | train_logloss: 0.29031 | train_accuracy: 0.88833 | valid_logloss: 0.3052  | valid_accuracy: 0.884   |  0:04:03s\n",
            "epoch 119| loss: 0.29436 | train_logloss: 0.28863 | train_accuracy: 0.89103 | valid_logloss: 0.30378 | valid_accuracy: 0.88607 |  0:04:05s\n",
            "epoch 120| loss: 0.29266 | train_logloss: 0.28664 | train_accuracy: 0.8898  | valid_logloss: 0.30107 | valid_accuracy: 0.88673 |  0:04:07s\n",
            "epoch 121| loss: 0.29158 | train_logloss: 0.2887  | train_accuracy: 0.88823 | valid_logloss: 0.30416 | valid_accuracy: 0.88443 |  0:04:09s\n",
            "epoch 122| loss: 0.28949 | train_logloss: 0.28323 | train_accuracy: 0.8927  | valid_logloss: 0.30021 | valid_accuracy: 0.88617 |  0:04:11s\n",
            "epoch 123| loss: 0.29078 | train_logloss: 0.28858 | train_accuracy: 0.89043 | valid_logloss: 0.30491 | valid_accuracy: 0.88483 |  0:04:13s\n",
            "epoch 124| loss: 0.28991 | train_logloss: 0.30816 | train_accuracy: 0.88403 | valid_logloss: 0.32276 | valid_accuracy: 0.88    |  0:04:15s\n",
            "epoch 125| loss: 0.29713 | train_logloss: 0.28751 | train_accuracy: 0.88977 | valid_logloss: 0.30317 | valid_accuracy: 0.8841  |  0:04:17s\n",
            "epoch 126| loss: 0.2915  | train_logloss: 0.28604 | train_accuracy: 0.8908  | valid_logloss: 0.30158 | valid_accuracy: 0.88463 |  0:04:19s\n",
            "epoch 127| loss: 0.2886  | train_logloss: 0.28589 | train_accuracy: 0.88953 | valid_logloss: 0.30317 | valid_accuracy: 0.88403 |  0:04:21s\n",
            "epoch 128| loss: 0.28848 | train_logloss: 0.2851  | train_accuracy: 0.89143 | valid_logloss: 0.30311 | valid_accuracy: 0.8843  |  0:04:23s\n",
            "epoch 129| loss: 0.2903  | train_logloss: 0.28506 | train_accuracy: 0.88873 | valid_logloss: 0.30325 | valid_accuracy: 0.88343 |  0:04:25s\n",
            "epoch 130| loss: 0.2894  | train_logloss: 0.28965 | train_accuracy: 0.89057 | valid_logloss: 0.30727 | valid_accuracy: 0.8842  |  0:04:27s\n",
            "epoch 131| loss: 0.28762 | train_logloss: 0.28461 | train_accuracy: 0.89223 | valid_logloss: 0.30297 | valid_accuracy: 0.8849  |  0:04:29s\n",
            "epoch 132| loss: 0.285   | train_logloss: 0.27961 | train_accuracy: 0.89263 | valid_logloss: 0.29898 | valid_accuracy: 0.88577 |  0:04:31s\n",
            "epoch 133| loss: 0.2856  | train_logloss: 0.28006 | train_accuracy: 0.89123 | valid_logloss: 0.29784 | valid_accuracy: 0.88593 |  0:04:33s\n",
            "epoch 134| loss: 0.28631 | train_logloss: 0.27796 | train_accuracy: 0.8936  | valid_logloss: 0.29582 | valid_accuracy: 0.88547 |  0:04:35s\n",
            "epoch 135| loss: 0.28502 | train_logloss: 0.28171 | train_accuracy: 0.89147 | valid_logloss: 0.30053 | valid_accuracy: 0.8871  |  0:04:37s\n",
            "epoch 136| loss: 0.28233 | train_logloss: 0.28323 | train_accuracy: 0.8912  | valid_logloss: 0.29975 | valid_accuracy: 0.88393 |  0:04:39s\n",
            "epoch 137| loss: 0.28947 | train_logloss: 0.28355 | train_accuracy: 0.89027 | valid_logloss: 0.30281 | valid_accuracy: 0.88617 |  0:04:41s\n",
            "epoch 138| loss: 0.29231 | train_logloss: 0.29651 | train_accuracy: 0.88693 | valid_logloss: 0.31217 | valid_accuracy: 0.8844  |  0:04:43s\n",
            "epoch 139| loss: 0.29671 | train_logloss: 0.29588 | train_accuracy: 0.88577 | valid_logloss: 0.31043 | valid_accuracy: 0.88387 |  0:04:45s\n",
            "epoch 140| loss: 0.29229 | train_logloss: 0.28555 | train_accuracy: 0.88843 | valid_logloss: 0.30152 | valid_accuracy: 0.8868  |  0:04:47s\n",
            "epoch 141| loss: 0.28667 | train_logloss: 0.28253 | train_accuracy: 0.8922  | valid_logloss: 0.30055 | valid_accuracy: 0.88567 |  0:04:49s\n",
            "epoch 142| loss: 0.2838  | train_logloss: 0.2798  | train_accuracy: 0.89207 | valid_logloss: 0.29761 | valid_accuracy: 0.88663 |  0:04:51s\n",
            "epoch 143| loss: 0.28263 | train_logloss: 0.27713 | train_accuracy: 0.8931  | valid_logloss: 0.29762 | valid_accuracy: 0.88773 |  0:04:53s\n",
            "epoch 144| loss: 0.29312 | train_logloss: 0.29438 | train_accuracy: 0.88807 | valid_logloss: 0.30979 | valid_accuracy: 0.88223 |  0:04:55s\n",
            "epoch 145| loss: 0.29435 | train_logloss: 0.29418 | train_accuracy: 0.88613 | valid_logloss: 0.31456 | valid_accuracy: 0.87967 |  0:04:57s\n",
            "epoch 146| loss: 0.3019  | train_logloss: 0.29062 | train_accuracy: 0.88933 | valid_logloss: 0.30791 | valid_accuracy: 0.8841  |  0:04:59s\n",
            "epoch 147| loss: 0.29219 | train_logloss: 0.28273 | train_accuracy: 0.89143 | valid_logloss: 0.30019 | valid_accuracy: 0.88597 |  0:05:01s\n",
            "epoch 148| loss: 0.28887 | train_logloss: 0.27913 | train_accuracy: 0.8936  | valid_logloss: 0.29889 | valid_accuracy: 0.88717 |  0:05:03s\n",
            "epoch 149| loss: 0.28628 | train_logloss: 0.2815  | train_accuracy: 0.8928  | valid_logloss: 0.30365 | valid_accuracy: 0.88627 |  0:05:05s\n",
            "epoch 150| loss: 0.29148 | train_logloss: 0.29523 | train_accuracy: 0.8854  | valid_logloss: 0.31148 | valid_accuracy: 0.88047 |  0:05:07s\n",
            "epoch 151| loss: 0.29156 | train_logloss: 0.28685 | train_accuracy: 0.88903 | valid_logloss: 0.30559 | valid_accuracy: 0.88477 |  0:05:09s\n",
            "epoch 152| loss: 0.28895 | train_logloss: 0.28363 | train_accuracy: 0.8912  | valid_logloss: 0.30186 | valid_accuracy: 0.88377 |  0:05:11s\n",
            "epoch 153| loss: 0.28358 | train_logloss: 0.27792 | train_accuracy: 0.89273 | valid_logloss: 0.29818 | valid_accuracy: 0.8862  |  0:05:13s\n",
            "epoch 154| loss: 0.28502 | train_logloss: 0.28191 | train_accuracy: 0.89177 | valid_logloss: 0.30061 | valid_accuracy: 0.88553 |  0:05:15s\n",
            "epoch 155| loss: 0.2873  | train_logloss: 0.28285 | train_accuracy: 0.89017 | valid_logloss: 0.30119 | valid_accuracy: 0.886   |  0:05:17s\n",
            "epoch 156| loss: 0.2916  | train_logloss: 0.28573 | train_accuracy: 0.89197 | valid_logloss: 0.30249 | valid_accuracy: 0.886   |  0:05:19s\n",
            "epoch 157| loss: 0.29098 | train_logloss: 0.2845  | train_accuracy: 0.89053 | valid_logloss: 0.30209 | valid_accuracy: 0.8862  |  0:05:21s\n",
            "epoch 158| loss: 0.28928 | train_logloss: 0.28452 | train_accuracy: 0.8921  | valid_logloss: 0.30025 | valid_accuracy: 0.8885  |  0:05:23s\n",
            "epoch 159| loss: 0.28896 | train_logloss: 0.28423 | train_accuracy: 0.89053 | valid_logloss: 0.30158 | valid_accuracy: 0.8856  |  0:05:25s\n",
            "epoch 160| loss: 0.28667 | train_logloss: 0.27949 | train_accuracy: 0.89277 | valid_logloss: 0.29901 | valid_accuracy: 0.88813 |  0:05:27s\n",
            "epoch 161| loss: 0.28757 | train_logloss: 0.2874  | train_accuracy: 0.88827 | valid_logloss: 0.30536 | valid_accuracy: 0.88547 |  0:05:29s\n",
            "epoch 162| loss: 0.29313 | train_logloss: 0.29471 | train_accuracy: 0.8865  | valid_logloss: 0.31204 | valid_accuracy: 0.88117 |  0:05:31s\n",
            "epoch 163| loss: 0.29558 | train_logloss: 0.28574 | train_accuracy: 0.89093 | valid_logloss: 0.30555 | valid_accuracy: 0.8851  |  0:05:33s\n",
            "epoch 164| loss: 0.28722 | train_logloss: 0.27993 | train_accuracy: 0.892   | valid_logloss: 0.30142 | valid_accuracy: 0.88607 |  0:05:35s\n",
            "epoch 165| loss: 0.28414 | train_logloss: 0.27833 | train_accuracy: 0.8926  | valid_logloss: 0.29729 | valid_accuracy: 0.88927 |  0:05:37s\n",
            "epoch 166| loss: 0.28333 | train_logloss: 0.27734 | train_accuracy: 0.89387 | valid_logloss: 0.30068 | valid_accuracy: 0.88723 |  0:05:39s\n",
            "epoch 167| loss: 0.28187 | train_logloss: 0.2782  | train_accuracy: 0.89287 | valid_logloss: 0.30147 | valid_accuracy: 0.88587 |  0:05:41s\n",
            "epoch 168| loss: 0.28429 | train_logloss: 0.28651 | train_accuracy: 0.89063 | valid_logloss: 0.30885 | valid_accuracy: 0.88433 |  0:05:43s\n",
            "epoch 169| loss: 0.29058 | train_logloss: 0.2813  | train_accuracy: 0.8926  | valid_logloss: 0.30253 | valid_accuracy: 0.8862  |  0:05:45s\n",
            "epoch 170| loss: 0.28234 | train_logloss: 0.27975 | train_accuracy: 0.8912  | valid_logloss: 0.29938 | valid_accuracy: 0.8866  |  0:05:47s\n",
            "epoch 171| loss: 0.28526 | train_logloss: 0.28394 | train_accuracy: 0.89347 | valid_logloss: 0.29788 | valid_accuracy: 0.88793 |  0:05:49s\n",
            "epoch 172| loss: 0.2855  | train_logloss: 0.28728 | train_accuracy: 0.8917  | valid_logloss: 0.30292 | valid_accuracy: 0.8862  |  0:05:51s\n",
            "epoch 173| loss: 0.28274 | train_logloss: 0.27901 | train_accuracy: 0.8943  | valid_logloss: 0.29868 | valid_accuracy: 0.8879  |  0:05:53s\n",
            "epoch 174| loss: 0.28248 | train_logloss: 0.27409 | train_accuracy: 0.89443 | valid_logloss: 0.29338 | valid_accuracy: 0.8893  |  0:05:55s\n",
            "epoch 175| loss: 0.28451 | train_logloss: 0.28231 | train_accuracy: 0.89313 | valid_logloss: 0.30192 | valid_accuracy: 0.88703 |  0:05:57s\n",
            "epoch 176| loss: 0.28208 | train_logloss: 0.27588 | train_accuracy: 0.89387 | valid_logloss: 0.29491 | valid_accuracy: 0.88873 |  0:05:59s\n",
            "epoch 177| loss: 0.28024 | train_logloss: 0.27356 | train_accuracy: 0.89443 | valid_logloss: 0.29585 | valid_accuracy: 0.8881  |  0:06:01s\n",
            "epoch 178| loss: 0.27697 | train_logloss: 0.27657 | train_accuracy: 0.89183 | valid_logloss: 0.29854 | valid_accuracy: 0.88857 |  0:06:03s\n",
            "epoch 179| loss: 0.27632 | train_logloss: 0.27165 | train_accuracy: 0.89497 | valid_logloss: 0.29381 | valid_accuracy: 0.8889  |  0:06:05s\n",
            "epoch 180| loss: 0.27514 | train_logloss: 0.27138 | train_accuracy: 0.89543 | valid_logloss: 0.29585 | valid_accuracy: 0.88807 |  0:06:07s\n",
            "epoch 181| loss: 0.27933 | train_logloss: 0.28085 | train_accuracy: 0.8904  | valid_logloss: 0.30109 | valid_accuracy: 0.88693 |  0:06:09s\n",
            "epoch 182| loss: 0.28048 | train_logloss: 0.2739  | train_accuracy: 0.89457 | valid_logloss: 0.29348 | valid_accuracy: 0.8901  |  0:06:11s\n",
            "epoch 183| loss: 0.27598 | train_logloss: 0.27392 | train_accuracy: 0.89427 | valid_logloss: 0.29632 | valid_accuracy: 0.88907 |  0:06:13s\n",
            "epoch 184| loss: 0.27808 | train_logloss: 0.27132 | train_accuracy: 0.89533 | valid_logloss: 0.29501 | valid_accuracy: 0.8883  |  0:06:15s\n",
            "epoch 185| loss: 0.27451 | train_logloss: 0.27087 | train_accuracy: 0.8971  | valid_logloss: 0.29424 | valid_accuracy: 0.89063 |  0:06:17s\n",
            "epoch 186| loss: 0.27738 | train_logloss: 0.26597 | train_accuracy: 0.8973  | valid_logloss: 0.29087 | valid_accuracy: 0.89043 |  0:06:19s\n",
            "epoch 187| loss: 0.27284 | train_logloss: 0.26481 | train_accuracy: 0.89733 | valid_logloss: 0.29195 | valid_accuracy: 0.8901  |  0:06:21s\n",
            "epoch 188| loss: 0.27198 | train_logloss: 0.26528 | train_accuracy: 0.89777 | valid_logloss: 0.29029 | valid_accuracy: 0.89147 |  0:06:23s\n",
            "epoch 189| loss: 0.26994 | train_logloss: 0.27022 | train_accuracy: 0.8957  | valid_logloss: 0.29573 | valid_accuracy: 0.8893  |  0:06:25s\n",
            "epoch 190| loss: 0.27016 | train_logloss: 0.26559 | train_accuracy: 0.8973  | valid_logloss: 0.29195 | valid_accuracy: 0.89007 |  0:06:27s\n",
            "epoch 191| loss: 0.27049 | train_logloss: 0.26866 | train_accuracy: 0.89663 | valid_logloss: 0.29771 | valid_accuracy: 0.88677 |  0:06:29s\n",
            "epoch 192| loss: 0.27184 | train_logloss: 0.27726 | train_accuracy: 0.89497 | valid_logloss: 0.3085  | valid_accuracy: 0.88393 |  0:06:31s\n",
            "epoch 193| loss: 0.28232 | train_logloss: 0.27191 | train_accuracy: 0.8955  | valid_logloss: 0.29736 | valid_accuracy: 0.88873 |  0:06:33s\n",
            "epoch 194| loss: 0.27718 | train_logloss: 0.26705 | train_accuracy: 0.89727 | valid_logloss: 0.29394 | valid_accuracy: 0.88967 |  0:06:35s\n",
            "epoch 195| loss: 0.2862  | train_logloss: 0.32688 | train_accuracy: 0.88123 | valid_logloss: 0.33832 | valid_accuracy: 0.87627 |  0:06:37s\n",
            "epoch 196| loss: 0.30374 | train_logloss: 0.28732 | train_accuracy: 0.89123 | valid_logloss: 0.30627 | valid_accuracy: 0.88523 |  0:06:39s\n",
            "epoch 197| loss: 0.28761 | train_logloss: 0.28678 | train_accuracy: 0.89087 | valid_logloss: 0.30569 | valid_accuracy: 0.8858  |  0:06:41s\n",
            "epoch 198| loss: 0.28241 | train_logloss: 0.27526 | train_accuracy: 0.8935  | valid_logloss: 0.2954  | valid_accuracy: 0.88847 |  0:06:43s\n",
            "epoch 199| loss: 0.28075 | train_logloss: 0.2743  | train_accuracy: 0.89553 | valid_logloss: 0.29774 | valid_accuracy: 0.88843 |  0:06:45s\n",
            "epoch 200| loss: 0.2769  | train_logloss: 0.27187 | train_accuracy: 0.8954  | valid_logloss: 0.29708 | valid_accuracy: 0.88913 |  0:06:47s\n",
            "epoch 201| loss: 0.27565 | train_logloss: 0.27795 | train_accuracy: 0.8929  | valid_logloss: 0.30414 | valid_accuracy: 0.88657 |  0:06:49s\n",
            "epoch 202| loss: 0.28035 | train_logloss: 0.27685 | train_accuracy: 0.8936  | valid_logloss: 0.29509 | valid_accuracy: 0.8874  |  0:06:51s\n",
            "epoch 203| loss: 0.27828 | train_logloss: 0.26967 | train_accuracy: 0.89667 | valid_logloss: 0.293   | valid_accuracy: 0.88973 |  0:06:53s\n",
            "epoch 204| loss: 0.27842 | train_logloss: 0.27066 | train_accuracy: 0.8955  | valid_logloss: 0.29366 | valid_accuracy: 0.8893  |  0:06:55s\n",
            "epoch 205| loss: 0.27532 | train_logloss: 0.269   | train_accuracy: 0.89553 | valid_logloss: 0.29426 | valid_accuracy: 0.88893 |  0:06:57s\n",
            "epoch 206| loss: 0.2722  | train_logloss: 0.27194 | train_accuracy: 0.89317 | valid_logloss: 0.29736 | valid_accuracy: 0.88687 |  0:06:59s\n",
            "epoch 207| loss: 0.27339 | train_logloss: 0.26651 | train_accuracy: 0.89797 | valid_logloss: 0.29347 | valid_accuracy: 0.8882  |  0:07:01s\n",
            "epoch 208| loss: 0.27339 | train_logloss: 0.26685 | train_accuracy: 0.8977  | valid_logloss: 0.29235 | valid_accuracy: 0.89    |  0:07:03s\n",
            "epoch 209| loss: 0.27029 | train_logloss: 0.2641  | train_accuracy: 0.89917 | valid_logloss: 0.29264 | valid_accuracy: 0.88963 |  0:07:05s\n",
            "epoch 210| loss: 0.26937 | train_logloss: 0.26392 | train_accuracy: 0.89783 | valid_logloss: 0.29663 | valid_accuracy: 0.8887  |  0:07:07s\n",
            "epoch 211| loss: 0.26854 | train_logloss: 0.26281 | train_accuracy: 0.89843 | valid_logloss: 0.29376 | valid_accuracy: 0.88967 |  0:07:09s\n",
            "epoch 212| loss: 0.27452 | train_logloss: 0.27711 | train_accuracy: 0.89377 | valid_logloss: 0.30342 | valid_accuracy: 0.88673 |  0:07:11s\n",
            "epoch 213| loss: 0.27671 | train_logloss: 0.26866 | train_accuracy: 0.89647 | valid_logloss: 0.29479 | valid_accuracy: 0.8882  |  0:07:13s\n",
            "epoch 214| loss: 0.27195 | train_logloss: 0.26481 | train_accuracy: 0.8975  | valid_logloss: 0.29176 | valid_accuracy: 0.88987 |  0:07:16s\n",
            "epoch 215| loss: 0.26989 | train_logloss: 0.26513 | train_accuracy: 0.8972  | valid_logloss: 0.29397 | valid_accuracy: 0.89093 |  0:07:17s\n",
            "epoch 216| loss: 0.27027 | train_logloss: 0.26362 | train_accuracy: 0.898   | valid_logloss: 0.29274 | valid_accuracy: 0.88963 |  0:07:20s\n",
            "epoch 217| loss: 0.26623 | train_logloss: 0.26164 | train_accuracy: 0.9001  | valid_logloss: 0.29202 | valid_accuracy: 0.89037 |  0:07:22s\n",
            "epoch 218| loss: 0.26571 | train_logloss: 0.26241 | train_accuracy: 0.8995  | valid_logloss: 0.29477 | valid_accuracy: 0.8896  |  0:07:24s\n",
            "epoch 219| loss: 0.26664 | train_logloss: 0.25976 | train_accuracy: 0.8995  | valid_logloss: 0.29294 | valid_accuracy: 0.88937 |  0:07:26s\n",
            "epoch 220| loss: 0.26711 | train_logloss: 0.26537 | train_accuracy: 0.89807 | valid_logloss: 0.29732 | valid_accuracy: 0.88917 |  0:07:28s\n",
            "epoch 221| loss: 0.26658 | train_logloss: 0.25995 | train_accuracy: 0.89917 | valid_logloss: 0.2916  | valid_accuracy: 0.89007 |  0:07:30s\n",
            "epoch 222| loss: 0.2673  | train_logloss: 0.26162 | train_accuracy: 0.89893 | valid_logloss: 0.2925  | valid_accuracy: 0.8905  |  0:07:32s\n",
            "epoch 223| loss: 0.26618 | train_logloss: 0.26324 | train_accuracy: 0.89887 | valid_logloss: 0.29778 | valid_accuracy: 0.88977 |  0:07:34s\n",
            "epoch 224| loss: 0.2652  | train_logloss: 0.26261 | train_accuracy: 0.8977  | valid_logloss: 0.29519 | valid_accuracy: 0.89053 |  0:07:36s\n",
            "epoch 225| loss: 0.26423 | train_logloss: 0.25686 | train_accuracy: 0.9009  | valid_logloss: 0.2933  | valid_accuracy: 0.8913  |  0:07:38s\n",
            "epoch 226| loss: 0.26273 | train_logloss: 0.25545 | train_accuracy: 0.90063 | valid_logloss: 0.29231 | valid_accuracy: 0.89043 |  0:07:40s\n",
            "epoch 227| loss: 0.26255 | train_logloss: 0.25584 | train_accuracy: 0.9005  | valid_logloss: 0.29217 | valid_accuracy: 0.89143 |  0:07:42s\n",
            "epoch 228| loss: 0.25956 | train_logloss: 0.25575 | train_accuracy: 0.9006  | valid_logloss: 0.28865 | valid_accuracy: 0.89107 |  0:07:44s\n",
            "epoch 229| loss: 0.25952 | train_logloss: 0.25504 | train_accuracy: 0.90107 | valid_logloss: 0.29357 | valid_accuracy: 0.89147 |  0:07:46s\n",
            "epoch 230| loss: 0.27308 | train_logloss: 0.27744 | train_accuracy: 0.8939  | valid_logloss: 0.30525 | valid_accuracy: 0.88583 |  0:07:48s\n",
            "epoch 231| loss: 0.2756  | train_logloss: 0.2654  | train_accuracy: 0.8977  | valid_logloss: 0.2954  | valid_accuracy: 0.8893  |  0:07:50s\n",
            "epoch 232| loss: 0.27109 | train_logloss: 0.26601 | train_accuracy: 0.89613 | valid_logloss: 0.2968  | valid_accuracy: 0.88777 |  0:07:52s\n",
            "epoch 233| loss: 0.26694 | train_logloss: 0.26158 | train_accuracy: 0.89923 | valid_logloss: 0.29497 | valid_accuracy: 0.89023 |  0:07:54s\n",
            "epoch 234| loss: 0.26703 | train_logloss: 0.26414 | train_accuracy: 0.89757 | valid_logloss: 0.29627 | valid_accuracy: 0.88967 |  0:07:56s\n",
            "epoch 235| loss: 0.26891 | train_logloss: 0.26247 | train_accuracy: 0.89753 | valid_logloss: 0.29674 | valid_accuracy: 0.88933 |  0:07:58s\n",
            "epoch 236| loss: 0.2648  | train_logloss: 0.25947 | train_accuracy: 0.89883 | valid_logloss: 0.2955  | valid_accuracy: 0.89013 |  0:08:00s\n",
            "epoch 237| loss: 0.26411 | train_logloss: 0.25461 | train_accuracy: 0.9011  | valid_logloss: 0.29302 | valid_accuracy: 0.892   |  0:08:02s\n",
            "epoch 238| loss: 0.26003 | train_logloss: 0.25766 | train_accuracy: 0.89867 | valid_logloss: 0.29744 | valid_accuracy: 0.88993 |  0:08:04s\n",
            "epoch 239| loss: 0.2601  | train_logloss: 0.25471 | train_accuracy: 0.9016  | valid_logloss: 0.29461 | valid_accuracy: 0.89117 |  0:08:06s\n",
            "epoch 240| loss: 0.26437 | train_logloss: 0.26948 | train_accuracy: 0.89597 | valid_logloss: 0.30102 | valid_accuracy: 0.8889  |  0:08:08s\n",
            "epoch 241| loss: 0.27138 | train_logloss: 0.2643  | train_accuracy: 0.8975  | valid_logloss: 0.2999  | valid_accuracy: 0.8884  |  0:08:10s\n",
            "epoch 242| loss: 0.26557 | train_logloss: 0.25649 | train_accuracy: 0.90027 | valid_logloss: 0.29486 | valid_accuracy: 0.8906  |  0:08:12s\n",
            "epoch 243| loss: 0.26536 | train_logloss: 0.25769 | train_accuracy: 0.89917 | valid_logloss: 0.29773 | valid_accuracy: 0.89033 |  0:08:14s\n",
            "epoch 244| loss: 0.26142 | train_logloss: 0.25467 | train_accuracy: 0.9007  | valid_logloss: 0.29352 | valid_accuracy: 0.8916  |  0:08:16s\n",
            "epoch 245| loss: 0.25737 | train_logloss: 0.25418 | train_accuracy: 0.90203 | valid_logloss: 0.29455 | valid_accuracy: 0.89157 |  0:08:18s\n",
            "epoch 246| loss: 0.25858 | train_logloss: 0.25286 | train_accuracy: 0.9009  | valid_logloss: 0.2943  | valid_accuracy: 0.89083 |  0:08:20s\n",
            "epoch 247| loss: 0.25952 | train_logloss: 0.25374 | train_accuracy: 0.90157 | valid_logloss: 0.29939 | valid_accuracy: 0.8915  |  0:08:22s\n",
            "epoch 248| loss: 0.25929 | train_logloss: 0.25598 | train_accuracy: 0.90067 | valid_logloss: 0.3003  | valid_accuracy: 0.88927 |  0:08:24s\n",
            "epoch 249| loss: 0.26206 | train_logloss: 0.25927 | train_accuracy: 0.89893 | valid_logloss: 0.30242 | valid_accuracy: 0.88867 |  0:08:26s\n",
            "epoch 250| loss: 0.25907 | train_logloss: 0.25544 | train_accuracy: 0.90027 | valid_logloss: 0.30002 | valid_accuracy: 0.88907 |  0:08:28s\n",
            "epoch 251| loss: 0.26633 | train_logloss: 0.27912 | train_accuracy: 0.89017 | valid_logloss: 0.31513 | valid_accuracy: 0.88313 |  0:08:30s\n",
            "epoch 252| loss: 0.28278 | train_logloss: 0.274   | train_accuracy: 0.89303 | valid_logloss: 0.30406 | valid_accuracy: 0.88817 |  0:08:32s\n",
            "epoch 253| loss: 0.28233 | train_logloss: 0.27218 | train_accuracy: 0.8955  | valid_logloss: 0.30228 | valid_accuracy: 0.88747 |  0:08:34s\n",
            "epoch 254| loss: 0.28067 | train_logloss: 0.27421 | train_accuracy: 0.89563 | valid_logloss: 0.29829 | valid_accuracy: 0.88707 |  0:08:36s\n",
            "epoch 255| loss: 0.27548 | train_logloss: 0.26786 | train_accuracy: 0.8971  | valid_logloss: 0.29646 | valid_accuracy: 0.88763 |  0:08:38s\n",
            "epoch 256| loss: 0.27237 | train_logloss: 0.26337 | train_accuracy: 0.8992  | valid_logloss: 0.2942  | valid_accuracy: 0.8889  |  0:08:40s\n",
            "epoch 257| loss: 0.26585 | train_logloss: 0.25792 | train_accuracy: 0.9008  | valid_logloss: 0.29311 | valid_accuracy: 0.89023 |  0:08:42s\n",
            "epoch 258| loss: 0.27488 | train_logloss: 0.28174 | train_accuracy: 0.8917  | valid_logloss: 0.30313 | valid_accuracy: 0.88617 |  0:08:44s\n",
            "epoch 259| loss: 0.27983 | train_logloss: 0.27409 | train_accuracy: 0.89557 | valid_logloss: 0.3007  | valid_accuracy: 0.88927 |  0:08:46s\n",
            "epoch 260| loss: 0.27451 | train_logloss: 0.27247 | train_accuracy: 0.89607 | valid_logloss: 0.29911 | valid_accuracy: 0.88793 |  0:08:48s\n",
            "epoch 261| loss: 0.27055 | train_logloss: 0.25954 | train_accuracy: 0.89933 | valid_logloss: 0.28966 | valid_accuracy: 0.8903  |  0:08:50s\n",
            "epoch 262| loss: 0.26646 | train_logloss: 0.26116 | train_accuracy: 0.8992  | valid_logloss: 0.29387 | valid_accuracy: 0.8899  |  0:08:52s\n",
            "epoch 263| loss: 0.26555 | train_logloss: 0.26226 | train_accuracy: 0.8992  | valid_logloss: 0.2944  | valid_accuracy: 0.89    |  0:08:54s\n",
            "epoch 264| loss: 0.26853 | train_logloss: 0.27316 | train_accuracy: 0.8965  | valid_logloss: 0.30094 | valid_accuracy: 0.8901  |  0:08:56s\n",
            "epoch 265| loss: 0.27209 | train_logloss: 0.26304 | train_accuracy: 0.8982  | valid_logloss: 0.29688 | valid_accuracy: 0.88857 |  0:08:58s\n",
            "epoch 266| loss: 0.26892 | train_logloss: 0.25988 | train_accuracy: 0.90077 | valid_logloss: 0.29097 | valid_accuracy: 0.89077 |  0:09:00s\n",
            "epoch 267| loss: 0.26533 | train_logloss: 0.25597 | train_accuracy: 0.90103 | valid_logloss: 0.29024 | valid_accuracy: 0.8907  |  0:09:02s\n",
            "epoch 268| loss: 0.2619  | train_logloss: 0.26325 | train_accuracy: 0.8982  | valid_logloss: 0.29668 | valid_accuracy: 0.88817 |  0:09:04s\n",
            "epoch 269| loss: 0.26179 | train_logloss: 0.2524  | train_accuracy: 0.9017  | valid_logloss: 0.28855 | valid_accuracy: 0.89113 |  0:09:06s\n",
            "epoch 270| loss: 0.25819 | train_logloss: 0.25315 | train_accuracy: 0.9014  | valid_logloss: 0.29278 | valid_accuracy: 0.89097 |  0:09:08s\n",
            "epoch 271| loss: 0.25938 | train_logloss: 0.25187 | train_accuracy: 0.9022  | valid_logloss: 0.29391 | valid_accuracy: 0.88997 |  0:09:10s\n",
            "epoch 272| loss: 0.2604  | train_logloss: 0.25152 | train_accuracy: 0.90283 | valid_logloss: 0.29234 | valid_accuracy: 0.89007 |  0:09:12s\n",
            "epoch 273| loss: 0.25584 | train_logloss: 0.25066 | train_accuracy: 0.9026  | valid_logloss: 0.28853 | valid_accuracy: 0.89167 |  0:09:14s\n",
            "epoch 274| loss: 0.25739 | train_logloss: 0.25001 | train_accuracy: 0.903   | valid_logloss: 0.2938  | valid_accuracy: 0.88987 |  0:09:16s\n",
            "epoch 275| loss: 0.25625 | train_logloss: 0.26212 | train_accuracy: 0.89917 | valid_logloss: 0.30536 | valid_accuracy: 0.88603 |  0:09:18s\n",
            "epoch 276| loss: 0.26663 | train_logloss: 0.26069 | train_accuracy: 0.8976  | valid_logloss: 0.30017 | valid_accuracy: 0.88707 |  0:09:20s\n",
            "epoch 277| loss: 0.26376 | train_logloss: 0.25722 | train_accuracy: 0.8994  | valid_logloss: 0.29478 | valid_accuracy: 0.88853 |  0:09:22s\n",
            "epoch 278| loss: 0.25891 | train_logloss: 0.25476 | train_accuracy: 0.90173 | valid_logloss: 0.29633 | valid_accuracy: 0.8892  |  0:09:24s\n",
            "epoch 279| loss: 0.25522 | train_logloss: 0.24765 | train_accuracy: 0.90377 | valid_logloss: 0.29184 | valid_accuracy: 0.88967 |  0:09:26s\n",
            "epoch 280| loss: 0.26783 | train_logloss: 0.27098 | train_accuracy: 0.8977  | valid_logloss: 0.30806 | valid_accuracy: 0.88457 |  0:09:28s\n",
            "epoch 281| loss: 0.2784  | train_logloss: 0.2828  | train_accuracy: 0.89387 | valid_logloss: 0.3106  | valid_accuracy: 0.8829  |  0:09:30s\n",
            "epoch 282| loss: 0.2904  | train_logloss: 0.27913 | train_accuracy: 0.895   | valid_logloss: 0.30259 | valid_accuracy: 0.88593 |  0:09:32s\n",
            "epoch 283| loss: 0.27844 | train_logloss: 0.27004 | train_accuracy: 0.8978  | valid_logloss: 0.29571 | valid_accuracy: 0.88807 |  0:09:34s\n",
            "epoch 284| loss: 0.27037 | train_logloss: 0.26244 | train_accuracy: 0.90007 | valid_logloss: 0.29262 | valid_accuracy: 0.88967 |  0:09:36s\n",
            "epoch 285| loss: 0.2664  | train_logloss: 0.25863 | train_accuracy: 0.90033 | valid_logloss: 0.2929  | valid_accuracy: 0.8898  |  0:09:38s\n",
            "epoch 286| loss: 0.26153 | train_logloss: 0.25482 | train_accuracy: 0.9013  | valid_logloss: 0.28829 | valid_accuracy: 0.8906  |  0:09:40s\n",
            "epoch 287| loss: 0.25943 | train_logloss: 0.25334 | train_accuracy: 0.90313 | valid_logloss: 0.2894  | valid_accuracy: 0.89153 |  0:09:42s\n",
            "\n",
            "Early stopping occurred at epoch 287 with best_epoch = 237 and best_valid_accuracy = 0.892\n",
            "Best weights from best epoch are automatically used!\n",
            "TN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz8TXSqYuxWr"
      },
      "source": [
        "  c1 = 9000\n",
        "  data_split = data_preparation(X, y, c=c1//3)\n",
        "\n",
        "  X_train, X_test = data_split[:2]\n",
        "  y_train, y_test = data_split[2:4]\n",
        "\n",
        "  train = np.concatenate((X_train, y_train.reshape((len(y_train), 1))), axis=1)\n",
        "  np.random.shuffle(train)\n",
        "  X_train, y_train = train[:,:-1], train[:,-1].astype('int')\n",
        "\n",
        "  count = c1//3\n",
        "\n",
        "  X1_train, X1_test = data_split[4:6]\n",
        "  y1_train, y1_test = data_split[6:8]\n",
        "  X2_train, X2_test = data_split[8:10] \n",
        "  y2_train, y2_test = data_split[10:12]\n",
        "  X3_train, X3_test = data_split[12:14]\n",
        "  y3_train, y3_test = data_split[14:16]\n",
        "\n",
        "  X_train_pred = np.concatenate((X1_test[2*count : 4*count], X2_test[2*count : 4*count], X3_test[2*count : 4*count])) ###############\n",
        "  X_val_pred   = np.concatenate((X1_test[count : 2*count], X2_test[count : 2*count], X3_test[count : 2*count]))\n",
        "  np.random.shuffle(X_train_pred)\n",
        "  np.random.shuffle(X_val_pred)\n",
        "\n",
        "  X_valid      = np.concatenate((X1_test[4*count : 5*count], X2_test[4*count : 5*count], X3_test[4*count : 5*count]))\n",
        "  y_valid      = np.concatenate((y1_test[4*count : 5*count], y2_test[4*count : 5*count], y3_test[4*count : 5*count]))\n",
        "\n",
        "  robust = RobustScaler()\n",
        "\n",
        "  X_train_norm = robust.fit_transform(X_train)\n",
        "  X_test_norm = robust.transform(X_test)\n",
        "  X_valid_norm = robust.transform(X_valid)\n",
        "\n",
        "  gb = lgb.LGBMClassifier(  #ЛУЧШАЯ МОДЕЛЬ\n",
        "    **{'colsample_bytree': 0.6437405148446416,\n",
        "    'learning_rate': 0.0741521019613115,\n",
        "    'min_child_samples': 9+1,\n",
        "    'min_child_weight': 0.43858057836890685,\n",
        "    'n_estimators': 10000,\n",
        "    'num_leaves': 59+10}\n",
        "  )\n",
        "\n",
        "  t = time()\n",
        "  gb.fit(X_train_norm, y_train, eval_set=[(X_train_norm, y_train), (X_valid_norm, y_valid)],  **lgb_fit_params)\n",
        "  t = time()-t\n",
        "  print(t)\n",
        "\n",
        "  data_split = data_preparation(X, y, c=30000//3)\n",
        "\n",
        "\n",
        "  X_train, X_test = data_split[:2]\n",
        "  y_train, y_test = data_split[2:4]\n",
        "\n",
        "  train = np.concatenate((X_train, y_train.reshape((len(y_train), 1))), axis=1)\n",
        "  np.random.shuffle(train)\n",
        "  X_train, y_train = train[:,:-1], train[:,-1].astype('int')\n",
        "\n",
        "  count = 30000//3\n",
        "\n",
        "  X1_train, X1_test = data_split[4:6]\n",
        "  y1_train, y1_test = data_split[6:8]\n",
        "  X2_train, X2_test = data_split[8:10] \n",
        "  y2_train, y2_test = data_split[10:12]\n",
        "  X3_train, X3_test = data_split[12:14]\n",
        "  y3_train, y3_test = data_split[14:16]\n",
        "\n",
        "  X_train_pred = np.concatenate((X1_test[2*count : 4*count], X2_test[2*count : 4*count], X3_test[2*count : 4*count])) ###############\n",
        "  X_val_pred   = np.concatenate((X1_test[count : 2*count], X2_test[count : 2*count], X3_test[count : 2*count]))\n",
        "  np.random.shuffle(X_train_pred)\n",
        "  np.random.shuffle(X_val_pred)\n",
        "\n",
        "  X_valid      = np.concatenate((X1_test[4*count : 5*count], X2_test[4*count : 5*count], X3_test[4*count : 5*count]))\n",
        "  y_valid      = np.concatenate((y1_test[4*count : 5*count], y2_test[4*count : 5*count], y3_test[4*count : 5*count]))\n",
        "\n",
        "  robust = RobustScaler()\n",
        "\n",
        "  X_train_norm = robust.fit_transform(X_train)\n",
        "  X_test_norm = robust.transform(X_test)\n",
        "  X_valid_norm = robust.transform(X_valid)\n",
        "\n",
        "\n",
        "  #Accuracy\n",
        "  with open('/content/drive/MyDrive/Научная работа/Data/hyperparametrs.txt', 'a') as f:\n",
        "    f.write('GB '+str(c1)+'   ')\n",
        "\n",
        "  acc, err = bootstrap_accuracy(gb, X_test_norm, y_test)\n",
        "  with open('/content/drive/MyDrive/Научная работа/Data/hyperparametrs.txt', 'a') as f:\n",
        "    f.write('acc GB: '+str(acc)+'+-'+str(err)+', ')\n",
        "\n",
        "  #Feature importance\n",
        "  feature_acc(gb, 'GB', Rows)\n",
        "  with open('/content/drive/MyDrive/Научная работа/Data/hyperparametrs.txt', 'a') as f:\n",
        "    f.write('\\n')\n",
        "  gb.booster_.save_model('/content/drive/MyDrive/Научная работа/Data/hyper/gb_size'+str(c1)+'.txt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}